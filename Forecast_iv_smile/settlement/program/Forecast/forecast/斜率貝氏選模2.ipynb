{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from function import Slope, minSSE_recovery\n",
    "\n",
    "s_c = '結算價'\n",
    "top_path = './../../../'\n",
    "Data_path = top_path + 'InterpData/'\n",
    "expiry = 'NearbyMonth'\n",
    "\n",
    "IV_type = 'putIV'\n",
    "K_Range = [500, 300]\n",
    "K_Range_file = '{}_{}.csv'.format(K_Range[0], K_Range[1])\n",
    "K_Range_dir = '{}_{}'.format(K_Range[0], K_Range[1])\n",
    "IV_path = '{}/{}/{}/{}'.format(Data_path, expiry, IV_type, K_Range_file)\n",
    "\n",
    "Dir_tree = [top_path, 'ForecastData', expiry, IV_type, K_Range_dir]\n",
    "current_path = Dir_tree[0]\n",
    "for i in range(1, len(Dir_tree), 1):\n",
    "    if Dir_tree[i] not in os.listdir(current_path):\n",
    "        os.mkdir(current_path + Dir_tree[i])\n",
    "    current_path = current_path + Dir_tree[i] + '/'\n",
    "\n",
    "IV_data = pd.read_csv(IV_path, encoding='Big5', index_col=False)\n",
    "IV_matrix = np.array(IV_data)\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "OC = np.array(IV_data['期貨開盤價'] - IV_data['期貨收盤價'])\n",
    "HL = np.array(IV_data['期貨最高價'] - IV_data['期貨最低價'])\n",
    "expirty_days = np.array(IV_data['到期天數'])\n",
    "#OC_HL_K_E = np.vstack((OC, HL, Kmin_reduce_F, Kmax_reduce_F, expirty_days)).T\n",
    "OCHL = np.vstack((OC, HL)).T\n",
    "\n",
    "\n",
    "IV_matrix = np.array(IV_data)\n",
    "K_num = len(np.where(IV_matrix[0, 0] == IV_matrix)[0])\n",
    "K = np.array(IV_data['履約價'])\n",
    "K = np.reshape(K, (-1, K_num))\n",
    "IV= np.array(IV_data['隱含波動率({})'.format(s_c)])\n",
    "IV = np.reshape(IV, (-1, K_num))\n",
    "K_IVslope = Slope(X=K, Y=IV, axis=1)\n",
    "E = IV_matrix[range(0, len(IV_matrix), K_num), IV_data.columns.get_loc('到期天數')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day_expiry_idx = np.arange(len(E))[np.equal(E, 1)]\n",
    "if one_day_expiry_idx[-1] == len(E)-1:\n",
    "    one_day_expiry_idx = one_day_expiry_idx[:-1]\n",
    "most_days_expiry_idx = one_day_expiry_idx + 1\n",
    "most_days_expiry_idx = np.hstack((0, most_days_expiry_idx))\n",
    "\n",
    "most_days_expiry_idx0 = most_days_expiry_idx[:-1]\n",
    "most_days_expiry_idx1 = most_days_expiry_idx[1:]\n",
    "trade_days_in_month = most_days_expiry_idx1 - most_days_expiry_idx0  \n",
    "most_days_expiry = E[most_days_expiry_idx]\n",
    "\n",
    "contract_appear_days1 = [list(range(1, trade_day_in_month+1, 1)) \\\n",
    "                for trade_day_in_month in trade_days_in_month]\n",
    "contract_appear_days1 = [contract_appear_day1 for subcontract_appear_day1 in contract_appear_days1\\\n",
    "                         for contract_appear_day1 in subcontract_appear_day1]\n",
    "contract_appear_days1 = np.array(contract_appear_days1)\n",
    "contract_appear_days2 = np.arange(1, len(E) - most_days_expiry_idx[-1] +1, 1)\n",
    "contract_appear_days = np.hstack((contract_appear_days1, contract_appear_days2))\n",
    "#contract_appear_days 為該契約(特定交易日期、到期日期，履約價不限)上市的交易日數，例如第一天上市到期天數35天，\n",
    "#則值為1，第二天則到期日為34天值為2，一直到k(因為是交易日數，所以數字不一定)。然後又到下個月的契約，值又從1開\n",
    "#始\n",
    "\n",
    "\n",
    "from function import TimeSeriesData\n",
    "seq_length1 = 7\n",
    "seq_length2 = seq_length1 + 1\n",
    "min_contract_day = 2\n",
    "magnification_slope = 10000\n",
    "\n",
    "\n",
    "#變數有考慮到期日\n",
    "#K_IVslope_E = np.hstack((K_IVslope*magnification_slope, np.reshape(E, (-1, 1))))\n",
    "\n",
    "#Inputs_slope, Ouputs = TimeSeriesData(K_IVslope_E, seq_length=seq_length1, \\\n",
    "                                      #drop_out_columns=[len(K_IVslope_E[0])-1])\n",
    "\n",
    "#變數沒考慮到期日\n",
    "K_IVslope_E = K_IVslope * magnification_slope\n",
    "Inputs_slope, Ouputs = TimeSeriesData(K_IVslope_E, seq_length=seq_length1, drop_out_columns=[])\n",
    "\n",
    "\n",
    "\n",
    "Inputs_OCHLE  = OCHL[range(0, len(IV_matrix), K_num)]\n",
    "Inputs_OCHLE  = np.array([Inputs_OCHLE[i:i+seq_length2] \\\n",
    "                              for i in range(len(Inputs_OCHLE)-seq_length2+1)])\n",
    "Inputs_OCHLE  = Inputs_OCHLE.astype(float)\n",
    "if seq_length1  > seq_length2-1:\n",
    "    Inputs_OCHLE = Inputs_OCHLE[seq_length1-seq_length2+1:]\n",
    "    contract_appear_days = contract_appear_days[seq_length1-seq_length2+1:]\n",
    "    IV_matrix_forecast = IV_matrix[seq_length1*K_num:]\n",
    "if seq_length1 <= seq_length2-1:\n",
    "    Inputs_slope = Inputs_slope[seq_length2-1-seq_length1:]\n",
    "    Ouputs = Ouputs[seq_length2-1-seq_length1:]\n",
    "    contract_appear_days = contract_appear_days[seq_length2-1:]\n",
    "    IV_matrix_forecast = IV_matrix[(seq_length2-1)*K_num:]\n",
    "\n",
    "\n",
    "match_cond = np.greater_equal(contract_appear_days, min_contract_day)\n",
    "Inputs_OCHLE = Inputs_OCHLE[match_cond]\n",
    "Inputs_slope = Inputs_slope[match_cond]\n",
    "contract_appear_days_filter = contract_appear_days[match_cond]\n",
    "contract_appear_days_filter_Knum = contract_appear_days_filter.repeat(K_num)\n",
    "match_cond_Knum = match_cond.repeat(K_num)\n",
    "IV_matrix_forecast = IV_matrix_forecast[match_cond_Knum]\n",
    "IV_matrix_forecast= np.hstack((IV_matrix_forecast, np.reshape(contract_appear_days_filter_Knum, (-1, 1))))\n",
    "Ouputs = Ouputs[match_cond]\n",
    "\n",
    "\n",
    "\n",
    "train_size = int(len(Inputs_slope)*0.8)\n",
    "#val_size = int(train_size*0.2)\n",
    "X_train = Inputs_slope[:train_size]\n",
    "#X_train = Inputs_slope[:train_size-val_size]\n",
    "#X_val = Inputs_slope[train_size - val_size:train_size]\n",
    "OCHLE_train = Inputs_OCHLE[:train_size ]\n",
    "#OCHLE_train = Inputs_OCHLE[:train_size - val_size]\n",
    "#OCHLE_val = Inputs_OCHLE[train_size - val_size:train_size]\n",
    "y_train = Ouputs[:train_size]\n",
    "#y_train = Ouputs[:train_size-val_size]\n",
    "#y_val = Ouputs[train_size - val_size:train_size]\n",
    "\n",
    "\n",
    "X_test = Inputs_slope[train_size:]\n",
    "y_test = Ouputs[train_size:]\n",
    "IV_matrix_test = IV_matrix_forecast[K_num*train_size:]\n",
    "OCHLE_test = Inputs_OCHLE[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "56/56 [==============================] - 8s 31ms/step - loss: 3.2012 - mse: 3.1213 - val_loss: 1.1464 - val_mse: 1.0815\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.6222 - mse: 2.5663 - val_loss: 1.0712 - val_mse: 1.0228\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5328 - mse: 2.4896 - val_loss: 1.1404 - val_mse: 1.1018\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.4761 - mse: 2.4408 - val_loss: 1.1228 - val_mse: 1.0905\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3842 - mse: 2.3544 - val_loss: 1.1323 - val_mse: 1.1049\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3427 - mse: 2.3171 - val_loss: 1.0983 - val_mse: 1.0743\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.2551 - mse: 2.2326 - val_loss: 1.1003 - val_mse: 1.0792\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.1936 - mse: 2.1736 - val_loss: 1.1411 - val_mse: 1.1219\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1195 - mse: 2.1012 - val_loss: 1.0984 - val_mse: 1.0811\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.0142 - mse: 1.9978 - val_loss: 1.1201 - val_mse: 1.1043\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.8853 - mse: 1.8700 - val_loss: 1.0837 - val_mse: 1.0690\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 1.8044 - mse: 1.7904Restoring model weights from the end of the best epoch: 2.\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.8044 - mse: 1.7904 - val_loss: 1.0979 - val_mse: 1.0845\n",
      "Epoch 12: early stopping\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 27ms/step - loss: 5.1927 - mse: 3.1184 - val_loss: 2.2697 - val_mse: 1.1373\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 3.4846 - mse: 2.6647 - val_loss: 1.7095 - val_mse: 1.1057\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 3.0600 - mse: 2.5672 - val_loss: 1.4816 - val_mse: 1.0777\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.9356 - mse: 2.5862 - val_loss: 1.3799 - val_mse: 1.0737\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.8125 - mse: 2.5377 - val_loss: 1.3068 - val_mse: 1.0608\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.7262 - mse: 2.4969 - val_loss: 1.2403 - val_mse: 1.0283\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.6414 - mse: 2.4412 - val_loss: 1.2256 - val_mse: 1.0361\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.6559 - mse: 2.4705 - val_loss: 1.2883 - val_mse: 1.1080\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5841 - mse: 2.4061 - val_loss: 1.2540 - val_mse: 1.0813\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5297 - mse: 2.3568 - val_loss: 1.2327 - val_mse: 1.0602\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5912 - mse: 2.4188 - val_loss: 1.2701 - val_mse: 1.0959\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5350 - mse: 2.3643 - val_loss: 1.2171 - val_mse: 1.0487\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4444 - mse: 2.2781 - val_loss: 1.2056 - val_mse: 1.0401\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4251 - mse: 2.2584 - val_loss: 1.1997 - val_mse: 1.0309\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.3933 - mse: 2.2265 - val_loss: 1.2255 - val_mse: 1.0528\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.4097 - mse: 2.2345 - val_loss: 1.2215 - val_mse: 1.0402\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.3419 - mse: 2.1576 - val_loss: 1.2268 - val_mse: 1.0449\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.3539 - mse: 2.1764 - val_loss: 1.2415 - val_mse: 1.0662\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.2326 - mse: 2.0602 - val_loss: 1.2503 - val_mse: 1.0801\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 2.1728 - mse: 2.0065 - val_loss: 1.2175 - val_mse: 1.0530\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1905 - mse: 2.0247 - val_loss: 1.2390 - val_mse: 1.0706\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.1501 - mse: 1.9789 - val_loss: 1.2832 - val_mse: 1.1102\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.1230 - mse: 1.9498 - val_loss: 1.2439 - val_mse: 1.0680\n",
      "Epoch 24/1000\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 2.1781 - mse: 1.9936Restoring model weights from the end of the best epoch: 14.\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.1579 - mse: 1.9732 - val_loss: 1.2291 - val_mse: 1.0397\n",
      "Epoch 24: early stopping\n",
      "18/18 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 30ms/step - loss: 3.2017 - mse: 3.1458 - val_loss: 1.1288 - val_mse: 1.0741\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.6411 - mse: 2.5875 - val_loss: 1.0867 - val_mse: 1.0341\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5871 - mse: 2.5351 - val_loss: 1.0952 - val_mse: 1.0439\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.5148 - mse: 2.4638 - val_loss: 1.1052 - val_mse: 1.0546\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.4206 - mse: 2.3701 - val_loss: 1.1312 - val_mse: 1.0807\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.3741 - mse: 2.3235 - val_loss: 1.1050 - val_mse: 1.0541\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3377 - mse: 2.2865 - val_loss: 1.1059 - val_mse: 1.0544\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3079 - mse: 2.2561 - val_loss: 1.1625 - val_mse: 1.1102\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.2085 - mse: 2.1558 - val_loss: 1.1158 - val_mse: 1.0626\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1354 - mse: 2.0819 - val_loss: 1.1469 - val_mse: 1.0930\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.0052 - mse: 1.9505 - val_loss: 1.1844 - val_mse: 1.1291\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 1.9843 - mse: 1.9284Restoring model weights from the end of the best epoch: 2.\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.9843 - mse: 1.9284 - val_loss: 1.1504 - val_mse: 1.0938\n",
      "Epoch 12: early stopping\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 30ms/step - loss: 3.5800 - mse: 3.2811 - val_loss: 1.4022 - val_mse: 1.2095\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.7545 - mse: 2.6046 - val_loss: 1.1924 - val_mse: 1.0748\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.6360 - mse: 2.5368 - val_loss: 1.1786 - val_mse: 1.0949\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5691 - mse: 2.4958 - val_loss: 1.1909 - val_mse: 1.1267\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.5020 - mse: 2.4444 - val_loss: 1.0868 - val_mse: 1.0353\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.4452 - mse: 2.3982 - val_loss: 1.1225 - val_mse: 1.0797\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.3448 - mse: 2.3051 - val_loss: 1.0710 - val_mse: 1.0342\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3092 - mse: 2.2746 - val_loss: 1.0964 - val_mse: 1.0639\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.1758 - mse: 2.1451 - val_loss: 1.0535 - val_mse: 1.0246\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.1307 - mse: 2.1029 - val_loss: 1.1221 - val_mse: 1.0956\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.0155 - mse: 1.9898 - val_loss: 1.0990 - val_mse: 1.0742\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.9562 - mse: 1.9310 - val_loss: 1.1229 - val_mse: 1.0873\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.9153 - mse: 1.8766 - val_loss: 1.0734 - val_mse: 1.0380\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.8271 - mse: 1.7977 - val_loss: 1.0901 - val_mse: 1.0643\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.6327 - mse: 1.6086 - val_loss: 1.0921 - val_mse: 1.0693\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.6343 - mse: 1.6124 - val_loss: 1.0995 - val_mse: 1.0783\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.5799 - mse: 1.5593 - val_loss: 1.1260 - val_mse: 1.1057\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.4488 - mse: 1.4282 - val_loss: 1.0745 - val_mse: 1.0544\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 1.3144 - mse: 1.2948Restoring model weights from the end of the best epoch: 9.\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.3144 - mse: 1.2948 - val_loss: 1.1157 - val_mse: 1.0964\n",
      "Epoch 19: early stopping\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 4s 30ms/step - loss: 4.6571 - mse: 3.0627 - val_loss: 2.0242 - val_mse: 1.0990\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 3.3085 - mse: 2.6263 - val_loss: 1.5801 - val_mse: 1.0738\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.9794 - mse: 2.5647 - val_loss: 1.4460 - val_mse: 1.1024\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.8463 - mse: 2.5435 - val_loss: 1.3990 - val_mse: 1.1284\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.7543 - mse: 2.5046 - val_loss: 1.2767 - val_mse: 1.0458\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.7007 - mse: 2.4838 - val_loss: 1.2995 - val_mse: 1.0917\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.6156 - mse: 2.4188 - val_loss: 1.2854 - val_mse: 1.0995\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5862 - mse: 2.4001 - val_loss: 1.2464 - val_mse: 1.0593\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5838 - mse: 2.3975 - val_loss: 1.2291 - val_mse: 1.0461\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5180 - mse: 2.3355 - val_loss: 1.2430 - val_mse: 1.0596\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5172 - mse: 2.3316 - val_loss: 1.2731 - val_mse: 1.0895\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4820 - mse: 2.2957 - val_loss: 1.2069 - val_mse: 1.0193\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4516 - mse: 2.2635 - val_loss: 1.2560 - val_mse: 1.0663\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.4173 - mse: 2.2287 - val_loss: 1.2783 - val_mse: 1.0892\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3712 - mse: 2.1816 - val_loss: 1.2770 - val_mse: 1.0866\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3424 - mse: 2.1545 - val_loss: 1.3309 - val_mse: 1.1447\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.2643 - mse: 2.0764 - val_loss: 1.2513 - val_mse: 1.0639\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.2354 - mse: 2.0503 - val_loss: 1.2743 - val_mse: 1.0851\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1713 - mse: 1.9812 - val_loss: 1.2846 - val_mse: 1.0942\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.2282 - mse: 2.0337 - val_loss: 1.2854 - val_mse: 1.0860\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1455 - mse: 1.9454 - val_loss: 1.2987 - val_mse: 1.0979\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 2.0449 - mse: 1.8450Restoring model weights from the end of the best epoch: 12.\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.0449 - mse: 1.8450 - val_loss: 1.3236 - val_mse: 1.1240\n",
      "Epoch 22: early stopping\n",
      "18/18 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 27ms/step - loss: 3.7230 - mse: 3.1714 - val_loss: 1.4747 - val_mse: 1.1298\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.8879 - mse: 2.6186 - val_loss: 1.2771 - val_mse: 1.0631\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.7526 - mse: 2.5691 - val_loss: 1.2143 - val_mse: 1.0558\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.6599 - mse: 2.5172 - val_loss: 1.1781 - val_mse: 1.0496\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5821 - mse: 2.4639 - val_loss: 1.1814 - val_mse: 1.0717\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5035 - mse: 2.3998 - val_loss: 1.1620 - val_mse: 1.0639\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.4072 - mse: 2.3133 - val_loss: 1.1658 - val_mse: 1.0754\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3448 - mse: 2.2564 - val_loss: 1.1517 - val_mse: 1.0653\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.3763 - mse: 2.2904 - val_loss: 1.1896 - val_mse: 1.1033\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.2942 - mse: 2.2069 - val_loss: 1.1676 - val_mse: 1.0782\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.1246 - mse: 2.0359 - val_loss: 1.1390 - val_mse: 1.0523\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1291 - mse: 2.0449 - val_loss: 1.1300 - val_mse: 1.0476\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.9703 - mse: 1.8882 - val_loss: 1.1990 - val_mse: 1.1173\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.9852 - mse: 1.9034 - val_loss: 1.1088 - val_mse: 1.0270\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.8467 - mse: 1.7649 - val_loss: 1.1704 - val_mse: 1.0885\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.7834 - mse: 1.7009 - val_loss: 1.1564 - val_mse: 1.0733\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.7473 - mse: 1.6640 - val_loss: 1.2022 - val_mse: 1.1185\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.6581 - mse: 1.5744 - val_loss: 1.1619 - val_mse: 1.0778\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.6149 - mse: 1.5298 - val_loss: 1.1596 - val_mse: 1.0741\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.5313 - mse: 1.4453 - val_loss: 1.1842 - val_mse: 1.0977\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.4435 - mse: 1.3566 - val_loss: 1.2351 - val_mse: 1.1477\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.3888 - mse: 1.3006 - val_loss: 1.1394 - val_mse: 1.0506\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.3276 - mse: 1.2388 - val_loss: 1.1990 - val_mse: 1.1102\n",
      "Epoch 24/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 1.2759 - mse: 1.1867Restoring model weights from the end of the best epoch: 14.\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.2743 - mse: 1.1851 - val_loss: 1.2450 - val_mse: 1.1553\n",
      "Epoch 24: early stopping\n",
      "18/18 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 4s 32ms/step - loss: 3.2488 - mse: 3.1850 - val_loss: 1.1511 - val_mse: 1.0973\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.6472 - mse: 2.5997 - val_loss: 1.1416 - val_mse: 1.0996\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5528 - mse: 2.5146 - val_loss: 1.0930 - val_mse: 1.0582\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5080 - mse: 2.4757 - val_loss: 1.0951 - val_mse: 1.0651\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.4304 - mse: 2.4023 - val_loss: 1.0629 - val_mse: 1.0365\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.3646 - mse: 2.3396 - val_loss: 1.0842 - val_mse: 1.0606\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.3515 - mse: 2.3291 - val_loss: 1.0460 - val_mse: 1.0245\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.2453 - mse: 2.2246 - val_loss: 1.0703 - val_mse: 1.0505\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 2.1274 - mse: 2.1082 - val_loss: 1.0704 - val_mse: 1.0518\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.0697 - mse: 2.0516 - val_loss: 1.0724 - val_mse: 1.0548\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.9660 - mse: 1.9491 - val_loss: 1.0758 - val_mse: 1.0596\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.8737 - mse: 1.8579 - val_loss: 1.1248 - val_mse: 1.1094\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.7937 - mse: 1.7785 - val_loss: 1.0488 - val_mse: 1.0338\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.6813 - mse: 1.6669 - val_loss: 1.0709 - val_mse: 1.0569\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.5976 - mse: 1.5837 - val_loss: 1.1050 - val_mse: 1.0910\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.5450 - mse: 1.5311 - val_loss: 1.1220 - val_mse: 1.1082\n",
      "Epoch 17/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 1.4617 - mse: 1.4482Restoring model weights from the end of the best epoch: 7.\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.4659 - mse: 1.4524 - val_loss: 1.1447 - val_mse: 1.1316\n",
      "Epoch 17: early stopping\n",
      "18/18 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 4s 26ms/step - loss: 5.8865 - mse: 3.0602 - val_loss: 1.8484 - val_mse: 1.1460\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 3.0229 - mse: 2.6125 - val_loss: 1.3412 - val_mse: 1.0771\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.7603 - mse: 2.5339 - val_loss: 1.2880 - val_mse: 1.0852\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.6565 - mse: 2.4640 - val_loss: 1.2619 - val_mse: 1.0779\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5756 - mse: 2.3971 - val_loss: 1.2297 - val_mse: 1.0553\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5151 - mse: 2.3436 - val_loss: 1.2483 - val_mse: 1.0789\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.4384 - mse: 2.2709 - val_loss: 1.2251 - val_mse: 1.0592\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5148 - mse: 2.3502 - val_loss: 1.2897 - val_mse: 1.1259\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.4573 - mse: 2.2923 - val_loss: 1.1880 - val_mse: 1.0232\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.2662 - mse: 2.1024 - val_loss: 1.2604 - val_mse: 1.0973\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.1590 - mse: 1.9966 - val_loss: 1.2837 - val_mse: 1.1224\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.0505 - mse: 1.8889 - val_loss: 1.2111 - val_mse: 1.0499\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.0077 - mse: 1.8462 - val_loss: 1.2262 - val_mse: 1.0649\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.8978 - mse: 1.7366 - val_loss: 1.3153 - val_mse: 1.1530\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.8571 - mse: 1.6946 - val_loss: 1.3442 - val_mse: 1.1806\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.8161 - mse: 1.6513 - val_loss: 1.2614 - val_mse: 1.0963\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.7312 - mse: 1.5654 - val_loss: 1.3322 - val_mse: 1.1655\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.6556 - mse: 1.4889 - val_loss: 1.2665 - val_mse: 1.0997\n",
      "Epoch 19/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 1.5857 - mse: 1.4188Restoring model weights from the end of the best epoch: 9.\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.5756 - mse: 1.4088 - val_loss: 1.3622 - val_mse: 1.1952\n",
      "Epoch 19: early stopping\n",
      "18/18 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 4s 30ms/step - loss: 3.7682 - mse: 2.9671 - val_loss: 1.4665 - val_mse: 1.0941\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.8441 - mse: 2.5822 - val_loss: 1.2557 - val_mse: 1.0696\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.6841 - mse: 2.5341 - val_loss: 1.1782 - val_mse: 1.0565\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5899 - mse: 2.4844 - val_loss: 1.1122 - val_mse: 1.0203\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5046 - mse: 2.4209 - val_loss: 1.1428 - val_mse: 1.0661\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4622 - mse: 2.3902 - val_loss: 1.1095 - val_mse: 1.0413\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.3969 - mse: 2.3306 - val_loss: 1.1345 - val_mse: 1.0698\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3971 - mse: 2.3333 - val_loss: 1.1514 - val_mse: 1.0880\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.2664 - mse: 2.2033 - val_loss: 1.1575 - val_mse: 1.0950\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.1209 - mse: 2.0584 - val_loss: 1.1332 - val_mse: 1.0709\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.1145 - mse: 2.0522 - val_loss: 1.3049 - val_mse: 1.2421\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.0594 - mse: 1.9947 - val_loss: 1.2315 - val_mse: 1.1647\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.8981 - mse: 1.8316 - val_loss: 1.1774 - val_mse: 1.1113\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.8530 - mse: 1.7861 - val_loss: 1.2058 - val_mse: 1.1389\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.7487 - mse: 1.6819 - val_loss: 1.1902 - val_mse: 1.1232\n",
      "Epoch 16/1000\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 1.6376 - mse: 1.5700Restoring model weights from the end of the best epoch: 6.\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.6348 - mse: 1.5672 - val_loss: 1.1473 - val_mse: 1.0790\n",
      "Epoch 16: early stopping\n",
      "18/18 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 28ms/step - loss: 3.2628 - mse: 3.2548 - val_loss: 1.1450 - val_mse: 1.1373\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.6314 - mse: 2.6241 - val_loss: 1.1037 - val_mse: 1.0966\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.5364 - mse: 2.5296 - val_loss: 1.0792 - val_mse: 1.0726\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.5102 - mse: 2.5038 - val_loss: 1.0768 - val_mse: 1.0706\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.4564 - mse: 2.4504 - val_loss: 1.0634 - val_mse: 1.0575\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3809 - mse: 2.3751 - val_loss: 1.1277 - val_mse: 1.1221\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.2955 - mse: 2.2900 - val_loss: 1.0640 - val_mse: 1.0586\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.1896 - mse: 2.1843 - val_loss: 1.0579 - val_mse: 1.0527\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1650 - mse: 2.1598 - val_loss: 1.0977 - val_mse: 1.0926\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1791 - mse: 2.1740 - val_loss: 1.1457 - val_mse: 1.1407\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.0613 - mse: 2.0563 - val_loss: 1.0515 - val_mse: 1.0465\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.9476 - mse: 1.9427 - val_loss: 1.1120 - val_mse: 1.1072\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.8828 - mse: 1.8780 - val_loss: 1.1205 - val_mse: 1.1157\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.8243 - mse: 1.8195 - val_loss: 1.0805 - val_mse: 1.0758\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.7256 - mse: 1.7209 - val_loss: 1.1299 - val_mse: 1.1252\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.6434 - mse: 1.6388 - val_loss: 1.1306 - val_mse: 1.1259\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.6034 - mse: 1.5987 - val_loss: 1.0947 - val_mse: 1.0901\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.5668 - mse: 1.5622 - val_loss: 1.1827 - val_mse: 1.1780\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.4601 - mse: 1.4555 - val_loss: 1.1370 - val_mse: 1.1324\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.3085 - mse: 1.3039 - val_loss: 1.1643 - val_mse: 1.1597\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 1.2146 - mse: 1.2100Restoring model weights from the end of the best epoch: 11.\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.2146 - mse: 1.2100 - val_loss: 1.1256 - val_mse: 1.1210\n",
      "Epoch 21: early stopping\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 29ms/step - loss: 5.0591 - mse: 3.1323 - val_loss: 2.1543 - val_mse: 1.1064\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 3.3729 - mse: 2.5905 - val_loss: 1.6762 - val_mse: 1.0846\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 3.1205 - mse: 2.6176 - val_loss: 1.4833 - val_mse: 1.0564\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.8910 - mse: 2.5165 - val_loss: 1.4017 - val_mse: 1.0706\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.7928 - mse: 2.4910 - val_loss: 1.3940 - val_mse: 1.1163\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.7107 - mse: 2.4520 - val_loss: 1.2813 - val_mse: 1.0386\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.7006 - mse: 2.4694 - val_loss: 1.4036 - val_mse: 1.1784\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.6170 - mse: 2.4018 - val_loss: 1.3341 - val_mse: 1.1289\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.6005 - mse: 2.3989 - val_loss: 1.2137 - val_mse: 1.0181\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4831 - mse: 2.2909 - val_loss: 1.2596 - val_mse: 1.0691\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4717 - mse: 2.2857 - val_loss: 1.2736 - val_mse: 1.0924\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4931 - mse: 2.3094 - val_loss: 1.2369 - val_mse: 1.0524\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4147 - mse: 2.2324 - val_loss: 1.2571 - val_mse: 1.0772\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3929 - mse: 2.2157 - val_loss: 1.2385 - val_mse: 1.0650\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.2871 - mse: 2.1116 - val_loss: 1.2461 - val_mse: 1.0656\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.2787 - mse: 2.0937 - val_loss: 1.2002 - val_mse: 1.0173\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.2264 - mse: 2.0469 - val_loss: 1.2399 - val_mse: 1.0617\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1910 - mse: 2.0127 - val_loss: 1.2444 - val_mse: 1.0643\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1295 - mse: 1.9447 - val_loss: 1.2809 - val_mse: 1.0929\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1435 - mse: 1.9536 - val_loss: 1.2525 - val_mse: 1.0619\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.0636 - mse: 1.8733 - val_loss: 1.2132 - val_mse: 1.0225\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.0442 - mse: 1.8512 - val_loss: 1.2154 - val_mse: 1.0213\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.0244 - mse: 1.8303 - val_loss: 1.2602 - val_mse: 1.0622\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.9266 - mse: 1.7233 - val_loss: 1.2926 - val_mse: 1.0871\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.8150 - mse: 1.6107 - val_loss: 1.3484 - val_mse: 1.1451\n",
      "Epoch 26/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 1.7436 - mse: 1.5405Restoring model weights from the end of the best epoch: 16.\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.7436 - mse: 1.5405 - val_loss: 1.2919 - val_mse: 1.0870\n",
      "Epoch 26: early stopping\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 36ms/step - loss: 4.6622 - mse: 3.2296 - val_loss: 2.0449 - val_mse: 1.0927\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 3.4081 - mse: 2.6565 - val_loss: 1.6407 - val_mse: 1.0349\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 3.1037 - mse: 2.5783 - val_loss: 1.5235 - val_mse: 1.0653\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.9533 - mse: 2.5367 - val_loss: 1.4133 - val_mse: 1.0385\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.8424 - mse: 2.4975 - val_loss: 1.3268 - val_mse: 1.0078\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.7894 - mse: 2.4908 - val_loss: 1.3295 - val_mse: 1.0459\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.7579 - mse: 2.4864 - val_loss: 1.3100 - val_mse: 1.0513\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.6391 - mse: 2.3896 - val_loss: 1.2524 - val_mse: 1.0140\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.6172 - mse: 2.3845 - val_loss: 1.2734 - val_mse: 1.0487\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.6149 - mse: 2.3940 - val_loss: 1.2628 - val_mse: 1.0436\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5754 - mse: 2.3603 - val_loss: 1.2939 - val_mse: 1.0804\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5230 - mse: 2.3141 - val_loss: 1.3657 - val_mse: 1.1587\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5659 - mse: 2.3604 - val_loss: 1.2333 - val_mse: 1.0333\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.4642 - mse: 2.2631 - val_loss: 1.2733 - val_mse: 1.0690\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4424 - mse: 2.2208 - val_loss: 1.2603 - val_mse: 1.0399\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.4078 - mse: 2.1962 - val_loss: 1.2250 - val_mse: 1.0204\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4012 - mse: 2.2032 - val_loss: 1.2092 - val_mse: 1.0113\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.3462 - mse: 2.1497 - val_loss: 1.2695 - val_mse: 1.0727\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3316 - mse: 2.1352 - val_loss: 1.2441 - val_mse: 1.0446\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.2676 - mse: 2.0709 - val_loss: 1.2818 - val_mse: 1.0847\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.2325 - mse: 2.0362 - val_loss: 1.2768 - val_mse: 1.0803\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.2051 - mse: 2.0075 - val_loss: 1.2399 - val_mse: 1.0409\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.1953 - mse: 1.9942 - val_loss: 1.2597 - val_mse: 1.0575\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1591 - mse: 1.9554 - val_loss: 1.2953 - val_mse: 1.0943\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.1065 - mse: 1.9020 - val_loss: 1.2748 - val_mse: 1.0695\n",
      "Epoch 26/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.0614 - mse: 1.8503 - val_loss: 1.2805 - val_mse: 1.0701\n",
      "Epoch 27/1000\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 1.9315 - mse: 1.7242Restoring model weights from the end of the best epoch: 17.\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.0170 - mse: 1.8099 - val_loss: 1.2868 - val_mse: 1.0802\n",
      "Epoch 27: early stopping\n",
      "18/18 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 4s 28ms/step - loss: 3.7883 - mse: 3.0322 - val_loss: 1.6018 - val_mse: 1.1138\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 3.0158 - mse: 2.6193 - val_loss: 1.3966 - val_mse: 1.0669\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.7922 - mse: 2.4998 - val_loss: 1.3196 - val_mse: 1.0589\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.7260 - mse: 2.4856 - val_loss: 1.2689 - val_mse: 1.0454\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.6216 - mse: 2.4097 - val_loss: 1.2862 - val_mse: 1.0855\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5975 - mse: 2.4048 - val_loss: 1.2386 - val_mse: 1.0533\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.6399 - mse: 2.4591 - val_loss: 1.3227 - val_mse: 1.1455\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.4749 - mse: 2.2969 - val_loss: 1.2214 - val_mse: 1.0422\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3707 - mse: 2.1964 - val_loss: 1.2161 - val_mse: 1.0489\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3193 - mse: 2.1551 - val_loss: 1.2128 - val_mse: 1.0509\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.2718 - mse: 2.1113 - val_loss: 1.1954 - val_mse: 1.0363\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.2574 - mse: 2.0979 - val_loss: 1.2146 - val_mse: 1.0552\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1134 - mse: 1.9550 - val_loss: 1.2053 - val_mse: 1.0466\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.0359 - mse: 1.8704 - val_loss: 1.2190 - val_mse: 1.0464\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.9374 - mse: 1.7687 - val_loss: 1.2292 - val_mse: 1.0644\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.8164 - mse: 1.6533 - val_loss: 1.2845 - val_mse: 1.1228\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.7564 - mse: 1.5957 - val_loss: 1.2649 - val_mse: 1.1046\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.7015 - mse: 1.5406 - val_loss: 1.3113 - val_mse: 1.1501\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.6563 - mse: 1.4947 - val_loss: 1.2307 - val_mse: 1.0682\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.5974 - mse: 1.4342 - val_loss: 1.2390 - val_mse: 1.0758\n",
      "Epoch 21/1000\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 1.5074 - mse: 1.3440Restoring model weights from the end of the best epoch: 11.\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.5158 - mse: 1.3524 - val_loss: 1.2371 - val_mse: 1.0732\n",
      "Epoch 21: early stopping\n",
      "18/18 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 4s 28ms/step - loss: 3.0905 - mse: 3.0661 - val_loss: 1.1316 - val_mse: 1.1093\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.6086 - mse: 2.5881 - val_loss: 1.1068 - val_mse: 1.0879\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.5450 - mse: 2.5273 - val_loss: 1.1017 - val_mse: 1.0851\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.4769 - mse: 2.4612 - val_loss: 1.0671 - val_mse: 1.0522\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.4617 - mse: 2.4475 - val_loss: 1.0603 - val_mse: 1.0467\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.3848 - mse: 2.3717 - val_loss: 1.0855 - val_mse: 1.0729\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.3050 - mse: 2.2929 - val_loss: 1.0584 - val_mse: 1.0467\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.2971 - mse: 2.2858 - val_loss: 1.1049 - val_mse: 1.0940\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.1748 - mse: 2.1642 - val_loss: 1.1016 - val_mse: 1.0914\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.0009 - mse: 1.9909 - val_loss: 1.1167 - val_mse: 1.1069\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.9016 - mse: 1.8920 - val_loss: 1.0875 - val_mse: 1.0782\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.8075 - mse: 1.7984 - val_loss: 1.0911 - val_mse: 1.0820\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.7555 - mse: 1.7465 - val_loss: 1.1218 - val_mse: 1.1129\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.6408 - mse: 1.6320 - val_loss: 1.1194 - val_mse: 1.1108\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.5328 - mse: 1.5243 - val_loss: 1.2085 - val_mse: 1.2000\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.4099 - mse: 1.4014 - val_loss: 1.1239 - val_mse: 1.1155\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 1.3172 - mse: 1.3088Restoring model weights from the end of the best epoch: 7.\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 1.3172 - mse: 1.3088 - val_loss: 1.2126 - val_mse: 1.2042\n",
      "Epoch 17: early stopping\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 27ms/step - loss: 3.3318 - mse: 3.2052 - val_loss: 1.2003 - val_mse: 1.0973\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.7260 - mse: 2.6360 - val_loss: 1.1563 - val_mse: 1.0770\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.6179 - mse: 2.5454 - val_loss: 1.1195 - val_mse: 1.0530\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5391 - mse: 2.4768 - val_loss: 1.1406 - val_mse: 1.0820\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.4869 - mse: 2.4311 - val_loss: 1.1083 - val_mse: 1.0551\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.4381 - mse: 2.3870 - val_loss: 1.1579 - val_mse: 1.1086\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.4014 - mse: 2.3534 - val_loss: 1.0853 - val_mse: 1.0387\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.2782 - mse: 2.2327 - val_loss: 1.1512 - val_mse: 1.1064\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.1975 - mse: 2.1535 - val_loss: 1.1421 - val_mse: 1.0991\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.1236 - mse: 2.0812 - val_loss: 1.1673 - val_mse: 1.1254\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.0893 - mse: 2.0476 - val_loss: 1.1379 - val_mse: 1.0965\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.0271 - mse: 1.9858 - val_loss: 1.1193 - val_mse: 1.0779\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.8795 - mse: 1.8383 - val_loss: 1.1627 - val_mse: 1.1216\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.8534 - mse: 1.8126 - val_loss: 1.1312 - val_mse: 1.0906\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.8021 - mse: 1.7614 - val_loss: 1.1881 - val_mse: 1.1473\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.6983 - mse: 1.6577 - val_loss: 1.1988 - val_mse: 1.1583\n",
      "Epoch 17/1000\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 1.5652 - mse: 1.5248Restoring model weights from the end of the best epoch: 7.\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.6270 - mse: 1.5866 - val_loss: 1.1688 - val_mse: 1.1284\n",
      "Epoch 17: early stopping\n",
      "18/18 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 26ms/step - loss: 5.3549 - mse: 3.2481 - val_loss: 1.6691 - val_mse: 1.0984\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.8920 - mse: 2.5853 - val_loss: 1.2345 - val_mse: 1.0813\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.6497 - mse: 2.5504 - val_loss: 1.1379 - val_mse: 1.0778\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.5420 - mse: 2.4999 - val_loss: 1.0448 - val_mse: 1.0162\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.4398 - mse: 2.4194 - val_loss: 1.0695 - val_mse: 1.0548\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.4306 - mse: 2.4191 - val_loss: 1.0528 - val_mse: 1.0441\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.3117 - mse: 2.3050 - val_loss: 1.0323 - val_mse: 1.0269\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.2551 - mse: 2.2504 - val_loss: 1.0631 - val_mse: 1.0590\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.1734 - mse: 2.1696 - val_loss: 1.0775 - val_mse: 1.0741\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.0458 - mse: 2.0426 - val_loss: 1.1080 - val_mse: 1.1050\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.0191 - mse: 2.0155 - val_loss: 1.0866 - val_mse: 1.0796\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.8945 - mse: 1.8811 - val_loss: 1.1138 - val_mse: 1.1046\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.7372 - mse: 1.7319 - val_loss: 1.1398 - val_mse: 1.1364\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.7025 - mse: 1.6994 - val_loss: 1.1681 - val_mse: 1.1651\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.6639 - mse: 1.6609 - val_loss: 1.0969 - val_mse: 1.0939\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.5366 - mse: 1.5336 - val_loss: 1.0981 - val_mse: 1.0952\n",
      "Epoch 17/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 1.4324 - mse: 1.4293Restoring model weights from the end of the best epoch: 7.\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.4215 - mse: 1.4185 - val_loss: 1.0905 - val_mse: 1.0875\n",
      "Epoch 17: early stopping\n",
      "18/18 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 28ms/step - loss: 4.9820 - mse: 3.1302 - val_loss: 1.7431 - val_mse: 1.2144\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.8863 - mse: 2.5975 - val_loss: 1.2218 - val_mse: 1.0715\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.6181 - mse: 2.5161 - val_loss: 1.1431 - val_mse: 1.0744\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5446 - mse: 2.4909 - val_loss: 1.0855 - val_mse: 1.0430\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 2.4094 - mse: 2.3724 - val_loss: 1.1296 - val_mse: 1.0967\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.3410 - mse: 2.3101 - val_loss: 1.1288 - val_mse: 1.0993\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 2.3834 - mse: 2.3545 - val_loss: 1.1194 - val_mse: 1.0910\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.2642 - mse: 2.2359 - val_loss: 1.1032 - val_mse: 1.0750\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 2.1283 - mse: 2.0999 - val_loss: 1.1561 - val_mse: 1.1276\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 2.0650 - mse: 2.0363 - val_loss: 1.1120 - val_mse: 1.0832\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.9541 - mse: 1.9251 - val_loss: 1.1216 - val_mse: 1.0923\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.8650 - mse: 1.8353 - val_loss: 1.0964 - val_mse: 1.0664\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.8396 - mse: 1.8093 - val_loss: 1.1068 - val_mse: 1.0761\n",
      "Epoch 14/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 1.7275 - mse: 1.6965Restoring model weights from the end of the best epoch: 4.\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.7159 - mse: 1.6849 - val_loss: 1.1378 - val_mse: 1.1065\n",
      "Epoch 14: early stopping\n",
      "18/18 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 4s 27ms/step - loss: 4.4135 - mse: 3.2831 - val_loss: 1.9529 - val_mse: 1.1614\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 3.2996 - mse: 2.6413 - val_loss: 1.6198 - val_mse: 1.0661\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 3.0543 - mse: 2.5660 - val_loss: 1.5117 - val_mse: 1.0786\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.9321 - mse: 2.5355 - val_loss: 1.4358 - val_mse: 1.0717\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.8454 - mse: 2.5058 - val_loss: 1.3812 - val_mse: 1.0638\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.7901 - mse: 2.4900 - val_loss: 1.3361 - val_mse: 1.0528\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.7054 - mse: 2.4321 - val_loss: 1.2946 - val_mse: 1.0314\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.6677 - mse: 2.4138 - val_loss: 1.2934 - val_mse: 1.0491\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5847 - mse: 2.3467 - val_loss: 1.2657 - val_mse: 1.0335\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5739 - mse: 2.3491 - val_loss: 1.3512 - val_mse: 1.1323\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5008 - mse: 2.2817 - val_loss: 1.2971 - val_mse: 1.0809\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5069 - mse: 2.2945 - val_loss: 1.2858 - val_mse: 1.0739\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5102 - mse: 2.2991 - val_loss: 1.2756 - val_mse: 1.0671\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5287 - mse: 2.3232 - val_loss: 1.2280 - val_mse: 1.0258\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.3768 - mse: 2.1770 - val_loss: 1.2432 - val_mse: 1.0447\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3256 - mse: 2.1304 - val_loss: 1.2198 - val_mse: 1.0277\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.3287 - mse: 2.1391 - val_loss: 1.2711 - val_mse: 1.0838\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.3224 - mse: 2.1343 - val_loss: 1.2634 - val_mse: 1.0759\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.3093 - mse: 2.1207 - val_loss: 1.2815 - val_mse: 1.0920\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.3203 - mse: 2.1283 - val_loss: 1.2328 - val_mse: 1.0392\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.2198 - mse: 2.0272 - val_loss: 1.2276 - val_mse: 1.0354\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.1619 - mse: 1.9676 - val_loss: 1.2586 - val_mse: 1.0631\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.2783 - mse: 2.0772 - val_loss: 1.2501 - val_mse: 1.0477\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.1415 - mse: 1.9387 - val_loss: 1.2289 - val_mse: 1.0251\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.0732 - mse: 1.8710 - val_loss: 1.3261 - val_mse: 1.1247\n",
      "Epoch 26/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 2.0527 - mse: 1.8500Restoring model weights from the end of the best epoch: 16.\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.0329 - mse: 1.8302 - val_loss: 1.2807 - val_mse: 1.0771\n",
      "Epoch 26: early stopping\n",
      "18/18 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 4s 29ms/step - loss: 3.3366 - mse: 3.1628 - val_loss: 1.2235 - val_mse: 1.0858\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.7338 - mse: 2.6156 - val_loss: 1.1716 - val_mse: 1.0690\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.6565 - mse: 2.5640 - val_loss: 1.1056 - val_mse: 1.0217\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5633 - mse: 2.4851 - val_loss: 1.1020 - val_mse: 1.0292\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4421 - mse: 2.3736 - val_loss: 1.0910 - val_mse: 1.0263\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3652 - mse: 2.3034 - val_loss: 1.1428 - val_mse: 1.0838\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.3925 - mse: 2.3352 - val_loss: 1.1442 - val_mse: 1.0886\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3091 - mse: 2.2546 - val_loss: 1.0889 - val_mse: 1.0359\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.2067 - mse: 2.1549 - val_loss: 1.1235 - val_mse: 1.0719\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1977 - mse: 2.1468 - val_loss: 1.1410 - val_mse: 1.0912\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.0053 - mse: 1.9563 - val_loss: 1.1117 - val_mse: 1.0635\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.9627 - mse: 1.9149 - val_loss: 1.0981 - val_mse: 1.0508\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.7532 - mse: 1.7063 - val_loss: 1.1476 - val_mse: 1.1011\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.6770 - mse: 1.6306 - val_loss: 1.1414 - val_mse: 1.0948\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.6497 - mse: 1.6029 - val_loss: 1.1434 - val_mse: 1.0965\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.5287 - mse: 1.4822 - val_loss: 1.1702 - val_mse: 1.1237\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.4842 - mse: 1.4376 - val_loss: 1.1710 - val_mse: 1.1242\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 1.3948 - mse: 1.3480Restoring model weights from the end of the best epoch: 8.\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.3948 - mse: 1.3480 - val_loss: 1.1258 - val_mse: 1.0786\n",
      "Epoch 18: early stopping\n",
      "18/18 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 27ms/step - loss: 3.5287 - mse: 3.0893 - val_loss: 1.3512 - val_mse: 1.1185\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.7422 - mse: 2.5752 - val_loss: 1.2099 - val_mse: 1.0895\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.6316 - mse: 2.5358 - val_loss: 1.1608 - val_mse: 1.0851\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.4759 - mse: 2.4131 - val_loss: 1.1378 - val_mse: 1.0865\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.5164 - mse: 2.4726 - val_loss: 1.0750 - val_mse: 1.0381\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.3490 - mse: 2.3172 - val_loss: 1.0578 - val_mse: 1.0306\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.3094 - mse: 2.2854 - val_loss: 1.0706 - val_mse: 1.0493\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.1928 - mse: 2.1741 - val_loss: 1.0990 - val_mse: 1.0827\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.1171 - mse: 2.1025 - val_loss: 1.0969 - val_mse: 1.0838\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.0064 - mse: 1.9946 - val_loss: 1.0548 - val_mse: 1.0442\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.8825 - mse: 1.8728 - val_loss: 1.1563 - val_mse: 1.1474\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.7578 - mse: 1.7497 - val_loss: 1.0746 - val_mse: 1.0672\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 1.6903 - mse: 1.6834 - val_loss: 1.0119 - val_mse: 1.0055\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.5736 - mse: 1.5676 - val_loss: 1.0484 - val_mse: 1.0428\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.4633 - mse: 1.4581 - val_loss: 1.0870 - val_mse: 1.0821\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.3424 - mse: 1.3377 - val_loss: 1.0682 - val_mse: 1.0637\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.2714 - mse: 1.2671 - val_loss: 1.1212 - val_mse: 1.1172\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 1.2847 - mse: 1.2809 - val_loss: 1.1231 - val_mse: 1.1194\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.1642 - mse: 1.1606 - val_loss: 1.1242 - val_mse: 1.1207\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.0475 - mse: 1.0442 - val_loss: 1.1225 - val_mse: 1.1193\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 0.9933 - mse: 0.9901 - val_loss: 1.1554 - val_mse: 1.1523\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 0.9122 - mse: 0.9064 - val_loss: 1.1361 - val_mse: 1.1133\n",
      "Epoch 23/1000\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.8876 - mse: 0.8739Restoring model weights from the end of the best epoch: 13.\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 0.8725 - mse: 0.8590 - val_loss: 1.2300 - val_mse: 1.2234\n",
      "Epoch 23: early stopping\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 4s 27ms/step - loss: 3.0504 - mse: 3.0412 - val_loss: 1.1054 - val_mse: 1.0962\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.6234 - mse: 2.6143 - val_loss: 1.1169 - val_mse: 1.1079\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5145 - mse: 2.5055 - val_loss: 1.0679 - val_mse: 1.0589\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4979 - mse: 2.4889 - val_loss: 1.0425 - val_mse: 1.0336\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.4271 - mse: 2.4182 - val_loss: 1.1096 - val_mse: 1.1007\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.3529 - mse: 2.3440 - val_loss: 1.1436 - val_mse: 1.1347\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.3223 - mse: 2.3133 - val_loss: 1.0613 - val_mse: 1.0522\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.2948 - mse: 2.2857 - val_loss: 1.0662 - val_mse: 1.0570\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.1338 - mse: 2.1245 - val_loss: 1.0738 - val_mse: 1.0645\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.9896 - mse: 1.9802 - val_loss: 1.0776 - val_mse: 1.0681\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.8831 - mse: 1.8736 - val_loss: 1.0731 - val_mse: 1.0634\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.7594 - mse: 1.7497 - val_loss: 1.1204 - val_mse: 1.1106\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.7073 - mse: 1.6973 - val_loss: 1.1475 - val_mse: 1.1374\n",
      "Epoch 14/1000\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 1.6514 - mse: 1.6412Restoring model weights from the end of the best epoch: 4.\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.6455 - mse: 1.6353 - val_loss: 1.1172 - val_mse: 1.1069\n",
      "Epoch 14: early stopping\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 30ms/step - loss: 3.4615 - mse: 3.0346 - val_loss: 1.3095 - val_mse: 1.0836\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.7833 - mse: 2.6207 - val_loss: 1.2877 - val_mse: 1.1702\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.6235 - mse: 2.5299 - val_loss: 1.1409 - val_mse: 1.0668\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.5276 - mse: 2.4653 - val_loss: 1.1126 - val_mse: 1.0606\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.5059 - mse: 2.4610 - val_loss: 1.1058 - val_mse: 1.0669\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.3992 - mse: 2.3647 - val_loss: 1.0813 - val_mse: 1.0508\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.3159 - mse: 2.2880 - val_loss: 1.0799 - val_mse: 1.0541\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.2422 - mse: 2.2182 - val_loss: 1.0817 - val_mse: 1.0594\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.1260 - mse: 2.1049 - val_loss: 1.0684 - val_mse: 1.0484\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.0417 - mse: 2.0225 - val_loss: 1.1381 - val_mse: 1.1197\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.0167 - mse: 1.9987 - val_loss: 1.0808 - val_mse: 1.0631\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.8942 - mse: 1.8767 - val_loss: 1.0783 - val_mse: 1.0606\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.7996 - mse: 1.7784 - val_loss: 1.2068 - val_mse: 1.1704\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.6949 - mse: 1.6630 - val_loss: 1.2065 - val_mse: 1.1809\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.5493 - mse: 1.5268 - val_loss: 1.1498 - val_mse: 1.1295\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.4576 - mse: 1.4383 - val_loss: 1.1521 - val_mse: 1.1336\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.3158 - mse: 1.2978 - val_loss: 1.1420 - val_mse: 1.1242\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.2733 - mse: 1.2558 - val_loss: 1.1795 - val_mse: 1.1622\n",
      "Epoch 19/1000\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 1.1929 - mse: 1.1756Restoring model weights from the end of the best epoch: 9.\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.1978 - mse: 1.1806 - val_loss: 1.1920 - val_mse: 1.1747\n",
      "Epoch 19: early stopping\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 32ms/step - loss: 3.2425 - mse: 3.1351 - val_loss: 1.2292 - val_mse: 1.1360\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.6594 - mse: 2.5749 - val_loss: 1.1541 - val_mse: 1.0771\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5755 - mse: 2.5036 - val_loss: 1.0849 - val_mse: 1.0177\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5473 - mse: 2.4834 - val_loss: 1.1835 - val_mse: 1.1227\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 2.4450 - mse: 2.3866 - val_loss: 1.0964 - val_mse: 1.0403\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 2.4198 - mse: 2.3653 - val_loss: 1.0953 - val_mse: 1.0424\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 2.2941 - mse: 2.2423 - val_loss: 1.1541 - val_mse: 1.1035\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 2.2184 - mse: 2.1687 - val_loss: 1.1704 - val_mse: 1.1214\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 2.0626 - mse: 2.0144 - val_loss: 1.1376 - val_mse: 1.0902\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.9471 - mse: 1.9001 - val_loss: 1.1330 - val_mse: 1.0863\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.7848 - mse: 1.7385 - val_loss: 1.1725 - val_mse: 1.1263\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.7875 - mse: 1.7413 - val_loss: 1.1279 - val_mse: 1.0819\n",
      "Epoch 13/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 1.6725 - mse: 1.6263Restoring model weights from the end of the best epoch: 3.\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.6557 - mse: 1.6095 - val_loss: 1.1460 - val_mse: 1.0993\n",
      "Epoch 13: early stopping\n",
      "18/18 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 4s 28ms/step - loss: 3.9910 - mse: 3.0475 - val_loss: 1.6617 - val_mse: 1.0693\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 3.0627 - mse: 2.5895 - val_loss: 1.4564 - val_mse: 1.0713\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.8773 - mse: 2.5414 - val_loss: 1.3369 - val_mse: 1.0415\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.7434 - mse: 2.4746 - val_loss: 1.3195 - val_mse: 1.0740\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.7053 - mse: 2.4763 - val_loss: 1.2783 - val_mse: 1.0628\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5874 - mse: 2.3817 - val_loss: 1.3169 - val_mse: 1.1199\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5533 - mse: 2.3623 - val_loss: 1.2801 - val_mse: 1.0937\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.4847 - mse: 2.3020 - val_loss: 1.3326 - val_mse: 1.1531\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.4295 - mse: 2.2509 - val_loss: 1.2259 - val_mse: 1.0478\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.3528 - mse: 2.1762 - val_loss: 1.2270 - val_mse: 1.0520\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.2793 - mse: 2.1048 - val_loss: 1.2450 - val_mse: 1.0713\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1653 - mse: 1.9925 - val_loss: 1.2412 - val_mse: 1.0694\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.0492 - mse: 1.8763 - val_loss: 1.2283 - val_mse: 1.0544\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 2.0215 - mse: 1.8476 - val_loss: 1.2337 - val_mse: 1.0591\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.0711 - mse: 1.8954 - val_loss: 1.2698 - val_mse: 1.0914\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.9457 - mse: 1.7664 - val_loss: 1.2449 - val_mse: 1.0658\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.7967 - mse: 1.6176 - val_loss: 1.2340 - val_mse: 1.0551\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.7410 - mse: 1.5619 - val_loss: 1.2737 - val_mse: 1.0915\n",
      "Epoch 19/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 1.6616 - mse: 1.4768Restoring model weights from the end of the best epoch: 9.\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.6523 - mse: 1.4676 - val_loss: 1.2829 - val_mse: 1.1021\n",
      "Epoch 19: early stopping\n",
      "18/18 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 4s 27ms/step - loss: 3.7037 - mse: 3.1498 - val_loss: 1.5603 - val_mse: 1.1242\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.9662 - mse: 2.5892 - val_loss: 1.4080 - val_mse: 1.0783\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.8545 - mse: 2.5513 - val_loss: 1.3827 - val_mse: 1.1036\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.7387 - mse: 2.4745 - val_loss: 1.3169 - val_mse: 1.0667\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.7315 - mse: 2.4935 - val_loss: 1.3340 - val_mse: 1.1061\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.6858 - mse: 2.4639 - val_loss: 1.2669 - val_mse: 1.0520\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5886 - mse: 2.3795 - val_loss: 1.2263 - val_mse: 1.0236\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5958 - mse: 2.3949 - val_loss: 1.2827 - val_mse: 1.0845\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4799 - mse: 2.2833 - val_loss: 1.2117 - val_mse: 1.0170\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3599 - mse: 2.1692 - val_loss: 1.2276 - val_mse: 1.0400\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.3719 - mse: 2.1850 - val_loss: 1.2686 - val_mse: 1.0813\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3820 - mse: 2.1941 - val_loss: 1.2684 - val_mse: 1.0792\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3248 - mse: 2.1359 - val_loss: 1.3706 - val_mse: 1.1796\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.2084 - mse: 2.0158 - val_loss: 1.2288 - val_mse: 1.0360\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.1283 - mse: 1.9363 - val_loss: 1.2922 - val_mse: 1.0987\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.1045 - mse: 1.9076 - val_loss: 1.2789 - val_mse: 1.0803\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.9996 - mse: 1.8018 - val_loss: 1.2786 - val_mse: 1.0804\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 1.9004 - mse: 1.7031 - val_loss: 1.2620 - val_mse: 1.0641\n",
      "Epoch 19/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 1.8969 - mse: 1.6984Restoring model weights from the end of the best epoch: 9.\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.8849 - mse: 1.6864 - val_loss: 1.2704 - val_mse: 1.0711\n",
      "Epoch 19: early stopping\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 31ms/step - loss: 3.2165 - mse: 3.1330 - val_loss: 1.1676 - val_mse: 1.0982\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.6780 - mse: 2.6170 - val_loss: 1.1476 - val_mse: 1.0936\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.5327 - mse: 2.4834 - val_loss: 1.1009 - val_mse: 1.0560\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5046 - mse: 2.4627 - val_loss: 1.1367 - val_mse: 1.0975\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.4451 - mse: 2.4079 - val_loss: 1.1268 - val_mse: 1.0917\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3688 - mse: 2.3353 - val_loss: 1.0954 - val_mse: 1.0634\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.2513 - mse: 2.2206 - val_loss: 1.1048 - val_mse: 1.0753\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1984 - mse: 2.1697 - val_loss: 1.1056 - val_mse: 1.0775\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.0681 - mse: 2.0402 - val_loss: 1.1263 - val_mse: 1.0995\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.0156 - mse: 1.9894 - val_loss: 1.1021 - val_mse: 1.0762\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.8414 - mse: 1.8158 - val_loss: 1.0763 - val_mse: 1.0513\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.8251 - mse: 1.8007 - val_loss: 1.0877 - val_mse: 1.0636\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.7517 - mse: 1.7278 - val_loss: 1.1414 - val_mse: 1.1180\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.6041 - mse: 1.5812 - val_loss: 1.1320 - val_mse: 1.1097\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 1.4882 - mse: 1.4661 - val_loss: 1.1380 - val_mse: 1.1161\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.4436 - mse: 1.4217 - val_loss: 1.1140 - val_mse: 1.0921\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.3721 - mse: 1.3504 - val_loss: 1.1642 - val_mse: 1.1426\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.2257 - mse: 1.2043 - val_loss: 1.1697 - val_mse: 1.1484\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.1560 - mse: 1.1348 - val_loss: 1.1761 - val_mse: 1.1551\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.0880 - mse: 1.0670 - val_loss: 1.2595 - val_mse: 1.2385\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 1.0378 - mse: 1.0170Restoring model weights from the end of the best epoch: 11.\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.0378 - mse: 1.0170 - val_loss: 1.2216 - val_mse: 1.2007\n",
      "Epoch 21: early stopping\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 30ms/step - loss: 5.5259 - mse: 3.0594 - val_loss: 2.0814 - val_mse: 1.1120\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 3.2824 - mse: 2.6061 - val_loss: 1.5296 - val_mse: 1.0402\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.9714 - mse: 2.5587 - val_loss: 1.4060 - val_mse: 1.0554\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.8020 - mse: 2.4901 - val_loss: 1.3224 - val_mse: 1.0415\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.6992 - mse: 2.4372 - val_loss: 1.3130 - val_mse: 1.0691\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.6808 - mse: 2.4466 - val_loss: 1.2753 - val_mse: 1.0506\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.5863 - mse: 2.3698 - val_loss: 1.2962 - val_mse: 1.0855\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.5561 - mse: 2.3499 - val_loss: 1.2485 - val_mse: 1.0460\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4958 - mse: 2.2977 - val_loss: 1.3389 - val_mse: 1.1448\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.4742 - mse: 2.2810 - val_loss: 1.2381 - val_mse: 1.0451\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3582 - mse: 2.1646 - val_loss: 1.2598 - val_mse: 1.0693\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3572 - mse: 2.1696 - val_loss: 1.2239 - val_mse: 1.0382\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.2550 - mse: 2.0712 - val_loss: 1.2482 - val_mse: 1.0651\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.1931 - mse: 2.0091 - val_loss: 1.2187 - val_mse: 1.0368\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1844 - mse: 2.0022 - val_loss: 1.3384 - val_mse: 1.1570\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.1318 - mse: 1.9481 - val_loss: 1.2503 - val_mse: 1.0641\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1355 - mse: 1.9465 - val_loss: 1.3840 - val_mse: 1.1925\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.0158 - mse: 1.8240 - val_loss: 1.3051 - val_mse: 1.1130\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.0035 - mse: 1.8098 - val_loss: 1.2780 - val_mse: 1.0843\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.9657 - mse: 1.7694 - val_loss: 1.2783 - val_mse: 1.0813\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.8572 - mse: 1.6600 - val_loss: 1.2721 - val_mse: 1.0760\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.8256 - mse: 1.6278 - val_loss: 1.2730 - val_mse: 1.0734\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.7302 - mse: 1.5300 - val_loss: 1.2998 - val_mse: 1.0998\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 1.6560 - mse: 1.4561Restoring model weights from the end of the best epoch: 14.\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.6560 - mse: 1.4561 - val_loss: 1.2767 - val_mse: 1.0760\n",
      "Epoch 24: early stopping\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 31ms/step - loss: 3.6003 - mse: 3.2622 - val_loss: 1.3705 - val_mse: 1.1652\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.7783 - mse: 2.6228 - val_loss: 1.1423 - val_mse: 1.0239\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.6104 - mse: 2.5130 - val_loss: 1.1286 - val_mse: 1.0489\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.5477 - mse: 2.4797 - val_loss: 1.0678 - val_mse: 1.0102\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.4915 - mse: 2.4413 - val_loss: 1.1147 - val_mse: 1.0712\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.4439 - mse: 2.4052 - val_loss: 1.0762 - val_mse: 1.0420\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.3988 - mse: 2.3677 - val_loss: 1.0666 - val_mse: 1.0388\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.3853 - mse: 2.3599 - val_loss: 1.1099 - val_mse: 1.0868\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.2502 - mse: 2.2291 - val_loss: 1.0671 - val_mse: 1.0479\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.1846 - mse: 2.1613 - val_loss: 1.1303 - val_mse: 1.0897\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.1930 - mse: 2.1592 - val_loss: 1.0714 - val_mse: 1.0460\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.0926 - mse: 2.0700 - val_loss: 1.0900 - val_mse: 1.0708\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 1.9751 - mse: 1.9583 - val_loss: 1.1329 - val_mse: 1.1181\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.8717 - mse: 1.8583 - val_loss: 1.1319 - val_mse: 1.1196\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.9820 - mse: 1.9705 - val_loss: 1.1149 - val_mse: 1.1042\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 1.8951 - mse: 1.8850 - val_loss: 1.1375 - val_mse: 1.1279\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 1.7646 - mse: 1.7554 - val_loss: 1.0563 - val_mse: 1.0474\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 1.7008 - mse: 1.6923 - val_loss: 1.0959 - val_mse: 1.0876\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 1.5622 - mse: 1.5542 - val_loss: 1.1078 - val_mse: 1.1000\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 1.4661 - mse: 1.4585 - val_loss: 1.0778 - val_mse: 1.0703\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.4259 - mse: 1.4185 - val_loss: 1.0717 - val_mse: 1.0644\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 1.3554 - mse: 1.3482 - val_loss: 1.1409 - val_mse: 1.1338\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.3359 - mse: 1.3288 - val_loss: 1.1300 - val_mse: 1.1230\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.2814 - mse: 1.2745 - val_loss: 1.1124 - val_mse: 1.1055\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 1.2583 - mse: 1.2514 - val_loss: 1.1736 - val_mse: 1.1667\n",
      "Epoch 26/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.2520 - mse: 1.2451 - val_loss: 1.0944 - val_mse: 1.0875\n",
      "Epoch 27/1000\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 1.1676 - mse: 1.1607Restoring model weights from the end of the best epoch: 17.\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 1.1702 - mse: 1.1633 - val_loss: 1.1250 - val_mse: 1.1181\n",
      "Epoch 27: early stopping\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 37ms/step - loss: 3.4625 - mse: 3.2855 - val_loss: 1.2865 - val_mse: 1.1205\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.8197 - mse: 2.6595 - val_loss: 1.2344 - val_mse: 1.0792\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.7007 - mse: 2.5497 - val_loss: 1.2296 - val_mse: 1.0826\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.6613 - mse: 2.5173 - val_loss: 1.2456 - val_mse: 1.1046\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.6007 - mse: 2.4619 - val_loss: 1.1668 - val_mse: 1.0303\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5541 - mse: 2.4194 - val_loss: 1.1481 - val_mse: 1.0150\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5184 - mse: 2.3861 - val_loss: 1.1441 - val_mse: 1.0131\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.4958 - mse: 2.3655 - val_loss: 1.2029 - val_mse: 1.0732\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4347 - mse: 2.3063 - val_loss: 1.2800 - val_mse: 1.1522\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4211 - mse: 2.2930 - val_loss: 1.1899 - val_mse: 1.0617\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3662 - mse: 2.2384 - val_loss: 1.1944 - val_mse: 1.0668\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3444 - mse: 2.2162 - val_loss: 1.2377 - val_mse: 1.1093\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.2680 - mse: 2.1392 - val_loss: 1.1943 - val_mse: 1.0653\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.1642 - mse: 2.0353 - val_loss: 1.2081 - val_mse: 1.0793\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.1173 - mse: 1.9880 - val_loss: 1.1961 - val_mse: 1.0659\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.0945 - mse: 1.9643 - val_loss: 1.2081 - val_mse: 1.0776\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 2.0069 - mse: 1.8758Restoring model weights from the end of the best epoch: 7.\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.0069 - mse: 1.8758 - val_loss: 1.2126 - val_mse: 1.0809\n",
      "Epoch 17: early stopping\n",
      "18/18 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 4s 29ms/step - loss: 3.5415 - mse: 3.1426 - val_loss: 1.4175 - val_mse: 1.0738\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.9365 - mse: 2.6272 - val_loss: 1.3367 - val_mse: 1.0568\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.7933 - mse: 2.5331 - val_loss: 1.3069 - val_mse: 1.0644\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.7101 - mse: 2.4796 - val_loss: 1.2868 - val_mse: 1.0689\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.6146 - mse: 2.4059 - val_loss: 1.2798 - val_mse: 1.0798\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.5903 - mse: 2.3964 - val_loss: 1.2744 - val_mse: 1.0866\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5190 - mse: 2.3353 - val_loss: 1.2232 - val_mse: 1.0437\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4346 - mse: 2.2575 - val_loss: 1.2463 - val_mse: 1.0712\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3406 - mse: 2.1672 - val_loss: 1.2387 - val_mse: 1.0667\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.3378 - mse: 2.1666 - val_loss: 1.2542 - val_mse: 1.0834\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.2980 - mse: 2.1281 - val_loss: 1.2456 - val_mse: 1.0768\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1755 - mse: 2.0058 - val_loss: 1.2049 - val_mse: 1.0361\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1006 - mse: 1.9319 - val_loss: 1.2438 - val_mse: 1.0762\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.0577 - mse: 1.8885 - val_loss: 1.2833 - val_mse: 1.1135\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.9346 - mse: 1.7654 - val_loss: 1.2747 - val_mse: 1.1051\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.7624 - mse: 1.5925 - val_loss: 1.2566 - val_mse: 1.0868\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.7414 - mse: 1.5721 - val_loss: 1.2365 - val_mse: 1.0668\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.6865 - mse: 1.5158 - val_loss: 1.3218 - val_mse: 1.1505\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.5740 - mse: 1.4018 - val_loss: 1.2460 - val_mse: 1.0734\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.5341 - mse: 1.3609 - val_loss: 1.3578 - val_mse: 1.1833\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.4548 - mse: 1.2804 - val_loss: 1.2643 - val_mse: 1.0898\n",
      "Epoch 22/1000\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 1.3871 - mse: 1.2126Restoring model weights from the end of the best epoch: 12.\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.3643 - mse: 1.1898 - val_loss: 1.2756 - val_mse: 1.1016\n",
      "Epoch 22: early stopping\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 28ms/step - loss: 7.7909 - mse: 3.0810 - val_loss: 1.7059 - val_mse: 1.0596\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.8329 - mse: 2.5845 - val_loss: 1.1109 - val_mse: 1.0415\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.5654 - mse: 2.5305 - val_loss: 1.0627 - val_mse: 1.0464\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4820 - mse: 2.4719 - val_loss: 1.0597 - val_mse: 1.0532\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5087 - mse: 2.5032 - val_loss: 1.0528 - val_mse: 1.0478\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.4136 - mse: 2.4088 - val_loss: 1.0281 - val_mse: 1.0234\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.2996 - mse: 2.2949 - val_loss: 1.0936 - val_mse: 1.0889\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.2649 - mse: 2.2601 - val_loss: 1.0749 - val_mse: 1.0700\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1722 - mse: 2.1673 - val_loss: 1.0748 - val_mse: 1.0699\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1079 - mse: 2.1029 - val_loss: 1.0953 - val_mse: 1.0903\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.0260 - mse: 2.0209 - val_loss: 1.0591 - val_mse: 1.0540\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.9020 - mse: 1.8967 - val_loss: 1.0927 - val_mse: 1.0874\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.9301 - mse: 1.9247 - val_loss: 1.0624 - val_mse: 1.0569\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.7910 - mse: 1.7854 - val_loss: 1.0898 - val_mse: 1.0842\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.6926 - mse: 1.6869 - val_loss: 1.0750 - val_mse: 1.0692\n",
      "Epoch 16/1000\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 1.5796 - mse: 1.5737Restoring model weights from the end of the best epoch: 6.\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.5853 - mse: 1.5793 - val_loss: 1.1012 - val_mse: 1.0952\n",
      "Epoch 16: early stopping\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 29ms/step - loss: 4.2742 - mse: 3.3401 - val_loss: 1.7614 - val_mse: 1.0928\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 3.1975 - mse: 2.6440 - val_loss: 1.5545 - val_mse: 1.0898\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 3.0026 - mse: 2.5898 - val_loss: 1.4979 - val_mse: 1.1315\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.8932 - mse: 2.5555 - val_loss: 1.4099 - val_mse: 1.0980\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.7905 - mse: 2.4958 - val_loss: 1.3425 - val_mse: 1.0658\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.7557 - mse: 2.4934 - val_loss: 1.3256 - val_mse: 1.0749\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.7013 - mse: 2.4589 - val_loss: 1.2895 - val_mse: 1.0545\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.6355 - mse: 2.4064 - val_loss: 1.2607 - val_mse: 1.0367\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.6035 - mse: 2.3832 - val_loss: 1.2798 - val_mse: 1.0624\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.5489 - mse: 2.3356 - val_loss: 1.2330 - val_mse: 1.0235\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5261 - mse: 2.3179 - val_loss: 1.2555 - val_mse: 1.0477\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4907 - mse: 2.2855 - val_loss: 1.2459 - val_mse: 1.0419\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.4372 - mse: 2.2360 - val_loss: 1.2381 - val_mse: 1.0398\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4315 - mse: 2.2339 - val_loss: 1.2638 - val_mse: 1.0672\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3929 - mse: 2.1986 - val_loss: 1.3067 - val_mse: 1.1117\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.3808 - mse: 2.1877 - val_loss: 1.2671 - val_mse: 1.0761\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.3012 - mse: 2.1126 - val_loss: 1.2807 - val_mse: 1.0958\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.2974 - mse: 2.1134 - val_loss: 1.2830 - val_mse: 1.0987\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.2221 - mse: 2.0375 - val_loss: 1.2548 - val_mse: 1.0712\n",
      "Epoch 20/1000\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 2.2227 - mse: 2.0407Restoring model weights from the end of the best epoch: 10.\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.1946 - mse: 2.0126 - val_loss: 1.2330 - val_mse: 1.0506\n",
      "Epoch 20: early stopping\n",
      "18/18 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 27ms/step - loss: 3.5019 - mse: 3.0912 - val_loss: 1.3421 - val_mse: 1.0883\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.7873 - mse: 2.5891 - val_loss: 1.2374 - val_mse: 1.0797\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.6693 - mse: 2.5337 - val_loss: 1.1615 - val_mse: 1.0446\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.5431 - mse: 2.4387 - val_loss: 1.1373 - val_mse: 1.0439\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.4998 - mse: 2.4138 - val_loss: 1.1563 - val_mse: 1.0772\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4009 - mse: 2.3265 - val_loss: 1.1382 - val_mse: 1.0682\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.4165 - mse: 2.3495 - val_loss: 1.1360 - val_mse: 1.0717\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.3343 - mse: 2.2717 - val_loss: 1.1399 - val_mse: 1.0793\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.1792 - mse: 2.1201 - val_loss: 1.1105 - val_mse: 1.0528\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1449 - mse: 2.0883 - val_loss: 1.1774 - val_mse: 1.1214\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 2.0363 - mse: 1.9806 - val_loss: 1.1262 - val_mse: 1.0705\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.9860 - mse: 1.9307 - val_loss: 1.1673 - val_mse: 1.1123\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.8389 - mse: 1.7841 - val_loss: 1.1134 - val_mse: 1.0589\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.7969 - mse: 1.7423 - val_loss: 1.2023 - val_mse: 1.1472\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.6904 - mse: 1.6337 - val_loss: 1.2252 - val_mse: 1.1665\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.6007 - mse: 1.5429 - val_loss: 1.2118 - val_mse: 1.1543\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.5206 - mse: 1.4630 - val_loss: 1.1930 - val_mse: 1.1349\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.4423 - mse: 1.3835 - val_loss: 1.1706 - val_mse: 1.1122\n",
      "Epoch 19/1000\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 1.3498 - mse: 1.2913Restoring model weights from the end of the best epoch: 9.\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.3347 - mse: 1.2762 - val_loss: 1.1998 - val_mse: 1.1410\n",
      "Epoch 19: early stopping\n",
      "18/18 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 4s 29ms/step - loss: 3.0124 - mse: 3.0070 - val_loss: 1.1836 - val_mse: 1.1783\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.6070 - mse: 2.6019 - val_loss: 1.0599 - val_mse: 1.0549\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.5400 - mse: 2.5351 - val_loss: 1.1206 - val_mse: 1.1159\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.4925 - mse: 2.4878 - val_loss: 1.0480 - val_mse: 1.0435\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.3901 - mse: 2.3856 - val_loss: 1.1040 - val_mse: 1.0996\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.2977 - mse: 2.2933 - val_loss: 1.1148 - val_mse: 1.1105\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.2207 - mse: 2.2164 - val_loss: 1.1125 - val_mse: 1.1083\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.0896 - mse: 2.0855 - val_loss: 1.0704 - val_mse: 1.0663\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.0558 - mse: 2.0518 - val_loss: 1.0604 - val_mse: 1.0563\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.9921 - mse: 1.9881 - val_loss: 1.1103 - val_mse: 1.1063\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.8635 - mse: 1.8594 - val_loss: 1.0570 - val_mse: 1.0530\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.7674 - mse: 1.7634 - val_loss: 1.1490 - val_mse: 1.1450\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.6713 - mse: 1.6673 - val_loss: 1.1395 - val_mse: 1.1355\n",
      "Epoch 14/1000\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 1.5200 - mse: 1.5160Restoring model weights from the end of the best epoch: 4.\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.5288 - mse: 1.5249 - val_loss: 1.0883 - val_mse: 1.0843\n",
      "Epoch 14: early stopping\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 34ms/step - loss: 3.2233 - mse: 3.1905 - val_loss: 1.1134 - val_mse: 1.0840\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.6777 - mse: 2.6508 - val_loss: 1.1100 - val_mse: 1.0853\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.5579 - mse: 2.5349 - val_loss: 1.0671 - val_mse: 1.0456\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.5051 - mse: 2.4849 - val_loss: 1.1024 - val_mse: 1.0834\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.4609 - mse: 2.4427 - val_loss: 1.1124 - val_mse: 1.0953\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.4045 - mse: 2.3881 - val_loss: 1.1038 - val_mse: 1.0882\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.2773 - mse: 2.2622 - val_loss: 1.0509 - val_mse: 1.0365\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.1823 - mse: 2.1685 - val_loss: 1.0982 - val_mse: 1.0848\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 2.1479 - mse: 2.1348 - val_loss: 1.0719 - val_mse: 1.0591\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.0744 - mse: 2.0621 - val_loss: 1.0947 - val_mse: 1.0828\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.9866 - mse: 1.9750 - val_loss: 1.0990 - val_mse: 1.0876\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 1.8429 - mse: 1.8316 - val_loss: 1.1035 - val_mse: 1.0925\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.8470 - mse: 1.8361 - val_loss: 1.0548 - val_mse: 1.0440\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 1.6503 - mse: 1.6396 - val_loss: 1.1429 - val_mse: 1.1323\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 1.5582 - mse: 1.5478 - val_loss: 1.0871 - val_mse: 1.0769\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 1.4799 - mse: 1.4698 - val_loss: 1.0971 - val_mse: 1.0872\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 1.3722 - mse: 1.3622Restoring model weights from the end of the best epoch: 7.\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 1.3722 - mse: 1.3622 - val_loss: 1.1256 - val_mse: 1.1153\n",
      "Epoch 17: early stopping\n",
      "18/18 [==============================] - 1s 12ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 6s 35ms/step - loss: 3.4468 - mse: 3.1530 - val_loss: 1.2849 - val_mse: 1.0906\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.7370 - mse: 2.5837 - val_loss: 1.1849 - val_mse: 1.0628\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.6000 - mse: 2.4960 - val_loss: 1.1529 - val_mse: 1.0643\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.5205 - mse: 2.4426 - val_loss: 1.1267 - val_mse: 1.0583\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.4647 - mse: 2.4027 - val_loss: 1.0941 - val_mse: 1.0382\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.3778 - mse: 2.3265 - val_loss: 1.0812 - val_mse: 1.0342\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.2942 - mse: 2.2503 - val_loss: 1.1003 - val_mse: 1.0592\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.2413 - mse: 2.2023 - val_loss: 1.1318 - val_mse: 1.0948\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.1732 - mse: 2.1378 - val_loss: 1.0882 - val_mse: 1.0543\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.0990 - mse: 2.0640 - val_loss: 1.1244 - val_mse: 1.0846\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.9953 - mse: 1.9591 - val_loss: 1.1411 - val_mse: 1.1082\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.9391 - mse: 1.9077 - val_loss: 1.0921 - val_mse: 1.0619\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.9120 - mse: 1.8823 - val_loss: 1.1742 - val_mse: 1.1450\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 1.7516 - mse: 1.7230 - val_loss: 1.1405 - val_mse: 1.1123\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 1.6628 - mse: 1.6347 - val_loss: 1.2059 - val_mse: 1.1781\n",
      "Epoch 16/1000\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 1.5852 - mse: 1.5577Restoring model weights from the end of the best epoch: 6.\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 1.5909 - mse: 1.5633 - val_loss: 1.0907 - val_mse: 1.0632\n",
      "Epoch 16: early stopping\n",
      "18/18 [==============================] - 1s 6ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 6s 35ms/step - loss: 3.2295 - mse: 3.1508 - val_loss: 1.1900 - val_mse: 1.1157\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 2.6826 - mse: 2.6117 - val_loss: 1.1300 - val_mse: 1.0621\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.6107 - mse: 2.5451 - val_loss: 1.1074 - val_mse: 1.0436\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.5247 - mse: 2.4624 - val_loss: 1.0957 - val_mse: 1.0348\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.5221 - mse: 2.4622 - val_loss: 1.1166 - val_mse: 1.0574\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.4124 - mse: 2.3538 - val_loss: 1.1666 - val_mse: 1.1084\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.3677 - mse: 2.3100 - val_loss: 1.2498 - val_mse: 1.1923\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.3332 - mse: 2.2758 - val_loss: 1.0971 - val_mse: 1.0397\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.2820 - mse: 2.2245 - val_loss: 1.1431 - val_mse: 1.0853\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.2134 - mse: 2.1556 - val_loss: 1.1112 - val_mse: 1.0536\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.1255 - mse: 2.0677 - val_loss: 1.1649 - val_mse: 1.1066\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.0704 - mse: 2.0118 - val_loss: 1.1447 - val_mse: 1.0858\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.0008 - mse: 1.9417 - val_loss: 1.1690 - val_mse: 1.1096\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 1.8809 - mse: 1.8212Restoring model weights from the end of the best epoch: 4.\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.8809 - mse: 1.8212 - val_loss: 1.2066 - val_mse: 1.1463\n",
      "Epoch 14: early stopping\n",
      "18/18 [==============================] - 1s 6ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 6s 37ms/step - loss: 4.9140 - mse: 3.2494 - val_loss: 2.1114 - val_mse: 1.1763\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 3.3104 - mse: 2.6075 - val_loss: 1.5748 - val_mse: 1.0518\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.9859 - mse: 2.5546 - val_loss: 1.4469 - val_mse: 1.0859\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.8555 - mse: 2.5377 - val_loss: 1.3543 - val_mse: 1.0758\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.7656 - mse: 2.5029 - val_loss: 1.2892 - val_mse: 1.0463\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.7345 - mse: 2.5043 - val_loss: 1.2906 - val_mse: 1.0731\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.6700 - mse: 2.4633 - val_loss: 1.3162 - val_mse: 1.1163\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.6121 - mse: 2.4118 - val_loss: 1.2670 - val_mse: 1.0710\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.5645 - mse: 2.3697 - val_loss: 1.2223 - val_mse: 1.0341\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.5401 - mse: 2.3531 - val_loss: 1.2408 - val_mse: 1.0533\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.6439 - mse: 2.4514 - val_loss: 1.2701 - val_mse: 1.0746\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.4861 - mse: 2.2915 - val_loss: 1.2312 - val_mse: 1.0396\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.4282 - mse: 2.2408 - val_loss: 1.2499 - val_mse: 1.0644\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.4261 - mse: 2.2399 - val_loss: 1.3423 - val_mse: 1.1528\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.4193 - mse: 2.2294 - val_loss: 1.2679 - val_mse: 1.0822\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.3419 - mse: 2.1562 - val_loss: 1.2780 - val_mse: 1.0955\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.3002 - mse: 2.1153 - val_loss: 1.2378 - val_mse: 1.0550\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.2911 - mse: 2.1100 - val_loss: 1.2243 - val_mse: 1.0445\n",
      "Epoch 19/1000\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 2.2023 - mse: 2.0235Restoring model weights from the end of the best epoch: 9.\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.2523 - mse: 2.0736 - val_loss: 1.2727 - val_mse: 1.0954\n",
      "Epoch 19: early stopping\n",
      "18/18 [==============================] - 1s 5ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 6s 43ms/step - loss: 3.1841 - mse: 3.1782 - val_loss: 1.1094 - val_mse: 1.1037\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.6433 - mse: 2.6377 - val_loss: 1.0848 - val_mse: 1.0794\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.5562 - mse: 2.5509 - val_loss: 1.0647 - val_mse: 1.0595\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.4580 - mse: 2.4530 - val_loss: 1.0215 - val_mse: 1.0166\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.3944 - mse: 2.3895 - val_loss: 1.0543 - val_mse: 1.0496\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.3463 - mse: 2.3417 - val_loss: 1.0681 - val_mse: 1.0635\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.3253 - mse: 2.3207 - val_loss: 1.0784 - val_mse: 1.0739\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.2130 - mse: 2.2086 - val_loss: 1.0361 - val_mse: 1.0316\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.0949 - mse: 2.0905 - val_loss: 1.0539 - val_mse: 1.0495\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.0112 - mse: 2.0069 - val_loss: 1.0543 - val_mse: 1.0499\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.9429 - mse: 1.9386 - val_loss: 1.0759 - val_mse: 1.0715\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.8856 - mse: 1.8813 - val_loss: 1.0761 - val_mse: 1.0717\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.7882 - mse: 1.7838 - val_loss: 1.1111 - val_mse: 1.1067\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 1.6926 - mse: 1.6883Restoring model weights from the end of the best epoch: 4.\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.6926 - mse: 1.6883 - val_loss: 1.1062 - val_mse: 1.1018\n",
      "Epoch 14: early stopping\n",
      "18/18 [==============================] - 1s 7ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 6s 36ms/step - loss: 5.8851 - mse: 3.1462 - val_loss: 1.7540 - val_mse: 1.1626\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.8789 - mse: 2.5862 - val_loss: 1.2494 - val_mse: 1.1153\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.6005 - mse: 2.5112 - val_loss: 1.1120 - val_mse: 1.0517\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.5094 - mse: 2.4604 - val_loss: 1.1182 - val_mse: 1.0769\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.4295 - mse: 2.3912 - val_loss: 1.0746 - val_mse: 1.0384\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.3653 - mse: 2.3300 - val_loss: 1.0847 - val_mse: 1.0499\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.3438 - mse: 2.3090 - val_loss: 1.1461 - val_mse: 1.1112\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.2789 - mse: 2.2439 - val_loss: 1.1336 - val_mse: 1.0984\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.1703 - mse: 2.1348 - val_loss: 1.0824 - val_mse: 1.0467\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.1373 - mse: 2.1013 - val_loss: 1.1184 - val_mse: 1.0819\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.0308 - mse: 1.9938 - val_loss: 1.0934 - val_mse: 1.0560\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 1.9699 - mse: 1.9320 - val_loss: 1.1205 - val_mse: 1.0822\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 1.9210 - mse: 1.8823 - val_loss: 1.1373 - val_mse: 1.0981\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.7927 - mse: 1.7532 - val_loss: 1.1527 - val_mse: 1.1128\n",
      "Epoch 15/1000\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 1.7676 - mse: 1.7273Restoring model weights from the end of the best epoch: 5.\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 1.7303 - mse: 1.6900 - val_loss: 1.1515 - val_mse: 1.1107\n",
      "Epoch 15: early stopping\n",
      "18/18 [==============================] - 1s 8ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 6s 32ms/step - loss: 3.5942 - mse: 3.0980 - val_loss: 1.5058 - val_mse: 1.0988\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 3.0254 - mse: 2.6623 - val_loss: 1.3874 - val_mse: 1.0610\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.8346 - mse: 2.5315 - val_loss: 1.3135 - val_mse: 1.0317\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.8219 - mse: 2.5555 - val_loss: 1.2992 - val_mse: 1.0474\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.6775 - mse: 2.4381 - val_loss: 1.2887 - val_mse: 1.0602\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.6331 - mse: 2.4120 - val_loss: 1.2681 - val_mse: 1.0545\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.6241 - mse: 2.4169 - val_loss: 1.2602 - val_mse: 1.0579\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.5825 - mse: 2.3829 - val_loss: 1.2318 - val_mse: 1.0357\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.4674 - mse: 2.2742 - val_loss: 1.2295 - val_mse: 1.0391\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 2.4302 - mse: 2.2409 - val_loss: 1.2450 - val_mse: 1.0573\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 2.3396 - mse: 2.1532 - val_loss: 1.2388 - val_mse: 1.0530\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.2295 - mse: 2.0454 - val_loss: 1.2455 - val_mse: 1.0608\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 2.1607 - mse: 1.9765 - val_loss: 1.2419 - val_mse: 1.0596\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 2.0600 - mse: 1.8770 - val_loss: 1.3188 - val_mse: 1.1360\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 2.0724 - mse: 1.8881 - val_loss: 1.2844 - val_mse: 1.0973\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.0917 - mse: 1.9035 - val_loss: 1.2067 - val_mse: 1.0167\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.9841 - mse: 1.7950 - val_loss: 1.3193 - val_mse: 1.1286\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 1.8670 - mse: 1.6754 - val_loss: 1.2370 - val_mse: 1.0447\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 1.8175 - mse: 1.6228 - val_loss: 1.2320 - val_mse: 1.0372\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.7619 - mse: 1.5672 - val_loss: 1.3218 - val_mse: 1.1260\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 1.6458 - mse: 1.4498 - val_loss: 1.3091 - val_mse: 1.1127\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 1.6144 - mse: 1.4178 - val_loss: 1.3008 - val_mse: 1.1031\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 1.5217 - mse: 1.3241 - val_loss: 1.2679 - val_mse: 1.0700\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 1.4614 - mse: 1.2643 - val_loss: 1.2641 - val_mse: 1.0675\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.4479 - mse: 1.2522 - val_loss: 1.3084 - val_mse: 1.1130\n",
      "Epoch 26/1000\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 1.3485 - mse: 1.1538Restoring model weights from the end of the best epoch: 16.\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 1.3409 - mse: 1.1462 - val_loss: 1.3216 - val_mse: 1.1277\n",
      "Epoch 26: early stopping\n",
      "18/18 [==============================] - 1s 5ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 6s 34ms/step - loss: 3.1350 - mse: 3.1307 - val_loss: 1.1206 - val_mse: 1.1164\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 2.6075 - mse: 2.6034 - val_loss: 1.0842 - val_mse: 1.0802\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.5635 - mse: 2.5596 - val_loss: 1.1285 - val_mse: 1.1246\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 2.5038 - mse: 2.5000 - val_loss: 1.0648 - val_mse: 1.0611\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.3724 - mse: 2.3688 - val_loss: 1.0391 - val_mse: 1.0355\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.3642 - mse: 2.3607 - val_loss: 1.0410 - val_mse: 1.0375\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.3589 - mse: 2.3554 - val_loss: 1.0744 - val_mse: 1.0709\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.2397 - mse: 2.2363 - val_loss: 1.0832 - val_mse: 1.0797\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.0930 - mse: 2.0896 - val_loss: 1.1046 - val_mse: 1.1011\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.0844 - mse: 2.0809 - val_loss: 1.0688 - val_mse: 1.0654\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 1.9580 - mse: 1.9545 - val_loss: 1.0593 - val_mse: 1.0559\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.8623 - mse: 1.8588 - val_loss: 1.0898 - val_mse: 1.0863\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 1.8712 - mse: 1.8677 - val_loss: 1.0943 - val_mse: 1.0908\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.7043 - mse: 1.7008 - val_loss: 1.1978 - val_mse: 1.1942\n",
      "Epoch 15/1000\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 1.6127 - mse: 1.6092Restoring model weights from the end of the best epoch: 5.\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 1.6349 - mse: 1.6314 - val_loss: 1.0864 - val_mse: 1.0828\n",
      "Epoch 15: early stopping\n",
      "18/18 [==============================] - 1s 5ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 7s 44ms/step - loss: 3.1248 - mse: 3.0914 - val_loss: 1.1242 - val_mse: 1.0910\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 2.6244 - mse: 2.5917 - val_loss: 1.0932 - val_mse: 1.0608\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 2.5565 - mse: 2.5243 - val_loss: 1.1173 - val_mse: 1.0853\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 2.4763 - mse: 2.4444 - val_loss: 1.0638 - val_mse: 1.0319\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 2.4258 - mse: 2.3940 - val_loss: 1.0976 - val_mse: 1.0656\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.4061 - mse: 2.3738 - val_loss: 1.1039 - val_mse: 1.0714\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 2.3412 - mse: 2.3086 - val_loss: 1.1156 - val_mse: 1.0827\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.2388 - mse: 2.2055 - val_loss: 1.0967 - val_mse: 1.0631\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 2.1340 - mse: 2.1002 - val_loss: 1.1237 - val_mse: 1.0897\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.0534 - mse: 2.0191 - val_loss: 1.1538 - val_mse: 1.1192\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.9743 - mse: 1.9393 - val_loss: 1.1390 - val_mse: 1.1038\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 1.9136 - mse: 1.8781 - val_loss: 1.1704 - val_mse: 1.1344\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 1.8480 - mse: 1.8115 - val_loss: 1.0914 - val_mse: 1.0545\n",
      "Epoch 14/1000\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 1.7593 - mse: 1.7221Restoring model weights from the end of the best epoch: 4.\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.7685 - mse: 1.7313 - val_loss: 1.1184 - val_mse: 1.0809\n",
      "Epoch 14: early stopping\n",
      "18/18 [==============================] - 1s 5ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 6s 51ms/step - loss: 3.6278 - mse: 3.1398 - val_loss: 1.3963 - val_mse: 1.1280\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.7803 - mse: 2.5863 - val_loss: 1.1709 - val_mse: 1.0313\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.6590 - mse: 2.5485 - val_loss: 1.2217 - val_mse: 1.1352\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.5481 - mse: 2.4771 - val_loss: 1.0907 - val_mse: 1.0340\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.4692 - mse: 2.4224 - val_loss: 1.0671 - val_mse: 1.0289\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.3525 - mse: 2.3203 - val_loss: 1.0915 - val_mse: 1.0648\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.2357 - mse: 2.2130 - val_loss: 1.0677 - val_mse: 1.0485\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.1765 - mse: 2.1598 - val_loss: 1.0820 - val_mse: 1.0677\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.0826 - mse: 2.0702 - val_loss: 1.1006 - val_mse: 1.0899\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 1.9393 - mse: 1.9298 - val_loss: 1.1080 - val_mse: 1.0997\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 1.8584 - mse: 1.8511 - val_loss: 1.0678 - val_mse: 1.0614\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.7923 - mse: 1.7867 - val_loss: 1.1170 - val_mse: 1.1120\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.7776 - mse: 1.7731 - val_loss: 1.1120 - val_mse: 1.1080\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 1.5612 - mse: 1.5575 - val_loss: 1.0810 - val_mse: 1.0777\n",
      "Epoch 15/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 1.4352 - mse: 1.4321Restoring model weights from the end of the best epoch: 5.\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 1.4620 - mse: 1.4589 - val_loss: 1.1116 - val_mse: 1.1086\n",
      "Epoch 15: early stopping\n",
      "18/18 [==============================] - 1s 9ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 6s 36ms/step - loss: 3.0783 - mse: 3.0712 - val_loss: 1.1102 - val_mse: 1.1033\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.6032 - mse: 2.5966 - val_loss: 1.1409 - val_mse: 1.1345\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.5616 - mse: 2.5555 - val_loss: 1.0746 - val_mse: 1.0686\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.4467 - mse: 2.4409 - val_loss: 1.0951 - val_mse: 1.0895\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.4447 - mse: 2.4392 - val_loss: 1.0483 - val_mse: 1.0429\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.4116 - mse: 2.4063 - val_loss: 1.0625 - val_mse: 1.0573\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.3728 - mse: 2.3676 - val_loss: 1.1287 - val_mse: 1.1236\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 2.3028 - mse: 2.2978 - val_loss: 1.0297 - val_mse: 1.0248\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 2.1828 - mse: 2.1779 - val_loss: 1.0602 - val_mse: 1.0554\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.1182 - mse: 2.1134 - val_loss: 1.0982 - val_mse: 1.0934\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.0441 - mse: 2.0393 - val_loss: 1.0648 - val_mse: 1.0599\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.0095 - mse: 2.0046 - val_loss: 1.1042 - val_mse: 1.0991\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.8604 - mse: 1.8554 - val_loss: 1.1062 - val_mse: 1.1012\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 1.7637 - mse: 1.7588 - val_loss: 1.0909 - val_mse: 1.0859\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.6895 - mse: 1.6845 - val_loss: 1.0822 - val_mse: 1.0772\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 1.6125 - mse: 1.6075 - val_loss: 1.1264 - val_mse: 1.1213\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.5542 - mse: 1.5491 - val_loss: 1.1489 - val_mse: 1.1437\n",
      "Epoch 18/1000\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 1.5225 - mse: 1.5173Restoring model weights from the end of the best epoch: 8.\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 1.5378 - mse: 1.5327 - val_loss: 1.1051 - val_mse: 1.1000\n",
      "Epoch 18: early stopping\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 5s 33ms/step - loss: 3.2300 - mse: 3.1742 - val_loss: 1.1313 - val_mse: 1.0768\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.7035 - mse: 2.6499 - val_loss: 1.1147 - val_mse: 1.0619\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.6108 - mse: 2.5587 - val_loss: 1.1361 - val_mse: 1.0848\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.5245 - mse: 2.4734 - val_loss: 1.0827 - val_mse: 1.0319\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.5047 - mse: 2.4541 - val_loss: 1.0985 - val_mse: 1.0480\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.3959 - mse: 2.3454 - val_loss: 1.1537 - val_mse: 1.1031\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.3710 - mse: 2.3200 - val_loss: 1.0873 - val_mse: 1.0360\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 2.2569 - mse: 2.2054 - val_loss: 1.1216 - val_mse: 1.0698\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.1657 - mse: 2.1135 - val_loss: 1.1164 - val_mse: 1.0637\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.1172 - mse: 2.0638 - val_loss: 1.1667 - val_mse: 1.1127\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 2.0111 - mse: 1.9565 - val_loss: 1.2050 - val_mse: 1.1495\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.9244 - mse: 1.8684 - val_loss: 1.1751 - val_mse: 1.1184\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.7937 - mse: 1.7364 - val_loss: 1.1803 - val_mse: 1.1224\n",
      "Epoch 14/1000\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 1.5896 - mse: 1.5311Restoring model weights from the end of the best epoch: 4.\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.6392 - mse: 1.5807 - val_loss: 1.1463 - val_mse: 1.0873\n",
      "Epoch 14: early stopping\n",
      "18/18 [==============================] - 1s 12ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 6s 35ms/step - loss: 4.1661 - mse: 3.2235 - val_loss: 1.6347 - val_mse: 1.1282\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 3.0054 - mse: 2.6188 - val_loss: 1.3677 - val_mse: 1.0648\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 2.8031 - mse: 2.5431 - val_loss: 1.2802 - val_mse: 1.0545\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.7029 - mse: 2.4989 - val_loss: 1.2893 - val_mse: 1.1042\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.6225 - mse: 2.4495 - val_loss: 1.1915 - val_mse: 1.0295\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.5626 - mse: 2.4081 - val_loss: 1.2083 - val_mse: 1.0603\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 2.5231 - mse: 2.3800 - val_loss: 1.1721 - val_mse: 1.0330\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.4474 - mse: 2.3107 - val_loss: 1.1695 - val_mse: 1.0356\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.3699 - mse: 2.2379 - val_loss: 1.1655 - val_mse: 1.0345\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.3494 - mse: 2.2192 - val_loss: 1.1776 - val_mse: 1.0487\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.3034 - mse: 2.1750 - val_loss: 1.1478 - val_mse: 1.0195\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.2551 - mse: 2.1268 - val_loss: 1.2194 - val_mse: 1.0915\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.2087 - mse: 2.0808 - val_loss: 1.1415 - val_mse: 1.0138\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.1151 - mse: 1.9868 - val_loss: 1.2173 - val_mse: 1.0884\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.0676 - mse: 1.9381 - val_loss: 1.1959 - val_mse: 1.0658\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.9571 - mse: 1.8259 - val_loss: 1.2448 - val_mse: 1.1130\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.9222 - mse: 1.7896 - val_loss: 1.2615 - val_mse: 1.1281\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.8746 - mse: 1.7412 - val_loss: 1.2214 - val_mse: 1.0867\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.8116 - mse: 1.6759 - val_loss: 1.2280 - val_mse: 1.0922\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 1.7817 - mse: 1.6453 - val_loss: 1.1995 - val_mse: 1.0623\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.7118 - mse: 1.5683 - val_loss: 1.2123 - val_mse: 1.0599\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.6796 - mse: 1.5247 - val_loss: 1.2692 - val_mse: 1.1125\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 1.5522 - mse: 1.4043Restoring model weights from the end of the best epoch: 13.\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.5522 - mse: 1.4043 - val_loss: 1.2202 - val_mse: 1.0768\n",
      "Epoch 23: early stopping\n",
      "18/18 [==============================] - 1s 7ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 6s 37ms/step - loss: 3.2999 - mse: 3.2335 - val_loss: 1.1541 - val_mse: 1.0891\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.6411 - mse: 2.5775 - val_loss: 1.1381 - val_mse: 1.0759\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 2.6344 - mse: 2.5730 - val_loss: 1.1186 - val_mse: 1.0580\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 2.5433 - mse: 2.4833 - val_loss: 1.1127 - val_mse: 1.0532\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.4788 - mse: 2.4198 - val_loss: 1.1467 - val_mse: 1.0880\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.4213 - mse: 2.3627 - val_loss: 1.1300 - val_mse: 1.0716\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 2.4064 - mse: 2.3477 - val_loss: 1.1243 - val_mse: 1.0656\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.3274 - mse: 2.2685 - val_loss: 1.1232 - val_mse: 1.0642\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.3055 - mse: 2.2461 - val_loss: 1.0996 - val_mse: 1.0399\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.2097 - mse: 2.1497 - val_loss: 1.1313 - val_mse: 1.0710\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.1736 - mse: 2.1129 - val_loss: 1.1122 - val_mse: 1.0511\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.0385 - mse: 1.9770 - val_loss: 1.1073 - val_mse: 1.0456\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 1.9413 - mse: 1.8793 - val_loss: 1.1698 - val_mse: 1.1073\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.9888 - mse: 1.9257 - val_loss: 1.1715 - val_mse: 1.1078\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.8347 - mse: 1.7705 - val_loss: 1.1375 - val_mse: 1.0729\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.7420 - mse: 1.6769 - val_loss: 1.1429 - val_mse: 1.0773\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.7030 - mse: 1.6372 - val_loss: 1.2471 - val_mse: 1.1808\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.6436 - mse: 1.5767 - val_loss: 1.2100 - val_mse: 1.1426\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 1.5237 - mse: 1.4559Restoring model weights from the end of the best epoch: 9.\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.5237 - mse: 1.4559 - val_loss: 1.1570 - val_mse: 1.0887\n",
      "Epoch 19: early stopping\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 6s 36ms/step - loss: 5.6272 - mse: 3.1301 - val_loss: 2.0483 - val_mse: 1.0839\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 3.2614 - mse: 2.6004 - val_loss: 1.5312 - val_mse: 1.0598\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 2.9480 - mse: 2.5537 - val_loss: 1.3922 - val_mse: 1.0573\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.7547 - mse: 2.4545 - val_loss: 1.3315 - val_mse: 1.0601\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 2.6852 - mse: 2.4304 - val_loss: 1.2977 - val_mse: 1.0570\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.6588 - mse: 2.4266 - val_loss: 1.2666 - val_mse: 1.0429\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.5924 - mse: 2.3760 - val_loss: 1.2769 - val_mse: 1.0674\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.5272 - mse: 2.3222 - val_loss: 1.2725 - val_mse: 1.0712\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.4505 - mse: 2.2513 - val_loss: 1.2941 - val_mse: 1.0983\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.3933 - mse: 2.2002 - val_loss: 1.2322 - val_mse: 1.0421\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.3420 - mse: 2.1532 - val_loss: 1.2423 - val_mse: 1.0540\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.2604 - mse: 2.0726 - val_loss: 1.2369 - val_mse: 1.0483\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.2245 - mse: 2.0357 - val_loss: 1.2095 - val_mse: 1.0212\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.1182 - mse: 1.9307 - val_loss: 1.2529 - val_mse: 1.0667\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 2.1157 - mse: 1.9287 - val_loss: 1.2370 - val_mse: 1.0457\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.0603 - mse: 1.8648 - val_loss: 1.2536 - val_mse: 1.0584\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 1.9608 - mse: 1.7666 - val_loss: 1.2869 - val_mse: 1.0943\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 1.8576 - mse: 1.6645 - val_loss: 1.3228 - val_mse: 1.1291\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.8102 - mse: 1.6158 - val_loss: 1.2828 - val_mse: 1.0866\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.7324 - mse: 1.5353 - val_loss: 1.2319 - val_mse: 1.0332\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.6170 - mse: 1.4182 - val_loss: 1.2996 - val_mse: 1.1006\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 1.5377 - mse: 1.3392 - val_loss: 1.3110 - val_mse: 1.1125\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 1.5313 - mse: 1.3313Restoring model weights from the end of the best epoch: 13.\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 1.5313 - mse: 1.3313 - val_loss: 1.3084 - val_mse: 1.1075\n",
      "Epoch 23: early stopping\n",
      "18/18 [==============================] - 1s 12ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 7s 51ms/step - loss: 4.8428 - mse: 3.2288 - val_loss: 2.1329 - val_mse: 1.1474\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 3.3778 - mse: 2.6298 - val_loss: 1.6501 - val_mse: 1.0770\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 3.0489 - mse: 2.5665 - val_loss: 1.5329 - val_mse: 1.1237\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 2.9076 - mse: 2.5394 - val_loss: 1.3792 - val_mse: 1.0488\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.8002 - mse: 2.4974 - val_loss: 1.3529 - val_mse: 1.0765\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.7365 - mse: 2.4743 - val_loss: 1.3269 - val_mse: 1.0774\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.6778 - mse: 2.4380 - val_loss: 1.2612 - val_mse: 1.0327\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.6328 - mse: 2.4104 - val_loss: 1.2431 - val_mse: 1.0272\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.5952 - mse: 2.3851 - val_loss: 1.3021 - val_mse: 1.0938\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.6297 - mse: 2.4233 - val_loss: 1.3444 - val_mse: 1.1394\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 2.5733 - mse: 2.3706 - val_loss: 1.2677 - val_mse: 1.0679\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 2.4509 - mse: 2.2551 - val_loss: 1.2439 - val_mse: 1.0510\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.5068 - mse: 2.3169 - val_loss: 1.2301 - val_mse: 1.0447\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.4954 - mse: 2.3066 - val_loss: 1.2310 - val_mse: 1.0389\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.4400 - mse: 2.2445 - val_loss: 1.2750 - val_mse: 1.0767\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.4640 - mse: 2.2675 - val_loss: 1.3212 - val_mse: 1.1230\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.3492 - mse: 2.1531 - val_loss: 1.2568 - val_mse: 1.0655\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.3089 - mse: 2.1216 - val_loss: 1.2536 - val_mse: 1.0699\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.3136 - mse: 2.1269 - val_loss: 1.2570 - val_mse: 1.0680\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.3280 - mse: 2.1381 - val_loss: 1.3007 - val_mse: 1.1083\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.2620 - mse: 2.0686 - val_loss: 1.2665 - val_mse: 1.0740\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.2036 - mse: 2.0150 - val_loss: 1.2970 - val_mse: 1.1049\n",
      "Epoch 23/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 2.1661 - mse: 1.9760Restoring model weights from the end of the best epoch: 13.\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.1771 - mse: 1.9870 - val_loss: 1.3090 - val_mse: 1.1195\n",
      "Epoch 23: early stopping\n",
      "18/18 [==============================] - 1s 11ms/step\n",
      "最佳参数: [600, 627, 225, 263, 0.00965869086178897, 8.204849769062996e-06, 7.361641032249826e-05]\n",
      "最小损失: 0.002288395285545951\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM, concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer, Real\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.acquisition import gaussian_ei\n",
    "\n",
    "#進行調參的次數\n",
    "n_calls=50\n",
    "\n",
    "lstm1_layers_num = 2\n",
    "lstm2_layers_num = 1\n",
    "dense1_neurons_num = 557\n",
    "dense2_neurons_num = 571\n",
    "merged_layers_num = 1\n",
    "\n",
    "#此函式可以幫我們設定一個模型的結構\n",
    "def set_LSTM_LSTM(lstm1_structure, lstm2_structure, Megred_struture):\n",
    "    lstm1_neurons_num = lstm1_structure['lstm_neurons_num']\n",
    "    lstm1_activations = lstm1_structure['lstm_activations']\n",
    "    lstm1_recurrent_activations = lstm1_structure['lstm_recurrent_activations']\n",
    "    dense1_neurons_num = lstm1_structure['dense_neurons_num']\n",
    "    dense1_activations = lstm1_structure['dense_activations']\n",
    "    kernel_regularizer1= lstm1_structure['kernel_regularizer']\n",
    "\n",
    "    lstm2_neurons_num = lstm2_structure['lstm_neurons_num']\n",
    "    lstm2_activations = lstm2_structure['lstm_activations']\n",
    "    lstm2_recurrent_activations = lstm2_structure['lstm_recurrent_activations']\n",
    "    dense2_neurons_num = lstm2_structure['dense_neurons_num']\n",
    "    dense2_activations = lstm2_structure['dense_activations']\n",
    "    kernel_regularizer2= lstm2_structure['kernel_regularizer']\n",
    "    \n",
    "    Merged_neurons_num = Megred_struture['neurons_num']\n",
    "    Megred_activations = Megred_struture['activations']\n",
    "    Merged_kernel_regularizer = Megred_struture['kernel_regularizer']\n",
    "\n",
    "    input_lstm1 = Input(shape=lstm1_structure['input_shape'])\n",
    "    hidden_1 = input_lstm1\n",
    "\n",
    "    for i in range(0, len(lstm1_neurons_num), 1):\n",
    "        if i == len(lstm1_neurons_num) - 1:\n",
    "            return_sequences=False\n",
    "        else:\n",
    "            return_sequences=True \n",
    "        hidden_1 = LSTM(lstm1_neurons_num[i], return_sequences=return_sequences,\\\n",
    "        activation=lstm1_activations[i], kernel_regularizer=kernel_regularizer1[i],\n",
    "        recurrent_activation= lstm1_recurrent_activations[i])(hidden_1)\n",
    "    output_1 = hidden_1\n",
    "    for i in range(0, len(dense1_neurons_num), 1):\n",
    "        output_1 = Dense(dense1_neurons_num[i], \\\n",
    "            kernel_regularizer=kernel_regularizer1[len(lstm1_neurons_num)-1+i], \\\n",
    "            activation=dense1_activations[i])(output_1)\n",
    "        \n",
    "    input_lstm2 = Input(shape=lstm2_structure['input_shape'])\n",
    "    hidden_2 = input_lstm2\n",
    "\n",
    "    for i in range(0, len(lstm2_neurons_num), 1):\n",
    "        if i == len(lstm2_neurons_num) - 1:\n",
    "            return_sequences=False\n",
    "        else:\n",
    "            return_sequences=True \n",
    "        hidden_2 = LSTM(lstm2_neurons_num[i], return_sequences=return_sequences,\\\n",
    "        activation=lstm2_activations[i], kernel_regularizer=kernel_regularizer2[i],\n",
    "        recurrent_activation= lstm2_recurrent_activations[i])(hidden_2)\n",
    "    output_2 = hidden_2\n",
    "    for i in range(0, len(dense2_neurons_num), 2):\n",
    "        output_2 = Dense(dense2_neurons_num[i], \\\n",
    "            kernel_regularizer=kernel_regularizer2[len(lstm2_neurons_num)-1+i], \\\n",
    "            activation=dense2_activations[i])(output_2)\n",
    "        \n",
    "    merged = concatenate([output_1, output_2], axis=-1)\n",
    "    dense = merged\n",
    "    for i in range(len(Merged_neurons_num)):\n",
    "        dense = Dense(Merged_neurons_num[i], Megred_activations[i], Merged_kernel_regularizer[i])(dense)\n",
    "\n",
    "    output = Dense(y_train.shape[1])(dense)\n",
    "    model = Model(inputs=[input_lstm1, input_lstm2], outputs=output)\n",
    "    return model\n",
    "\n",
    "search_space = [\n",
    "    Integer(498, 698, name='lstm1_neurons_num1'),\n",
    "    Integer(498, 698, name='lstm1_neurons_num2'),\n",
    "    Integer(54, 254, name='lstm2_neurons_num1'),\n",
    "    Integer(252, 352, name='merged_neurons_num1'),\n",
    "    Real(1e-6, 1e-2, prior='log-uniform', name='lambda1'),\n",
    "    Real(1e-6, 1e-2, prior='log-uniform', name='lambda2'),\n",
    "    Real(1e-6, 1e-2, prior='log-uniform', name='lambda3')\n",
    "]\n",
    "\n",
    "\n",
    "def train_and_evaluate_net(lstm1_neurons_num1, lstm1_neurons_num2, lstm2_neurons_num1, \n",
    "                    merged_neurons_num1, lambda1, lambda2, lambda3):\n",
    "    batch_size = 32\n",
    "    epochs = 1000\n",
    "\n",
    "    OCHL_lstm_neurons_num = [lstm1_neurons_num1, lstm1_neurons_num2]\n",
    "    OCHLE_lstm_activations = ['tanh']*len(OCHL_lstm_neurons_num)\n",
    "    OCHL_lstm_recurrent_activations = ['sigmoid']*len(OCHL_lstm_neurons_num)\n",
    "    OCHL_dense_neurons_num = [dense1_neurons_num]\n",
    "    OCHL_dense_activations = ['relu']\n",
    "    OCHL_kernel_regularizer=[l2(lambda1)]*(len(OCHL_lstm_neurons_num) + len(OCHL_dense_neurons_num))\n",
    "\n",
    "    Slope_lstm_neurons_num = [lstm2_neurons_num1]\n",
    "    Slope_lstm_activations = ['tanh']*len(Slope_lstm_neurons_num)\n",
    "    Slope_lstm_recurrent_activations = ['sigmoid']*len(Slope_lstm_neurons_num)\n",
    "    Slope_dense_neurons_num = [dense2_neurons_num]\n",
    "    Slope_dense_activations = ['relu']\n",
    "    Slope_kernel_regularizer=[l2(lambda2)]*(len(Slope_lstm_neurons_num) + len(Slope_dense_neurons_num))\n",
    "\n",
    "    Merged_neurons_num = [merged_neurons_num1] \n",
    "    Megred_activations = ['relu']*len(Merged_neurons_num)\n",
    "    Merged_kernel_regularizer=[l2(lambda3)]*(len(Merged_neurons_num))\n",
    "\n",
    "    lstm_OCHL_structure = {\n",
    "        'input_shape': OCHLE_train.shape[1:],\n",
    "        'lstm_neurons_num': OCHL_lstm_neurons_num,\n",
    "        'lstm_activations': OCHLE_lstm_activations,\n",
    "        'lstm_recurrent_activations':OCHL_lstm_recurrent_activations,\n",
    "        'dense_neurons_num':OCHL_dense_neurons_num,\n",
    "        'dense_activations':OCHL_dense_activations,\n",
    "        'kernel_regularizer':OCHL_kernel_regularizer\n",
    "        }\n",
    "\n",
    "    lstm_Slope_structure = {\n",
    "        'input_shape': X_train.shape[1:],\n",
    "        'lstm_neurons_num': Slope_lstm_neurons_num,\n",
    "        'lstm_activations': Slope_lstm_activations,\n",
    "        'lstm_recurrent_activations':Slope_lstm_recurrent_activations,\n",
    "        'dense_neurons_num':Slope_dense_neurons_num,\n",
    "        'dense_activations':Slope_dense_activations,\n",
    "        'kernel_regularizer':Slope_kernel_regularizer\n",
    "        }\n",
    "\n",
    "    Merged_structure = {\n",
    "        'neurons_num': Merged_neurons_num,\n",
    "        'activations': Megred_activations,\n",
    "        'kernel_regularizer': Merged_kernel_regularizer\n",
    "        }\n",
    "    alltrain = 1\n",
    "    allMSE = np.zeros(alltrain) \n",
    "    for j in range(alltrain):\n",
    "        #設定模型結構\n",
    "        model = set_LSTM_LSTM(lstm_OCHL_structure, lstm_Slope_structure, Merged_structure)\n",
    "        model.compile(loss='mse', optimizer = 'adam', metrics=['mse'])  \n",
    "\n",
    "        # 訓練模型\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=10, \\\n",
    "                                verbose=2, mode='min', restore_best_weights=True)\n",
    "        hist_model = model.fit(\n",
    "            [OCHLE_train, X_train], y_train, epochs=epochs, batch_size=batch_size, \\\n",
    "            validation_split=0.2, callbacks=[early_stopping]\n",
    "        )\n",
    "\n",
    "        #得到輸出\n",
    "        y_pred = model.predict([OCHLE_test, X_test])\n",
    "        y_pred = y_pred / magnification_slope\n",
    "        columns_names = ['履約價', '隱含波動率({})'.format(s_c)]\n",
    "        column_index = [IV_data.columns.get_loc(col) for col in columns_names]\n",
    "\n",
    "        SSE_everyday = np.zeros(((len(y_pred), K_num)))\n",
    "    \n",
    "        for i in range(len(y_pred)):\n",
    "            K_day = IV_matrix_test[i*K_num:(i+1)*K_num, column_index[0]]\n",
    "            iv_day = IV_matrix_test[i*K_num:(i+1)*K_num, column_index[1]]\n",
    "            y_pred_day = y_pred[i]\n",
    "\n",
    "            ForecastData, SSE_everyday[i] = minSSE_recovery(y=iv_day, x=K_day, slope_yhat=y_pred_day)\n",
    "        sse_everyday = SSE_everyday[:, 0]\n",
    "        allMSE[j] = np.mean(sse_everyday)\n",
    "\n",
    "    loss = np.min(allMSE)\n",
    "    return loss\n",
    "\n",
    "@use_named_args(search_space)\n",
    "def objective(**params):\n",
    "    lstm1_neurons_num1 = params['lstm1_neurons_num1']\n",
    "    lstm1_neurons_num2 = params['lstm1_neurons_num2']\n",
    "    lstm2_neurons_num1 = params['lstm2_neurons_num1']\n",
    "    merged_neurons_num1 = params['merged_neurons_num1']\n",
    "    lambda1 = params['lambda1']\n",
    "    lambda2 = params['lambda2']\n",
    "    lambda3 = params['lambda3']\n",
    "    \n",
    "    loss = train_and_evaluate_net(lstm1_neurons_num1, lstm1_neurons_num2, lstm2_neurons_num1, \n",
    "                           merged_neurons_num1, lambda1, lambda2, lambda3)\n",
    "    return loss\n",
    "\n",
    "\n",
    "result = gp_minimize(objective, search_space, n_calls=n_calls, random_state=42, acq_func='EI')\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"最佳参数: {}\".format(result.x))\n",
    "print(\"最小损失: {}\".format(result.fun))\n",
    "\n",
    "\n",
    "best_params = result.x\n",
    "lstm1_neurons_num1 = best_params[0]\n",
    "lstm1_neurons_num2 = best_params[1]\n",
    "lstm2_neurons_num1 = best_params[2]\n",
    "merged_neurons_num1 = best_params[3]\n",
    "lambda1 = best_params[4]\n",
    "lambda2 = best_params[5]\n",
    "lambda3 = best_params[6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4/4 [==============================] - 7s 418ms/step - loss: 18.7701 - mse: 4.6496 - val_loss: 13.9939 - val_mse: 1.7780\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 15.1319 - mse: 3.7747 - val_loss: 11.1027 - val_mse: 1.3955\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 12.3029 - mse: 3.3244 - val_loss: 8.7959 - val_mse: 1.1993\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 9.9354 - mse: 2.9357 - val_loss: 6.9669 - val_mse: 1.0910\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 8.0749 - mse: 2.6780 - val_loss: 5.6004 - val_mse: 1.0987\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 6.7038 - mse: 2.5790 - val_loss: 4.5125 - val_mse: 1.0881\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 5.6655 - mse: 2.5328 - val_loss: 3.6553 - val_mse: 1.0619\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.8603 - mse: 2.4895 - val_loss: 3.0268 - val_mse: 1.0661\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.2541 - mse: 2.4613 - val_loss: 2.5260 - val_mse: 1.0420\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.7717 - mse: 2.4139 - val_loss: 2.1636 - val_mse: 1.0369\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.4080 - mse: 2.3753 - val_loss: 1.8891 - val_mse: 1.0295\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.1238 - mse: 2.3350 - val_loss: 1.6838 - val_mse: 1.0250\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.9073 - mse: 2.3018 - val_loss: 1.5621 - val_mse: 1.0548\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 2.7373 - mse: 2.2704 - val_loss: 1.4185 - val_mse: 1.0263\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 2.6091 - mse: 2.2479 - val_loss: 1.3468 - val_mse: 1.0430\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.4603 - mse: 2.1803 - val_loss: 1.2625 - val_mse: 1.0268\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.3529 - mse: 2.1358 - val_loss: 1.2245 - val_mse: 1.0419\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.2598 - mse: 2.0916 - val_loss: 1.2004 - val_mse: 1.0588\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.1655 - mse: 2.0352 - val_loss: 1.1706 - val_mse: 1.0612\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.0783 - mse: 1.9776 - val_loss: 1.1294 - val_mse: 1.0447\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 1.9909 - mse: 1.9130 - val_loss: 1.1190 - val_mse: 1.0535\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 1.9099 - mse: 1.8496 - val_loss: 1.1040 - val_mse: 1.0532\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.8802 - mse: 1.8333 - val_loss: 1.0831 - val_mse: 1.0436\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.8133 - mse: 1.7767 - val_loss: 1.0801 - val_mse: 1.0490\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.7461 - mse: 1.7173 - val_loss: 1.1031 - val_mse: 1.0784\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.6832 - mse: 1.6603 - val_loss: 1.0669 - val_mse: 1.0471\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.6657 - mse: 1.6472 - val_loss: 1.0833 - val_mse: 1.0671\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.6212 - mse: 1.6059 - val_loss: 1.0881 - val_mse: 1.0745\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.5220 - mse: 1.5091 - val_loss: 1.0797 - val_mse: 1.0682\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.4608 - mse: 1.4498 - val_loss: 1.1030 - val_mse: 1.0929\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 1.4071 - mse: 1.3975 - val_loss: 1.1161 - val_mse: 1.1072\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.3443 - mse: 1.3357 - val_loss: 1.0862 - val_mse: 1.0782\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.3163 - mse: 1.3085 - val_loss: 1.1115 - val_mse: 1.1040\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.2752 - mse: 1.2679 - val_loss: 1.1694 - val_mse: 1.1624\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.2173 - mse: 1.2105 - val_loss: 1.1025 - val_mse: 1.0959\n",
      "Epoch 36/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1738 - mse: 1.1673Restoring model weights from the end of the best epoch: 26.\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1.1736 - mse: 1.1670 - val_loss: 1.1432 - val_mse: 1.1368\n",
      "Epoch 36: early stopping\n",
      "18/18 [==============================] - 1s 5ms/step\n",
      "Epoch 1/1000\n",
      "4/4 [==============================] - 5s 355ms/step - loss: 18.7119 - mse: 4.6131 - val_loss: 13.7927 - val_mse: 1.5899\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 15.0231 - mse: 3.6707 - val_loss: 11.1149 - val_mse: 1.3956\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 12.3145 - mse: 3.3166 - val_loss: 8.8479 - val_mse: 1.2216\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 10.0027 - mse: 2.9708 - val_loss: 7.0167 - val_mse: 1.1042\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 8.1146 - mse: 2.6798 - val_loss: 5.6263 - val_mse: 1.0856\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 6.7441 - mse: 2.5802 - val_loss: 4.5483 - val_mse: 1.0851\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.6976 - mse: 2.5264 - val_loss: 3.6990 - val_mse: 1.0683\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.8975 - mse: 2.4901 - val_loss: 3.0449 - val_mse: 1.0492\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.2687 - mse: 2.4418 - val_loss: 2.5505 - val_mse: 1.0342\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.8112 - mse: 2.4219 - val_loss: 2.1880 - val_mse: 1.0320\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.4495 - mse: 2.3887 - val_loss: 1.9141 - val_mse: 1.0281\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 3.1644 - mse: 2.3497 - val_loss: 1.7085 - val_mse: 1.0256\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.9384 - mse: 2.3097 - val_loss: 1.5657 - val_mse: 1.0367\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 2.7540 - mse: 2.2660 - val_loss: 1.4270 - val_mse: 1.0151\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 2.5924 - mse: 2.2123 - val_loss: 1.3589 - val_mse: 1.0375\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.4635 - mse: 2.1667 - val_loss: 1.2676 - val_mse: 1.0163\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 2.3345 - mse: 2.1025 - val_loss: 1.2555 - val_mse: 1.0593\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.2469 - mse: 2.0656 - val_loss: 1.2079 - val_mse: 1.0545\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 2.1350 - mse: 1.9934 - val_loss: 1.1714 - val_mse: 1.0517\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 2.0412 - mse: 1.9307 - val_loss: 1.1792 - val_mse: 1.0857\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.9525 - mse: 1.8662 - val_loss: 1.1537 - val_mse: 1.0807\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 1.8681 - mse: 1.8006 - val_loss: 1.1523 - val_mse: 1.0951\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 1.8066 - mse: 1.7536 - val_loss: 1.1475 - val_mse: 1.1025\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.6905 - mse: 1.6488 - val_loss: 1.1366 - val_mse: 1.1009\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.6227 - mse: 1.5895 - val_loss: 1.1647 - val_mse: 1.1362\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.5441 - mse: 1.5175 - val_loss: 1.2196 - val_mse: 1.1965\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.5084 - mse: 1.4868 - val_loss: 1.2199 - val_mse: 1.2010\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.4180 - mse: 1.4002 - val_loss: 1.1848 - val_mse: 1.1689\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.3556 - mse: 1.3406 - val_loss: 1.1980 - val_mse: 1.1845\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.3272 - mse: 1.3144 - val_loss: 1.2147 - val_mse: 1.2030\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.2614 - mse: 1.2503 - val_loss: 1.2109 - val_mse: 1.2006\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.2377 - mse: 1.2279 - val_loss: 1.2009 - val_mse: 1.1917\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.2061 - mse: 1.1972 - val_loss: 1.1616 - val_mse: 1.1532\n",
      "Epoch 34/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1325 - mse: 1.1243Restoring model weights from the end of the best epoch: 24.\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1.1568 - mse: 1.1487 - val_loss: 1.1952 - val_mse: 1.1875\n",
      "Epoch 34: early stopping\n",
      "18/18 [==============================] - 1s 5ms/step\n",
      "Epoch 1/1000\n",
      "4/4 [==============================] - 5s 352ms/step - loss: 18.6673 - mse: 4.5535 - val_loss: 13.8476 - val_mse: 1.6126\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 15.0552 - mse: 3.6658 - val_loss: 11.1644 - val_mse: 1.4020\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 12.3457 - mse: 3.3036 - val_loss: 8.8780 - val_mse: 1.2050\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 10.0443 - mse: 2.9654 - val_loss: 7.0896 - val_mse: 1.1300\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 8.1559 - mse: 2.6744 - val_loss: 5.7010 - val_mse: 1.1142\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 6.8076 - mse: 2.5981 - val_loss: 4.6086 - val_mse: 1.1013\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 5.7611 - mse: 2.5469 - val_loss: 3.7626 - val_mse: 1.0908\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.9589 - mse: 2.5115 - val_loss: 3.0933 - val_mse: 1.0601\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.3332 - mse: 2.4703 - val_loss: 2.6155 - val_mse: 1.0661\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 3.8720 - mse: 2.4510 - val_loss: 2.2391 - val_mse: 1.0542\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.5164 - mse: 2.4282 - val_loss: 1.9594 - val_mse: 1.0491\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.2187 - mse: 2.3814 - val_loss: 1.7438 - val_mse: 1.0408\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 2.9937 - mse: 2.3459 - val_loss: 1.5938 - val_mse: 1.0482\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.8151 - mse: 2.3118 - val_loss: 1.4646 - val_mse: 1.0395\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.6600 - mse: 2.2675 - val_loss: 1.4099 - val_mse: 1.0780\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.5460 - mse: 2.2393 - val_loss: 1.3029 - val_mse: 1.0435\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 2.4116 - mse: 2.1719 - val_loss: 1.2553 - val_mse: 1.0524\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.3015 - mse: 2.1142 - val_loss: 1.2227 - val_mse: 1.0643\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 2.2016 - mse: 2.0552 - val_loss: 1.1797 - val_mse: 1.0560\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.1248 - mse: 2.0106 - val_loss: 1.1597 - val_mse: 1.0632\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.0213 - mse: 1.9322 - val_loss: 1.1576 - val_mse: 1.0822\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.9579 - mse: 1.8882 - val_loss: 1.1310 - val_mse: 1.0720\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.8939 - mse: 1.8393 - val_loss: 1.1354 - val_mse: 1.0889\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.8154 - mse: 1.7723 - val_loss: 1.1704 - val_mse: 1.1336\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.7799 - mse: 1.7458 - val_loss: 1.1566 - val_mse: 1.1272\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.7292 - mse: 1.7017 - val_loss: 1.1673 - val_mse: 1.1435\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.7113 - mse: 1.6890 - val_loss: 1.1569 - val_mse: 1.1374\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.6175 - mse: 1.5991 - val_loss: 1.1482 - val_mse: 1.1320\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.5756 - mse: 1.5602 - val_loss: 1.1876 - val_mse: 1.1738\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 1.5197 - mse: 1.5066 - val_loss: 1.1168 - val_mse: 1.1049\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.4416 - mse: 1.4303 - val_loss: 1.1775 - val_mse: 1.1671\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.3818 - mse: 1.3718 - val_loss: 1.2057 - val_mse: 1.1964\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.3212 - mse: 1.3122 - val_loss: 1.1696 - val_mse: 1.1612\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.2600 - mse: 1.2518 - val_loss: 1.2168 - val_mse: 1.2090\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.2950 - mse: 1.2874 - val_loss: 1.2046 - val_mse: 1.1973\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.2122 - mse: 1.2050 - val_loss: 1.2058 - val_mse: 1.1989\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.1696 - mse: 1.1628 - val_loss: 1.2327 - val_mse: 1.2261\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.1308 - mse: 1.1243 - val_loss: 1.2008 - val_mse: 1.1945\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.1131 - mse: 1.1069 - val_loss: 1.1751 - val_mse: 1.1689\n",
      "Epoch 40/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9780 - mse: 0.9719Restoring model weights from the end of the best epoch: 30.\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 1.0542 - mse: 1.0481 - val_loss: 1.2607 - val_mse: 1.2547\n",
      "Epoch 40: early stopping\n",
      "18/18 [==============================] - 1s 5ms/step\n",
      "Epoch 1/1000\n",
      "4/4 [==============================] - 5s 365ms/step - loss: 18.7399 - mse: 4.5993 - val_loss: 14.0418 - val_mse: 1.7883\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 15.1508 - mse: 3.7474 - val_loss: 11.1471 - val_mse: 1.3787\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 12.3692 - mse: 3.3248 - val_loss: 8.8786 - val_mse: 1.2101\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 10.0199 - mse: 2.9482 - val_loss: 7.0563 - val_mse: 1.1095\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 8.1513 - mse: 2.6849 - val_loss: 5.6664 - val_mse: 1.0990\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 6.7726 - mse: 2.5844 - val_loss: 4.5853 - val_mse: 1.1023\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.7211 - mse: 2.5322 - val_loss: 3.7175 - val_mse: 1.0730\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.9124 - mse: 2.4929 - val_loss: 3.0816 - val_mse: 1.0771\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.2924 - mse: 2.4582 - val_loss: 2.5695 - val_mse: 1.0487\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.8028 - mse: 2.4103 - val_loss: 2.1958 - val_mse: 1.0389\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.4391 - mse: 2.3785 - val_loss: 1.9124 - val_mse: 1.0288\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.1435 - mse: 2.3323 - val_loss: 1.7299 - val_mse: 1.0520\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.9162 - mse: 2.2929 - val_loss: 1.5480 - val_mse: 1.0253\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.7334 - mse: 2.2523 - val_loss: 1.4474 - val_mse: 1.0432\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.5996 - mse: 2.2272 - val_loss: 1.3764 - val_mse: 1.0631\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.4754 - mse: 2.1866 - val_loss: 1.2870 - val_mse: 1.0437\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.3407 - mse: 2.1165 - val_loss: 1.2555 - val_mse: 1.0668\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.2288 - mse: 2.0550 - val_loss: 1.1946 - val_mse: 1.0483\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 2.1928 - mse: 2.0581 - val_loss: 1.2299 - val_mse: 1.1168\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.0987 - mse: 1.9946 - val_loss: 1.1467 - val_mse: 1.0593\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.0044 - mse: 1.9239 - val_loss: 1.1419 - val_mse: 1.0743\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.9399 - mse: 1.8777 - val_loss: 1.1389 - val_mse: 1.0865\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.9056 - mse: 1.8573 - val_loss: 1.1226 - val_mse: 1.0818\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 1.8227 - mse: 1.7850 - val_loss: 1.1162 - val_mse: 1.0842\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.7377 - mse: 1.7080 - val_loss: 1.1219 - val_mse: 1.0965\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.7032 - mse: 1.6796 - val_loss: 1.1274 - val_mse: 1.1070\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1.6076 - mse: 1.5885 - val_loss: 1.1598 - val_mse: 1.1432\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.5550 - mse: 1.5393 - val_loss: 1.1575 - val_mse: 1.1436\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.4779 - mse: 1.4648 - val_loss: 1.1570 - val_mse: 1.1452\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.4213 - mse: 1.4101 - val_loss: 1.2075 - val_mse: 1.1972\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.3645 - mse: 1.3547 - val_loss: 1.1592 - val_mse: 1.1501\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.2900 - mse: 1.2812 - val_loss: 1.1557 - val_mse: 1.1475\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.2589 - mse: 1.2509 - val_loss: 1.2491 - val_mse: 1.2415\n",
      "Epoch 34/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2285 - mse: 1.2211Restoring model weights from the end of the best epoch: 24.\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1.2182 - mse: 1.2108 - val_loss: 1.2053 - val_mse: 1.1982\n",
      "Epoch 34: early stopping\n",
      "18/18 [==============================] - 2s 9ms/step\n",
      "Epoch 1/1000\n",
      "4/4 [==============================] - 5s 346ms/step - loss: 18.6736 - mse: 4.5446 - val_loss: 13.9742 - val_mse: 1.7420\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 15.0789 - mse: 3.6994 - val_loss: 11.1112 - val_mse: 1.3726\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 12.3096 - mse: 3.2965 - val_loss: 8.8226 - val_mse: 1.1872\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 9.9687 - mse: 2.9301 - val_loss: 7.0025 - val_mse: 1.0884\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 8.0971 - mse: 2.6629 - val_loss: 5.6368 - val_mse: 1.1004\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 6.7491 - mse: 2.5910 - val_loss: 4.5408 - val_mse: 1.0860\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.6920 - mse: 2.5303 - val_loss: 3.6965 - val_mse: 1.0771\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.8896 - mse: 2.4941 - val_loss: 3.0293 - val_mse: 1.0466\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.2702 - mse: 2.4569 - val_loss: 2.5389 - val_mse: 1.0367\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 3.7989 - mse: 2.4239 - val_loss: 2.1817 - val_mse: 1.0401\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 3.4224 - mse: 2.3762 - val_loss: 1.9019 - val_mse: 1.0306\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.1576 - mse: 2.3579 - val_loss: 1.6987 - val_mse: 1.0305\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.9324 - mse: 2.3180 - val_loss: 1.5510 - val_mse: 1.0361\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.7481 - mse: 2.2741 - val_loss: 1.4444 - val_mse: 1.0460\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.5924 - mse: 2.2254 - val_loss: 1.3298 - val_mse: 1.0210\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.4454 - mse: 2.1608 - val_loss: 1.2755 - val_mse: 1.0359\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.3218 - mse: 2.1010 - val_loss: 1.2333 - val_mse: 1.0474\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.2263 - mse: 2.0551 - val_loss: 1.1746 - val_mse: 1.0307\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.1352 - mse: 2.0027 - val_loss: 1.1541 - val_mse: 1.0428\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 2.0521 - mse: 1.9496 - val_loss: 1.1557 - val_mse: 1.0697\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.9905 - mse: 1.9113 - val_loss: 1.1365 - val_mse: 1.0700\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.9257 - mse: 1.8645 - val_loss: 1.1069 - val_mse: 1.0554\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.8504 - mse: 1.8029 - val_loss: 1.0977 - val_mse: 1.0576\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.7780 - mse: 1.7409 - val_loss: 1.1020 - val_mse: 1.0706\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.7257 - mse: 1.6965 - val_loss: 1.1002 - val_mse: 1.0752\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.6482 - mse: 1.6249 - val_loss: 1.1078 - val_mse: 1.0877\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.5933 - mse: 1.5745 - val_loss: 1.1033 - val_mse: 1.0869\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.5417 - mse: 1.5262 - val_loss: 1.1579 - val_mse: 1.1442\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.5450 - mse: 1.5321 - val_loss: 1.1035 - val_mse: 1.0918\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.4736 - mse: 1.4624 - val_loss: 1.2019 - val_mse: 1.1918\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.4380 - mse: 1.4282 - val_loss: 1.1477 - val_mse: 1.1387\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.3664 - mse: 1.3577 - val_loss: 1.1279 - val_mse: 1.1198\n",
      "Epoch 33/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3074 - mse: 1.2994Restoring model weights from the end of the best epoch: 23.\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 1.2923 - mse: 1.2844 - val_loss: 1.1564 - val_mse: 1.1489\n",
      "Epoch 33: early stopping\n",
      "18/18 [==============================] - 1s 5ms/step\n",
      "Epoch 1/1000\n",
      "4/4 [==============================] - 5s 355ms/step - loss: 18.6155 - mse: 4.5152 - val_loss: 13.8384 - val_mse: 1.5993\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 15.0731 - mse: 3.6713 - val_loss: 11.2149 - val_mse: 1.4256\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 12.3853 - mse: 3.3113 - val_loss: 8.9205 - val_mse: 1.2064\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 10.0790 - mse: 2.9559 - val_loss: 7.1541 - val_mse: 1.1454\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 8.2404 - mse: 2.7080 - val_loss: 5.7252 - val_mse: 1.0850\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 6.8721 - mse: 2.6086 - val_loss: 4.6728 - val_mse: 1.1105\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.8339 - mse: 2.5647 - val_loss: 3.8216 - val_mse: 1.0956\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.0325 - mse: 2.5315 - val_loss: 3.1480 - val_mse: 1.0626\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.3938 - mse: 2.4797 - val_loss: 2.6439 - val_mse: 1.0455\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 3.9090 - mse: 2.4404 - val_loss: 2.2654 - val_mse: 1.0356\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 3.5388 - mse: 2.4069 - val_loss: 1.9787 - val_mse: 1.0272\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 3.2398 - mse: 2.3626 - val_loss: 1.7688 - val_mse: 1.0285\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 3.0156 - mse: 2.3319 - val_loss: 1.5997 - val_mse: 1.0207\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.8351 - mse: 2.2995 - val_loss: 1.5002 - val_mse: 1.0453\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.7146 - mse: 2.2935 - val_loss: 1.3939 - val_mse: 1.0352\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.5795 - mse: 2.2470 - val_loss: 1.3554 - val_mse: 1.0721\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.4745 - mse: 2.2118 - val_loss: 1.2473 - val_mse: 1.0231\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.3745 - mse: 2.1665 - val_loss: 1.2298 - val_mse: 1.0526\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.2900 - mse: 2.1256 - val_loss: 1.1493 - val_mse: 1.0090\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 2.2098 - mse: 2.0797 - val_loss: 1.1668 - val_mse: 1.0558\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.1245 - mse: 2.0215 - val_loss: 1.1301 - val_mse: 1.0420\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 2.0393 - mse: 1.9575 - val_loss: 1.1162 - val_mse: 1.0463\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 1.9491 - mse: 1.8841 - val_loss: 1.1132 - val_mse: 1.0573\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.8793 - mse: 1.8272 - val_loss: 1.0796 - val_mse: 1.0347\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.8115 - mse: 1.7696 - val_loss: 1.1130 - val_mse: 1.0767\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.7458 - mse: 1.7118 - val_loss: 1.0957 - val_mse: 1.0659\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.6961 - mse: 1.6681 - val_loss: 1.0876 - val_mse: 1.0630\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.6383 - mse: 1.6151 - val_loss: 1.1169 - val_mse: 1.0963\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.5558 - mse: 1.5363 - val_loss: 1.0666 - val_mse: 1.0492\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.5307 - mse: 1.5141 - val_loss: 1.1435 - val_mse: 1.1285\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.4637 - mse: 1.4494 - val_loss: 1.1233 - val_mse: 1.1103\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.4275 - mse: 1.4150 - val_loss: 1.1081 - val_mse: 1.0966\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.3805 - mse: 1.3694 - val_loss: 1.1582 - val_mse: 1.1479\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.3461 - mse: 1.3362 - val_loss: 1.1010 - val_mse: 1.0917\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.2686 - mse: 1.2595 - val_loss: 1.1520 - val_mse: 1.1434\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.2065 - mse: 1.1981 - val_loss: 1.1500 - val_mse: 1.1420\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.1625 - mse: 1.1547 - val_loss: 1.1131 - val_mse: 1.1056\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.1241 - mse: 1.1167 - val_loss: 1.1604 - val_mse: 1.1533\n",
      "Epoch 39/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0783 - mse: 1.0713Restoring model weights from the end of the best epoch: 29.\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1.0808 - mse: 1.0738 - val_loss: 1.1859 - val_mse: 1.1791\n",
      "Epoch 39: early stopping\n",
      "18/18 [==============================] - 1s 5ms/step\n",
      "Epoch 1/1000\n",
      "4/4 [==============================] - 5s 528ms/step - loss: 18.7372 - mse: 4.5712 - val_loss: 13.9921 - val_mse: 1.6744\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 15.1703 - mse: 3.6968 - val_loss: 11.2238 - val_mse: 1.3778\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 12.4155 - mse: 3.2922 - val_loss: 8.9306 - val_mse: 1.1821\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 10.0518 - mse: 2.9003 - val_loss: 7.1305 - val_mse: 1.1051\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 8.2164 - mse: 2.6727 - val_loss: 5.7603 - val_mse: 1.1186\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 6.8485 - mse: 2.5876 - val_loss: 4.6497 - val_mse: 1.0978\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 5.8027 - mse: 2.5469 - val_loss: 3.7822 - val_mse: 1.0747\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.9898 - mse: 2.5094 - val_loss: 3.1404 - val_mse: 1.0791\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.3631 - mse: 2.4742 - val_loss: 2.6192 - val_mse: 1.0478\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.8760 - mse: 2.4349 - val_loss: 2.2436 - val_mse: 1.0422\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 3.5000 - mse: 2.3970 - val_loss: 1.9552 - val_mse: 1.0329\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.2153 - mse: 2.3672 - val_loss: 1.7597 - val_mse: 1.0484\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 2.9863 - mse: 2.3312 - val_loss: 1.5944 - val_mse: 1.0432\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 2.7962 - mse: 2.2880 - val_loss: 1.4682 - val_mse: 1.0396\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.6448 - mse: 2.2493 - val_loss: 1.3821 - val_mse: 1.0481\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 2.5060 - mse: 2.1976 - val_loss: 1.3108 - val_mse: 1.0502\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.3781 - mse: 2.1376 - val_loss: 1.2545 - val_mse: 1.0513\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.2821 - mse: 2.0946 - val_loss: 1.2309 - val_mse: 1.0726\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.1790 - mse: 2.0329 - val_loss: 1.2082 - val_mse: 1.0850\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.0864 - mse: 1.9727 - val_loss: 1.1918 - val_mse: 1.0959\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.0261 - mse: 1.9377 - val_loss: 1.1745 - val_mse: 1.0999\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.9325 - mse: 1.8636 - val_loss: 1.1825 - val_mse: 1.1243\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 1.8793 - mse: 1.8255 - val_loss: 1.1441 - val_mse: 1.0985\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.8148 - mse: 1.7726 - val_loss: 1.1690 - val_mse: 1.1330\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.7508 - mse: 1.7173 - val_loss: 1.1441 - val_mse: 1.1154\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.6863 - mse: 1.6596 - val_loss: 1.1527 - val_mse: 1.1295\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.6355 - mse: 1.6138 - val_loss: 1.1584 - val_mse: 1.1395\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.5496 - mse: 1.5318 - val_loss: 1.1726 - val_mse: 1.1568\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.4919 - mse: 1.4770 - val_loss: 1.1721 - val_mse: 1.1588\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.4333 - mse: 1.4206 - val_loss: 1.1658 - val_mse: 1.1542\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.3578 - mse: 1.3468 - val_loss: 1.2078 - val_mse: 1.1977\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.3168 - mse: 1.3070 - val_loss: 1.2551 - val_mse: 1.2460\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.2614 - mse: 1.2526 - val_loss: 1.2348 - val_mse: 1.2265\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.2115 - mse: 1.2035 - val_loss: 1.2038 - val_mse: 1.1961\n",
      "Epoch 35/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1653 - mse: 1.1577Restoring model weights from the end of the best epoch: 25.\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 1.2001 - mse: 1.1926 - val_loss: 1.2586 - val_mse: 1.2514\n",
      "Epoch 35: early stopping\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1000\n",
      "4/4 [==============================] - 5s 388ms/step - loss: 18.6452 - mse: 4.5351 - val_loss: 13.8399 - val_mse: 1.6346\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 14.9772 - mse: 3.6305 - val_loss: 11.0326 - val_mse: 1.3351\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 12.1998 - mse: 3.2305 - val_loss: 8.7584 - val_mse: 1.1717\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 9.8590 - mse: 2.8705 - val_loss: 6.9598 - val_mse: 1.0978\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 8.0328 - mse: 2.6509 - val_loss: 5.5729 - val_mse: 1.0884\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 6.6872 - mse: 2.5802 - val_loss: 4.4887 - val_mse: 1.0830\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.6371 - mse: 2.5233 - val_loss: 3.6447 - val_mse: 1.0706\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.8424 - mse: 2.4909 - val_loss: 2.9908 - val_mse: 1.0493\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.2295 - mse: 2.4558 - val_loss: 2.5124 - val_mse: 1.0469\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 3.7569 - mse: 2.4171 - val_loss: 2.1491 - val_mse: 1.0399\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 3.4021 - mse: 2.3868 - val_loss: 1.8765 - val_mse: 1.0333\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.1265 - mse: 2.3535 - val_loss: 1.6908 - val_mse: 1.0468\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.8991 - mse: 2.3078 - val_loss: 1.5149 - val_mse: 1.0206\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 2.7273 - mse: 2.2729 - val_loss: 1.4095 - val_mse: 1.0288\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.5729 - mse: 2.2227 - val_loss: 1.3468 - val_mse: 1.0530\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 2.4471 - mse: 2.1767 - val_loss: 1.2813 - val_mse: 1.0542\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.3263 - mse: 2.1174 - val_loss: 1.2536 - val_mse: 1.0783\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.2536 - mse: 2.0923 - val_loss: 1.2161 - val_mse: 1.0809\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.1409 - mse: 2.0166 - val_loss: 1.2120 - val_mse: 1.1080\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.0775 - mse: 1.9819 - val_loss: 1.1475 - val_mse: 1.0675\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 1.9952 - mse: 1.9217 - val_loss: 1.1455 - val_mse: 1.0840\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.8963 - mse: 1.8397 - val_loss: 1.1060 - val_mse: 1.0585\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 1.8453 - mse: 1.8015 - val_loss: 1.1557 - val_mse: 1.1189\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.7636 - mse: 1.7296 - val_loss: 1.1188 - val_mse: 1.0901\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.6931 - mse: 1.6664 - val_loss: 1.1446 - val_mse: 1.1218\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.6211 - mse: 1.5999 - val_loss: 1.1628 - val_mse: 1.1445\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.5602 - mse: 1.5431 - val_loss: 1.1397 - val_mse: 1.1247\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.5068 - mse: 1.4927 - val_loss: 1.1980 - val_mse: 1.1855\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.4267 - mse: 1.4148 - val_loss: 1.1504 - val_mse: 1.1397\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.3575 - mse: 1.3473 - val_loss: 1.1656 - val_mse: 1.1562\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.3056 - mse: 1.2966 - val_loss: 1.1995 - val_mse: 1.1911\n",
      "Epoch 32/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2944 - mse: 1.2862Restoring model weights from the end of the best epoch: 22.\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 1.2666 - mse: 1.2585 - val_loss: 1.2349 - val_mse: 1.2273\n",
      "Epoch 32: early stopping\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1000\n",
      "4/4 [==============================] - 5s 359ms/step - loss: 18.7000 - mse: 4.5999 - val_loss: 13.8066 - val_mse: 1.6079\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 14.9731 - mse: 3.6344 - val_loss: 11.0930 - val_mse: 1.4076\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 12.2271 - mse: 3.2702 - val_loss: 8.7641 - val_mse: 1.1868\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 9.8611 - mse: 2.8803 - val_loss: 6.9417 - val_mse: 1.0841\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 8.0228 - mse: 2.6440 - val_loss: 5.5686 - val_mse: 1.0848\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 6.6794 - mse: 2.5721 - val_loss: 4.4881 - val_mse: 1.0807\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.6338 - mse: 2.5177 - val_loss: 3.6386 - val_mse: 1.0614\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.8360 - mse: 2.4812 - val_loss: 2.9980 - val_mse: 1.0527\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.2212 - mse: 2.4438 - val_loss: 2.5198 - val_mse: 1.0508\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.7606 - mse: 2.4174 - val_loss: 2.1546 - val_mse: 1.0422\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 3.3943 - mse: 2.3760 - val_loss: 1.8795 - val_mse: 1.0337\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.1167 - mse: 2.3411 - val_loss: 1.6839 - val_mse: 1.0375\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.8878 - mse: 2.2943 - val_loss: 1.5283 - val_mse: 1.0323\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.7015 - mse: 2.2456 - val_loss: 1.4418 - val_mse: 1.0598\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.5511 - mse: 2.1997 - val_loss: 1.3292 - val_mse: 1.0343\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 2.4126 - mse: 2.1413 - val_loss: 1.2676 - val_mse: 1.0400\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 2.2927 - mse: 2.0832 - val_loss: 1.2289 - val_mse: 1.0532\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.1631 - mse: 2.0015 - val_loss: 1.1841 - val_mse: 1.0487\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 2.0698 - mse: 1.9453 - val_loss: 1.1663 - val_mse: 1.0621\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 1.9715 - mse: 1.8758 - val_loss: 1.1560 - val_mse: 1.0760\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.8860 - mse: 1.8125 - val_loss: 1.1540 - val_mse: 1.0925\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.8088 - mse: 1.7522 - val_loss: 1.2107 - val_mse: 1.1633\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.7567 - mse: 1.7130 - val_loss: 1.2669 - val_mse: 1.2302\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.7229 - mse: 1.6889 - val_loss: 1.1365 - val_mse: 1.1078\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 1.6225 - mse: 1.5959 - val_loss: 1.1272 - val_mse: 1.1044\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.5307 - mse: 1.5095 - val_loss: 1.1700 - val_mse: 1.1517\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.4573 - mse: 1.4402 - val_loss: 1.2112 - val_mse: 1.1962\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.4152 - mse: 1.4011 - val_loss: 1.1749 - val_mse: 1.1624\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 1.3323 - mse: 1.3204 - val_loss: 1.1624 - val_mse: 1.1517\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.2987 - mse: 1.2884 - val_loss: 1.1452 - val_mse: 1.1358\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.2418 - mse: 1.2328 - val_loss: 1.1994 - val_mse: 1.1910\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.1783 - mse: 1.1702 - val_loss: 1.2044 - val_mse: 1.1967\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.1461 - mse: 1.1386 - val_loss: 1.1964 - val_mse: 1.1893\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.0873 - mse: 1.0803 - val_loss: 1.2453 - val_mse: 1.2385\n",
      "Epoch 35/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0865 - mse: 1.0798Restoring model weights from the end of the best epoch: 25.\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 1.0867 - mse: 1.0801 - val_loss: 1.1980 - val_mse: 1.1916\n",
      "Epoch 35: early stopping\n",
      "18/18 [==============================] - 1s 5ms/step\n",
      "Epoch 1/1000\n",
      "4/4 [==============================] - 5s 403ms/step - loss: 18.6331 - mse: 4.4991 - val_loss: 13.9091 - val_mse: 1.6461\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 15.0823 - mse: 3.6668 - val_loss: 11.1834 - val_mse: 1.3999\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 12.3279 - mse: 3.2664 - val_loss: 8.9007 - val_mse: 1.2110\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 9.9920 - mse: 2.8976 - val_loss: 7.1137 - val_mse: 1.1410\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 8.1544 - mse: 2.6608 - val_loss: 5.6939 - val_mse: 1.0973\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 6.7960 - mse: 2.5781 - val_loss: 4.6123 - val_mse: 1.0991\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.7379 - mse: 2.5189 - val_loss: 3.7613 - val_mse: 1.0873\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.9549 - mse: 2.5064 - val_loss: 3.1048 - val_mse: 1.0723\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.3244 - mse: 2.4629 - val_loss: 2.6191 - val_mse: 1.0724\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 3.8397 - mse: 2.4220 - val_loss: 2.2307 - val_mse: 1.0501\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.4593 - mse: 2.3757 - val_loss: 1.9532 - val_mse: 1.0481\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.1742 - mse: 2.3424 - val_loss: 1.7404 - val_mse: 1.0433\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.9561 - mse: 2.3145 - val_loss: 1.5900 - val_mse: 1.0508\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 2.7493 - mse: 2.2523 - val_loss: 1.4608 - val_mse: 1.0422\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 2.5863 - mse: 2.2002 - val_loss: 1.3856 - val_mse: 1.0599\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.4518 - mse: 2.1513 - val_loss: 1.3201 - val_mse: 1.0665\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 2.3350 - mse: 2.1010 - val_loss: 1.2433 - val_mse: 1.0458\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 2.2619 - mse: 2.0798 - val_loss: 1.2491 - val_mse: 1.0954\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 2.1691 - mse: 2.0274 - val_loss: 1.2322 - val_mse: 1.1128\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.0648 - mse: 1.9548 - val_loss: 1.1617 - val_mse: 1.0690\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.9905 - mse: 1.9050 - val_loss: 1.1712 - val_mse: 1.0991\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.9451 - mse: 1.8786 - val_loss: 1.2408 - val_mse: 1.1847\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.8839 - mse: 1.8320 - val_loss: 1.1550 - val_mse: 1.1111\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 1.8004 - mse: 1.7598 - val_loss: 1.1298 - val_mse: 1.0951\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 1.7747 - mse: 1.7426 - val_loss: 1.2298 - val_mse: 1.2022\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1.7239 - mse: 1.6982 - val_loss: 1.1444 - val_mse: 1.1221\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1.6252 - mse: 1.6044 - val_loss: 1.1803 - val_mse: 1.1622\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.5509 - mse: 1.5338 - val_loss: 1.1556 - val_mse: 1.1404\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 1.4906 - mse: 1.4763 - val_loss: 1.1924 - val_mse: 1.1795\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.4359 - mse: 1.4236 - val_loss: 1.1794 - val_mse: 1.1683\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1.3830 - mse: 1.3724 - val_loss: 1.2004 - val_mse: 1.1905\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1.3162 - mse: 1.3068 - val_loss: 1.2354 - val_mse: 1.2266\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 1.3038 - mse: 1.2953 - val_loss: 1.2055 - val_mse: 1.1975\n",
      "Epoch 34/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2441 - mse: 1.2362Restoring model weights from the end of the best epoch: 24.\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 1.2239 - mse: 1.2161 - val_loss: 1.2244 - val_mse: 1.2169\n",
      "Epoch 34: early stopping\n",
      "18/18 [==============================] - 2s 5ms/step\n",
      "0.002437387057604803\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
    "\n",
    "\n",
    "\n",
    "#決定這次的模型編號\n",
    "model_idx = 1\n",
    "#本次預測的變數為：slope(隱波與履約價之間的斜率)或iv(隱波的數值)\n",
    "forecast_variable = 'slope'\n",
    "#資料設定都相同的情況下，最多儲存多少種模型結果\n",
    "max_model = 20\n",
    "\n",
    "#設定參數\n",
    "batch_size = 500\n",
    "epochs = 1000\n",
    "\n",
    "OCHL_lstm_neurons_num = [lstm1_neurons_num1, lstm1_neurons_num2]\n",
    "OCHLE_lstm_activations = ['tanh']*len(OCHL_lstm_neurons_num)\n",
    "OCHL_lstm_recurrent_activations = ['sigmoid']*len(OCHL_lstm_neurons_num)\n",
    "OCHL_dense_neurons_num = [dense1_neurons_num]\n",
    "OCHL_dense_activations = ['relu']\n",
    "OCHL_kernel_regularizer=[l2(lambda1)]*(len(OCHL_lstm_neurons_num) + len(OCHL_dense_neurons_num))\n",
    "\n",
    "Slope_lstm_neurons_num = [lstm2_neurons_num1]\n",
    "Slope_lstm_activations = ['tanh']*len(Slope_lstm_neurons_num)\n",
    "Slope_lstm_recurrent_activations = ['sigmoid']*len(Slope_lstm_neurons_num)\n",
    "Slope_dense_neurons_num = [dense2_neurons_num]\n",
    "Slope_dense_activations = ['relu']\n",
    "Slope_kernel_regularizer=[l2(lambda2)]*(len(Slope_lstm_neurons_num) + len(Slope_dense_neurons_num))\n",
    "\n",
    "Merged_neurons_num = [merged_neurons_num1] \n",
    "Megred_activations = ['relu']*len(Merged_neurons_num)\n",
    "Merged_kernel_regularizer=[l2(lambda3)]*(len(Merged_neurons_num))\n",
    "\n",
    "lstm_OCHL_structure = {\n",
    "    'input_shape': OCHLE_train.shape[1:],\n",
    "    'lstm_neurons_num': OCHL_lstm_neurons_num,\n",
    "    'lstm_activations': OCHLE_lstm_activations,\n",
    "    'lstm_recurrent_activations':OCHL_lstm_recurrent_activations,\n",
    "    'dense_neurons_num':OCHL_dense_neurons_num,\n",
    "    'dense_activations':OCHL_dense_activations,\n",
    "    'kernel_regularizer':OCHL_kernel_regularizer\n",
    "}\n",
    "\n",
    "lstm_Slope_structure = {\n",
    "    'input_shape': X_train.shape[1:],\n",
    "    'lstm_neurons_num': Slope_lstm_neurons_num,\n",
    "    'lstm_activations': Slope_lstm_activations,\n",
    "    'lstm_recurrent_activations':Slope_lstm_recurrent_activations,\n",
    "    'dense_neurons_num':Slope_dense_neurons_num,\n",
    "    'dense_activations':Slope_dense_activations,\n",
    "    'kernel_regularizer':Slope_kernel_regularizer\n",
    "}\n",
    "\n",
    "Merged_structure = {\n",
    "    'neurons_num': Merged_neurons_num,\n",
    "    'activations': Megred_activations,\n",
    "    'kernel_regularizer': Merged_kernel_regularizer\n",
    "}\n",
    "\n",
    "alltrain = 10\n",
    "allMSE = np.zeros(alltrain)\n",
    "allMSE_adj = np.zeros(alltrain)  \n",
    "allForecastIV = np.zeros((K_num*len(OCHLE_test), alltrain))\n",
    "allSSE_everyday = np.zeros((K_num*len(OCHLE_test), alltrain))\n",
    "allSSE_everyday_adj = np.zeros((K_num*len(OCHLE_test), alltrain))\n",
    "for j in range(alltrain):\n",
    "    #設定模型結構\n",
    "    model = set_LSTM_LSTM(lstm_OCHL_structure, lstm_Slope_structure, Merged_structure)\n",
    "    model.compile(loss='mse', optimizer = 'adam', metrics=['mse'])  \n",
    "\n",
    "    # 訓練模型\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=10, \\\n",
    "                               verbose=2, mode='min', restore_best_weights=True)\n",
    "    hist_model = model.fit(\n",
    "        [OCHLE_train, X_train], y_train, epochs=epochs, batch_size=batch_size, \\\n",
    "        validation_split=0.2, callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #得到輸出\n",
    "    y_pred = model.predict([OCHLE_test, X_test])\n",
    "    y_pred = y_pred / magnification_slope\n",
    "    columns_names = ['履約價', '隱含波動率({})'.format(s_c)]\n",
    "    column_index = [IV_data.columns.get_loc(col) for col in columns_names]\n",
    "    ForecastIV = np.zeros(((len(y_pred), K_num)))\n",
    "    SSE_everyday = np.zeros(((len(y_pred), K_num)))\n",
    "    SSE_everyday_adj = np.zeros(((len(y_pred), K_num)))\n",
    "\n",
    "    model_name = 'model{}'.format(model_idx)\n",
    "    model_file = 'model{}.h5'.format(model_idx)\n",
    "    model_png = 'model{}.png'.format(model_idx)\n",
    "    Forecast_name = 'model{}.csv'.format(model_idx)\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        K_day = IV_matrix_test[i*K_num:(i+1)*K_num, column_index[0]]\n",
    "        iv_day = IV_matrix_test[i*K_num:(i+1)*K_num, column_index[1]]\n",
    "        y_pred_day = y_pred[i]\n",
    "        iv_day_mean = np.mean(iv_day)\n",
    "        ForecastIV[i], SSE_everyday_ = minSSE_recovery(y=iv_day, x=K_day, slope_yhat=y_pred_day)\n",
    "        SSE_everyday[i] = SSE_everyday_\n",
    "        SSE_everyday_adj[i] = SSE_everyday_ / iv_day_mean\n",
    "\n",
    "    ForecastIV = np.reshape(ForecastIV,(-1,1))\n",
    "    sse_everyday = SSE_everyday[:, 0]\n",
    "    sse_everyday_adj = SSE_everyday_adj[:, 0]\n",
    "    SSE_everyday = np.reshape(SSE_everyday ,(-1,1))\n",
    "    SSE_everyday_adj = np.reshape(SSE_everyday_adj ,(-1,1))\n",
    "    allMSE[j] = np.mean(sse_everyday)\n",
    "    allMSE_adj[j] = np.mean(sse_everyday_adj)\n",
    "    allForecastIV[:,j:j+1] = ForecastIV\n",
    "    allSSE_everyday[:, j:j+1] = SSE_everyday\n",
    "    allSSE_everyday_adj[:, j:j+1] = SSE_everyday_adj\n",
    "\n",
    "min_MSE_idx = np.argsort(allMSE)[0]\n",
    "ForecastIV = allForecastIV[:, min_MSE_idx:min_MSE_idx+1]\n",
    "SSE_everyday = allSSE_everyday[:, min_MSE_idx:min_MSE_idx+1]\n",
    "SSE_everyday_adj = allSSE_everyday_adj[:, min_MSE_idx:min_MSE_idx+1]\n",
    "min_MSE = allMSE[min_MSE_idx]\n",
    "min_MSE_adj = allMSE_adj[min_MSE_idx]\n",
    "\n",
    "Forecast_matrix  = np.hstack((IV_matrix_test, ForecastIV, SSE_everyday, SSE_everyday_adj))\n",
    "column = np.hstack((IV_data.columns.to_numpy(), \\\n",
    "                        np.array(['上市天數(交易日)','預測隱含波動率({})'.format(s_c), 'loss', '調整後loss'])))\n",
    "    \n",
    "   \n",
    "Forecast_Data = pd.DataFrame(data=Forecast_matrix, columns=column)\n",
    "\n",
    "\n",
    "loss_columns_names = ['交易日期', '到期天數', '上市天數(交易日)', 'loss']\n",
    "loss_columns_index = [Forecast_Data.columns.get_loc(col) for col in loss_columns_names]\n",
    "loss_Data = Forecast_Data.iloc[range(0, len(Forecast_Data), K_num), loss_columns_index]\n",
    "loss_Data = loss_Data.reset_index().iloc[:,1:]\n",
    "loss_Data = loss_Data.rename(columns={'loss': model_name})\n",
    "MSE_data = pd.DataFrame(columns=loss_Data.columns, data=[['MSE', 'MSE', 'MSE', min_MSE]])\n",
    "loss_Data = pd.concat([loss_Data, MSE_data], axis=0)\n",
    "loss_Data = loss_Data.reset_index().iloc[:,1:]\n",
    "print(min_MSE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_path = top_path\n",
    "model_type = 'LSTM-LSTM'\n",
    "\n",
    "model_Dir_tree = ['Forecast&model', expiry, IV_type, 'K_{}'.format(K_Range_dir), model_type,\\\n",
    "            'seq{}_seq{}_min{}'.format(seq_length1, seq_length2,min_contract_day), forecast_variable]\n",
    "for model_dir in model_Dir_tree:\n",
    "    if model_dir not in os.listdir(model_path):\n",
    "        os.mkdir(model_path + model_dir)\n",
    "    model_path = model_path + model_dir + '/'\n",
    "\n",
    "loss_adj_columns_names = ['交易日期', '到期天數', '調整後loss']\n",
    "loss_adj_columns_index = [Forecast_Data.columns.get_loc(col) for col in loss_adj_columns_names]\n",
    "loss_adj_Data = Forecast_Data.iloc[range(0, len(Forecast_Data), K_num), loss_adj_columns_index]\n",
    "loss_adj_Data = loss_adj_Data.reset_index().iloc[:,1:]\n",
    "loss_adj_Data = loss_adj_Data.rename(columns={'調整後loss': model_name})\n",
    "MSE_adj_data = pd.DataFrame(columns=loss_adj_Data.columns, data=[['MSE', 'MSE', min_MSE_adj]])\n",
    "loss_adj_Data = pd.concat([loss_adj_Data, MSE_adj_data], axis=0)\n",
    "loss_adj_Data = loss_adj_Data.reset_index().iloc[:,1:]\n",
    "\n",
    "\n",
    "\n",
    "if 'Modelloss.csv' in os.listdir(model_path):\n",
    "    Modelloss = pd.read_csv(model_path + 'Modelloss.csv', index_col=False, encoding='Big5')\n",
    "    Modelloss_adj = pd.read_csv(model_path + 'Modelloss_adj.csv', index_col=False, encoding='Big5')\n",
    "    if model_name in Modelloss.columns:\n",
    "        if Modelloss[model_name][len(Modelloss)-1] > min_MSE:\n",
    "            Modelloss[model_name] = loss_Data[model_name]\n",
    "            Modelloss_adj[model_name] = loss_adj_Data[model_name]\n",
    "            Forecast_Data.to_csv(model_path + Forecast_name, index=False, encoding='Big5')\n",
    "            model.save(model_path + model_file)\n",
    "            plot_model(model, to_file=model_path + model_png, show_shapes=True, show_layer_names=False)\n",
    "            print('原本的{}已經被替換'.format(model_name))\n",
    "        else:\n",
    "            print('此模型未被儲存')\n",
    "    elif len(Modelloss.columns) >= max_model+2 :\n",
    "        all_MSE = np.array(Modelloss.iloc[-1, 2:])\n",
    "        max_MSE = np.max(all_MSE)\n",
    "        if max_MSE > min_MSE:\n",
    "            max_MSE_idx = (np.arange(len(all_MSE))[np.equal(all_MSE, max_MSE)])[0] +2\n",
    "            Modelloss.iloc[:,max_MSE_idx] = loss_Data[model_name]\n",
    "            Modelloss_adj.iloc[:,max_MSE_idx] = loss_adj_Data[model_name]\n",
    "            model_name = Modelloss.columns[max_MSE_idx]\n",
    "            Forecast_name = model_name + '.csv'\n",
    "            model_file = model_name + '.h5'\n",
    "            model_png = model_name + '.png'\n",
    "            Forecast_Data.to_csv(model_path + Forecast_name, index=False, encoding='Big5')\n",
    "            model.save(model_path + model_file)\n",
    "            plot_model(model, to_file=model_path + model_png, show_shapes=True, show_layer_names=False)\n",
    "            print('原本的{}已經被替換'.format(model_name))\n",
    "        else:\n",
    "            print('此模型未被儲存')\n",
    "    else:\n",
    "        Modelloss = pd.concat([Modelloss, loss_Data[model_name]], axis=1)\n",
    "        Modelloss = Modelloss.reset_index().iloc[:,1:] \n",
    "        Modelloss_adj = pd.concat([Modelloss_adj, loss_Data[model_name]], axis=1)\n",
    "        Modelloss_adj = Modelloss_adj.reset_index().iloc[:,1:] \n",
    "        Forecast_Data.to_csv(model_path + Forecast_name, index=False, encoding='Big5')\n",
    "        model.save(model_path + model_file)\n",
    "        plot_model(model, to_file=model_path + model_png, show_shapes=True, show_layer_names=False)\n",
    "        print('此模型已經被儲存為{}'.format(model_name))\n",
    "else:\n",
    "    Modelloss = loss_Data\n",
    "    Modelloss_adj = loss_adj_Data\n",
    "    Forecast_Data.to_csv(model_path + Forecast_name, index=False, encoding='Big5')\n",
    "    model.save(model_path + model_file)\n",
    "    plot_model(model, to_file=model_path + model_png, show_shapes=True, show_layer_names=False)\n",
    "\n",
    "    \n",
    "Modelloss.to_csv(model_path + 'Modelloss.csv', index=False, encoding='Big5')\n",
    "Modelloss_adj.to_csv(model_path + 'Modelloss_adj.csv', index=False, encoding='Big5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
