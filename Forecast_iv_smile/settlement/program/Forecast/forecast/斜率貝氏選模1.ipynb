{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from function import Slope, minSSE_recovery\n",
    "\n",
    "s_c = '結算價'\n",
    "top_path = './../../../'\n",
    "Data_path = top_path + 'InterpData/'\n",
    "expiry = 'NearbyMonth'\n",
    "\n",
    "IV_type = 'callIV'\n",
    "K_Range = [300, 500]\n",
    "K_Range_file = '{}_{}.csv'.format(K_Range[0], K_Range[1])\n",
    "K_Range_dir = '{}_{}'.format(K_Range[0], K_Range[1])\n",
    "IV_path = '{}/{}/{}/{}'.format(Data_path, expiry, IV_type, K_Range_file)\n",
    "\n",
    "Dir_tree = [top_path, 'ForecastData', expiry, IV_type, K_Range_dir]\n",
    "current_path = Dir_tree[0]\n",
    "for i in range(1, len(Dir_tree), 1):\n",
    "    if Dir_tree[i] not in os.listdir(current_path):\n",
    "        os.mkdir(current_path + Dir_tree[i])\n",
    "    current_path = current_path + Dir_tree[i] + '/'\n",
    "\n",
    "IV_data = pd.read_csv(IV_path, encoding='Big5', index_col=False)\n",
    "IV_matrix = np.array(IV_data)\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "OC = np.array(IV_data['期貨開盤價'] - IV_data['期貨收盤價'])\n",
    "HL = np.array(IV_data['期貨最高價'] - IV_data['期貨最低價'])\n",
    "expirty_days = np.array(IV_data['到期天數'])\n",
    "#OC_HL_K_E = np.vstack((OC, HL, Kmin_reduce_F, Kmax_reduce_F, expirty_days)).T\n",
    "OCHL = np.vstack((OC, HL)).T\n",
    "\n",
    "\n",
    "IV_matrix = np.array(IV_data)\n",
    "K_num = len(np.where(IV_matrix[0, 0] == IV_matrix)[0])\n",
    "K = np.array(IV_data['履約價'])\n",
    "K = np.reshape(K, (-1, K_num))\n",
    "IV= np.array(IV_data['隱含波動率({})'.format(s_c)])\n",
    "IV = np.reshape(IV, (-1, K_num))\n",
    "K_IVslope = Slope(X=K, Y=IV, axis=1)\n",
    "E = IV_matrix[range(0, len(IV_matrix), K_num), IV_data.columns.get_loc('到期天數')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day_expiry_idx = np.arange(len(E))[np.equal(E, 1)]\n",
    "if one_day_expiry_idx[-1] == len(E)-1:\n",
    "    one_day_expiry_idx = one_day_expiry_idx[:-1]\n",
    "most_days_expiry_idx = one_day_expiry_idx + 1\n",
    "most_days_expiry_idx = np.hstack((0, most_days_expiry_idx))\n",
    "\n",
    "most_days_expiry_idx0 = most_days_expiry_idx[:-1]\n",
    "most_days_expiry_idx1 = most_days_expiry_idx[1:]\n",
    "trade_days_in_month = most_days_expiry_idx1 - most_days_expiry_idx0  \n",
    "most_days_expiry = E[most_days_expiry_idx]\n",
    "\n",
    "contract_appear_days1 = [list(range(1, trade_day_in_month+1, 1)) \\\n",
    "                for trade_day_in_month in trade_days_in_month]\n",
    "contract_appear_days1 = [contract_appear_day1 for subcontract_appear_day1 in contract_appear_days1\\\n",
    "                         for contract_appear_day1 in subcontract_appear_day1]\n",
    "contract_appear_days1 = np.array(contract_appear_days1)\n",
    "contract_appear_days2 = np.arange(1, len(E) - most_days_expiry_idx[-1] +1, 1)\n",
    "contract_appear_days = np.hstack((contract_appear_days1, contract_appear_days2))\n",
    "#contract_appear_days 為該契約(特定交易日期、到期日期，履約價不限)上市的交易日數，例如第一天上市到期天數35天，\n",
    "#則值為1，第二天則到期日為34天值為2，一直到k(因為是交易日數，所以數字不一定)。然後又到下個月的契約，值又從1開\n",
    "#始\n",
    "\n",
    "\n",
    "from function import TimeSeriesData\n",
    "seq_length1 = 7\n",
    "seq_length2 = seq_length1 + 1\n",
    "#seq_length2 = 16\n",
    "min_contract_day = 2\n",
    "magnification_slope = 10000\n",
    "\n",
    "\n",
    "#變數有考慮到期日\n",
    "#K_IVslope_E = np.hstack((K_IVslope*magnification_slope, np.reshape(E, (-1, 1))))\n",
    "\n",
    "#Inputs_slope, Ouputs = TimeSeriesData(K_IVslope_E, seq_length=seq_length1, \\\n",
    "                                      #drop_out_columns=[len(K_IVslope_E[0])-1])\n",
    "\n",
    "#變數沒考慮到期日\n",
    "K_IVslope_E = K_IVslope * magnification_slope\n",
    "Inputs_slope, Ouputs = TimeSeriesData(K_IVslope_E, seq_length=seq_length1, drop_out_columns=[])\n",
    "\n",
    "\n",
    "\n",
    "Inputs_OCHLE  = OCHL[range(0, len(IV_matrix), K_num)]\n",
    "Inputs_OCHLE  = np.array([Inputs_OCHLE[i:i+seq_length2] \\\n",
    "                              for i in range(len(Inputs_OCHLE)-seq_length2+1)])\n",
    "Inputs_OCHLE  = Inputs_OCHLE.astype(float)\n",
    "if seq_length1  > seq_length2-1:\n",
    "    Inputs_OCHLE = Inputs_OCHLE[seq_length1-seq_length2+1:]\n",
    "    contract_appear_days = contract_appear_days[seq_length1-seq_length2+1:]\n",
    "    IV_matrix_forecast = IV_matrix[seq_length1*K_num:]\n",
    "if seq_length1 <= seq_length2-1:\n",
    "    Inputs_slope = Inputs_slope[seq_length2-1-seq_length1:]\n",
    "    Ouputs = Ouputs[seq_length2-1-seq_length1:]\n",
    "    contract_appear_days = contract_appear_days[seq_length2-1:]\n",
    "    IV_matrix_forecast = IV_matrix[(seq_length2-1)*K_num:]\n",
    "\n",
    "\n",
    "match_cond = np.greater_equal(contract_appear_days, min_contract_day)\n",
    "Inputs_OCHLE = Inputs_OCHLE[match_cond]\n",
    "Inputs_slope = Inputs_slope[match_cond]\n",
    "contract_appear_days_filter = contract_appear_days[match_cond]\n",
    "contract_appear_days_filter_Knum = contract_appear_days_filter.repeat(K_num)\n",
    "match_cond_Knum = match_cond.repeat(K_num)\n",
    "IV_matrix_forecast = IV_matrix_forecast[match_cond_Knum]\n",
    "IV_matrix_forecast= np.hstack((IV_matrix_forecast, np.reshape(contract_appear_days_filter_Knum, (-1, 1))))\n",
    "Ouputs = Ouputs[match_cond]\n",
    "\n",
    "\n",
    "\n",
    "train_size = int(len(Inputs_slope)*0.8)\n",
    "#val_size = int(train_size*0.2)\n",
    "X_train = Inputs_slope[:train_size]\n",
    "#X_train = Inputs_slope[:train_size-val_size]\n",
    "#X_val = Inputs_slope[train_size - val_size:train_size]\n",
    "OCHLE_train = Inputs_OCHLE[:train_size ]\n",
    "#OCHLE_train = Inputs_OCHLE[:train_size - val_size]\n",
    "#OCHLE_val = Inputs_OCHLE[train_size - val_size:train_size]\n",
    "y_train = Ouputs[:train_size]\n",
    "#y_train = Ouputs[:train_size-val_size]\n",
    "#y_val = Ouputs[train_size - val_size:train_size]\n",
    "\n",
    "\n",
    "X_test = Inputs_slope[train_size:]\n",
    "y_test = Ouputs[train_size:]\n",
    "IV_matrix_test = IV_matrix_forecast[K_num*train_size:]\n",
    "OCHLE_test = Inputs_OCHLE[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "56/56 [==============================] - 13s 74ms/step - loss: 4.1236 - mse: 3.8528 - val_loss: 1.1801 - val_mse: 0.9589\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 3.3003 - mse: 3.0884 - val_loss: 1.0081 - val_mse: 0.8063\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 3.0212 - mse: 2.8286 - val_loss: 0.8235 - val_mse: 0.6397\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 2.9189 - mse: 2.7414 - val_loss: 0.8590 - val_mse: 0.6888\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.9116 - mse: 2.7467 - val_loss: 0.8674 - val_mse: 0.7060\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.8030 - mse: 2.6455 - val_loss: 0.8032 - val_mse: 0.6503\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 2.7788 - mse: 2.6289 - val_loss: 0.7925 - val_mse: 0.6445\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.7261 - mse: 2.5810 - val_loss: 0.8166 - val_mse: 0.6738\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.7743 - mse: 2.6300 - val_loss: 0.7936 - val_mse: 0.6487\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.7014 - mse: 2.5596 - val_loss: 0.7778 - val_mse: 0.6385\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 2.6763 - mse: 2.5381 - val_loss: 0.7972 - val_mse: 0.6581\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.7265 - mse: 2.5847 - val_loss: 0.7684 - val_mse: 0.6268\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 2s 42ms/step - loss: 2.5470 - mse: 2.4073 - val_loss: 0.8605 - val_mse: 0.7220\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 2.5343 - mse: 2.3958 - val_loss: 0.8359 - val_mse: 0.6997\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.6613 - mse: 2.5260 - val_loss: 0.8316 - val_mse: 0.6860\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 2s 42ms/step - loss: 2.8386 - mse: 2.6746 - val_loss: 0.7970 - val_mse: 0.6291\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 2s 42ms/step - loss: 2.7216 - mse: 2.5560 - val_loss: 0.9199 - val_mse: 0.7561\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.5965 - mse: 2.4322 - val_loss: 0.7716 - val_mse: 0.6089\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.5228 - mse: 2.3622 - val_loss: 0.8064 - val_mse: 0.6468\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 2.5014 - mse: 2.3438 - val_loss: 0.8074 - val_mse: 0.6504\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.3749 - mse: 2.2195 - val_loss: 0.7735 - val_mse: 0.6194\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 2.4422 - mse: 2.2897 - val_loss: 0.7659 - val_mse: 0.6111\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.7580 - mse: 2.6055 - val_loss: 0.7554 - val_mse: 0.6049\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 2.7251 - mse: 2.5742 - val_loss: 0.8002 - val_mse: 0.6503\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 2.5525 - mse: 2.4036 - val_loss: 0.8150 - val_mse: 0.6667\n",
      "Epoch 26/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 2.3826 - mse: 2.2352 - val_loss: 0.7457 - val_mse: 0.5994\n",
      "Epoch 27/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.3268 - mse: 2.1813 - val_loss: 0.7907 - val_mse: 0.6458\n",
      "Epoch 28/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.3730 - mse: 2.2274 - val_loss: 0.8529 - val_mse: 0.7064\n",
      "Epoch 29/1000\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 2.2972 - mse: 2.1516 - val_loss: 0.7551 - val_mse: 0.6106\n",
      "Epoch 30/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.2734 - mse: 2.1265 - val_loss: 0.7760 - val_mse: 0.6291\n",
      "Epoch 31/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.0934 - mse: 1.9461 - val_loss: 0.7432 - val_mse: 0.5955\n",
      "Epoch 32/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.0275 - mse: 1.8794 - val_loss: 0.7427 - val_mse: 0.5950\n",
      "Epoch 33/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.0405 - mse: 1.8942 - val_loss: 0.7401 - val_mse: 0.5939\n",
      "Epoch 34/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.1322 - mse: 1.9847 - val_loss: 0.7894 - val_mse: 0.6395\n",
      "Epoch 35/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 2.1482 - mse: 1.9982 - val_loss: 0.8383 - val_mse: 0.6871\n",
      "Epoch 36/1000\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 1.9480 - mse: 1.7971 - val_loss: 0.8065 - val_mse: 0.6558\n",
      "Epoch 37/1000\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 2.0218 - mse: 1.8712 - val_loss: 0.7997 - val_mse: 0.6479\n",
      "Epoch 38/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 1.8372 - mse: 1.6853 - val_loss: 0.7721 - val_mse: 0.6204\n",
      "Epoch 39/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 1.9475 - mse: 1.7961 - val_loss: 0.8922 - val_mse: 0.7411\n",
      "Epoch 40/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 1.8556 - mse: 1.7038 - val_loss: 0.7535 - val_mse: 0.6022\n",
      "Epoch 41/1000\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 1.7175 - mse: 1.5672 - val_loss: 0.8135 - val_mse: 0.6644\n",
      "Epoch 42/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 1.6384 - mse: 1.4894 - val_loss: 0.7490 - val_mse: 0.6021\n",
      "Epoch 43/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 1.7125 - mse: 1.5658Restoring model weights from the end of the best epoch: 33.\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 1.7236 - mse: 1.5770 - val_loss: 0.7807 - val_mse: 0.6339\n",
      "Epoch 43: early stopping\n",
      "18/18 [==============================] - 2s 19ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 10s 82ms/step - loss: 4.1942 - mse: 4.0208 - val_loss: 1.1761 - val_mse: 1.0259\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 3.4126 - mse: 3.2653 - val_loss: 1.0206 - val_mse: 0.8754\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 3.0823 - mse: 2.9409 - val_loss: 0.8765 - val_mse: 0.7404\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 2.9248 - mse: 2.7939 - val_loss: 0.8514 - val_mse: 0.7251\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 2.9599 - mse: 2.8372 - val_loss: 0.8761 - val_mse: 0.7568\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 2.8561 - mse: 2.7410 - val_loss: 0.8668 - val_mse: 0.7556\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 3s 49ms/step - loss: 2.8022 - mse: 2.6946 - val_loss: 0.8547 - val_mse: 0.7496\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 2.8189 - mse: 2.7155 - val_loss: 0.9222 - val_mse: 0.8201\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 2.8595 - mse: 2.7595 - val_loss: 0.9123 - val_mse: 0.8130\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 3s 51ms/step - loss: 2.7684 - mse: 2.6698 - val_loss: 0.8674 - val_mse: 0.7707\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 3s 49ms/step - loss: 2.7137 - mse: 2.6197 - val_loss: 0.8826 - val_mse: 0.7895\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 2.6020 - mse: 2.5097 - val_loss: 0.8150 - val_mse: 0.7241\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 2.6696 - mse: 2.5803 - val_loss: 0.8591 - val_mse: 0.7705\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 2.7189 - mse: 2.6264 - val_loss: 0.8631 - val_mse: 0.7674\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 2.6419 - mse: 2.5469 - val_loss: 0.8966 - val_mse: 0.8004\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 3s 50ms/step - loss: 2.4755 - mse: 2.3802 - val_loss: 0.9249 - val_mse: 0.8306\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 3s 50ms/step - loss: 2.5247 - mse: 2.4323 - val_loss: 0.8856 - val_mse: 0.7941\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 3s 51ms/step - loss: 2.3980 - mse: 2.3067 - val_loss: 0.8569 - val_mse: 0.7672\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 2.2300 - mse: 2.1420 - val_loss: 0.8869 - val_mse: 0.8013\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 2.2024 - mse: 2.1171 - val_loss: 0.8378 - val_mse: 0.7550\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 2.1302 - mse: 2.0485 - val_loss: 0.8385 - val_mse: 0.7567\n",
      "Epoch 22/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 2.0451 - mse: 1.9644Restoring model weights from the end of the best epoch: 12.\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 2.0645 - mse: 1.9838 - val_loss: 0.8314 - val_mse: 0.7516\n",
      "Epoch 22: early stopping\n",
      "18/18 [==============================] - 2s 19ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 7s 44ms/step - loss: 4.1152 - mse: 3.9033 - val_loss: 1.0301 - val_mse: 0.8652\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 3.1445 - mse: 2.9999 - val_loss: 0.8310 - val_mse: 0.7019\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 2.9416 - mse: 2.8222 - val_loss: 0.7918 - val_mse: 0.6809\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.8829 - mse: 2.7783 - val_loss: 0.8361 - val_mse: 0.7374\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.7748 - mse: 2.6802 - val_loss: 0.7492 - val_mse: 0.6586\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.6672 - mse: 2.5798 - val_loss: 0.7212 - val_mse: 0.6367\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.6897 - mse: 2.6069 - val_loss: 0.7503 - val_mse: 0.6687\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 2.6433 - mse: 2.5632 - val_loss: 0.8191 - val_mse: 0.7403\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.7403 - mse: 2.6617 - val_loss: 0.7661 - val_mse: 0.6871\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.5904 - mse: 2.5116 - val_loss: 0.7078 - val_mse: 0.6294\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.4805 - mse: 2.4025 - val_loss: 0.7402 - val_mse: 0.6625\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.5584 - mse: 2.4815 - val_loss: 0.7874 - val_mse: 0.7105\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 2.5295 - mse: 2.4528 - val_loss: 0.6766 - val_mse: 0.5999\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.4991 - mse: 2.4227 - val_loss: 0.7829 - val_mse: 0.7065\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 2.3834 - mse: 2.3076 - val_loss: 0.7936 - val_mse: 0.7188\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 2.4873 - mse: 2.4126 - val_loss: 0.7398 - val_mse: 0.6644\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 2.5136 - mse: 2.4373 - val_loss: 0.7689 - val_mse: 0.6914\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.3346 - mse: 2.2568 - val_loss: 0.7986 - val_mse: 0.7208\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.3175 - mse: 2.2393 - val_loss: 0.6910 - val_mse: 0.6126\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.0825 - mse: 2.0046 - val_loss: 0.7248 - val_mse: 0.6473\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 2.2072 - mse: 2.1289 - val_loss: 0.6760 - val_mse: 0.5971\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.2358 - mse: 2.1569 - val_loss: 0.7166 - val_mse: 0.6371\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.4248 - mse: 2.3450 - val_loss: 0.7367 - val_mse: 0.6559\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.3817 - mse: 2.3006 - val_loss: 0.6989 - val_mse: 0.6174\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.2837 - mse: 2.2025 - val_loss: 0.6881 - val_mse: 0.6076\n",
      "Epoch 26/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.1096 - mse: 2.0294 - val_loss: 0.7028 - val_mse: 0.6231\n",
      "Epoch 27/1000\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 2.0562 - mse: 1.9769 - val_loss: 0.7557 - val_mse: 0.6765\n",
      "Epoch 28/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.9845 - mse: 1.9056 - val_loss: 0.7277 - val_mse: 0.6491\n",
      "Epoch 29/1000\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 1.9421 - mse: 1.8640 - val_loss: 0.6821 - val_mse: 0.6046\n",
      "Epoch 30/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.8837 - mse: 1.8058 - val_loss: 0.7098 - val_mse: 0.6320\n",
      "Epoch 31/1000\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 1.8162 - mse: 1.7386 - val_loss: 0.6688 - val_mse: 0.5914\n",
      "Epoch 32/1000\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 1.8580 - mse: 1.7808 - val_loss: 0.7312 - val_mse: 0.6539\n",
      "Epoch 33/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.8888 - mse: 1.8108 - val_loss: 0.6878 - val_mse: 0.6088\n",
      "Epoch 34/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.8362 - mse: 1.7575 - val_loss: 0.6944 - val_mse: 0.6159\n",
      "Epoch 35/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.7886 - mse: 1.7099 - val_loss: 0.6843 - val_mse: 0.6052\n",
      "Epoch 36/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.6844 - mse: 1.6057 - val_loss: 0.6797 - val_mse: 0.6012\n",
      "Epoch 37/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.6464 - mse: 1.5684 - val_loss: 0.6600 - val_mse: 0.5823\n",
      "Epoch 38/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.5664 - mse: 1.4888 - val_loss: 0.6731 - val_mse: 0.5954\n",
      "Epoch 39/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.5572 - mse: 1.4801 - val_loss: 0.6752 - val_mse: 0.5984\n",
      "Epoch 40/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.4911 - mse: 1.4146 - val_loss: 0.6745 - val_mse: 0.5984\n",
      "Epoch 41/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.4695 - mse: 1.3937 - val_loss: 0.6616 - val_mse: 0.5860\n",
      "Epoch 42/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.4597 - mse: 1.3844 - val_loss: 0.6713 - val_mse: 0.5963\n",
      "Epoch 43/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.4270 - mse: 1.3521 - val_loss: 0.6861 - val_mse: 0.6114\n",
      "Epoch 44/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.5228 - mse: 1.4481 - val_loss: 0.6893 - val_mse: 0.6146\n",
      "Epoch 45/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.5817 - mse: 1.5067 - val_loss: 0.7233 - val_mse: 0.6480\n",
      "Epoch 46/1000\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 1.5678 - mse: 1.4918 - val_loss: 0.6647 - val_mse: 0.5884\n",
      "Epoch 47/1000\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 1.4578 - mse: 1.3817Restoring model weights from the end of the best epoch: 37.\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 1.4374 - mse: 1.3613 - val_loss: 0.6994 - val_mse: 0.6235\n",
      "Epoch 47: early stopping\n",
      "18/18 [==============================] - 1s 10ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 7s 51ms/step - loss: 4.6720 - mse: 3.1820 - val_loss: 0.8980 - val_mse: 0.6324\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.8852 - mse: 2.7563 - val_loss: 0.7064 - val_mse: 0.6540\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.7115 - mse: 2.6819 - val_loss: 0.6128 - val_mse: 0.5974\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 2.6122 - mse: 2.6021 - val_loss: 0.6330 - val_mse: 0.6265\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.5239 - mse: 2.5189 - val_loss: 0.6473 - val_mse: 0.6433\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.3630 - mse: 2.3595 - val_loss: 0.6040 - val_mse: 0.6008\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 2s 35ms/step - loss: 2.3525 - mse: 2.3495 - val_loss: 0.6158 - val_mse: 0.6128\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 2.3047 - mse: 2.3017 - val_loss: 0.5813 - val_mse: 0.5783\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 2.2525 - mse: 2.2495 - val_loss: 0.6169 - val_mse: 0.6139\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.0983 - mse: 2.0953 - val_loss: 0.6342 - val_mse: 0.6311\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.0120 - mse: 2.0089 - val_loss: 0.6232 - val_mse: 0.6201\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 1.8933 - mse: 1.8902 - val_loss: 0.5855 - val_mse: 0.5823\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 1.8108 - mse: 1.8076 - val_loss: 0.6174 - val_mse: 0.6142\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 1.6584 - mse: 1.6551 - val_loss: 0.6233 - val_mse: 0.6200\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 1.6630 - mse: 1.6597 - val_loss: 0.6281 - val_mse: 0.6248\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 1.5502 - mse: 1.5468 - val_loss: 0.6311 - val_mse: 0.6277\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 1.6216 - mse: 1.6182 - val_loss: 0.6632 - val_mse: 0.6598\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 1.5101 - mse: 1.5067Restoring model weights from the end of the best epoch: 8.\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 1.5101 - mse: 1.5067 - val_loss: 0.6298 - val_mse: 0.6263\n",
      "Epoch 18: early stopping\n",
      "18/18 [==============================] - 1s 13ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 8s 52ms/step - loss: 5.8149 - mse: 3.5128 - val_loss: 1.6427 - val_mse: 0.7752\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 3.5519 - mse: 2.9244 - val_loss: 1.1551 - val_mse: 0.6863\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 3.1800 - mse: 2.7952 - val_loss: 1.0092 - val_mse: 0.6885\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 3.0903 - mse: 2.7873 - val_loss: 0.9685 - val_mse: 0.6912\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 2.9656 - mse: 2.7110 - val_loss: 0.9300 - val_mse: 0.6980\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 2.8976 - mse: 2.6815 - val_loss: 0.9836 - val_mse: 0.7763\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 2.8438 - mse: 2.6385 - val_loss: 0.9539 - val_mse: 0.7597\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 2.8601 - mse: 2.6696 - val_loss: 0.8869 - val_mse: 0.6797\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 2.8101 - mse: 2.6084 - val_loss: 0.8804 - val_mse: 0.6642\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 2.8033 - mse: 2.5963 - val_loss: 0.8718 - val_mse: 0.6797\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 2.7123 - mse: 2.5097 - val_loss: 0.8337 - val_mse: 0.6326\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 2.7829 - mse: 2.5750 - val_loss: 0.9053 - val_mse: 0.6961\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 2.6931 - mse: 2.4801 - val_loss: 0.9131 - val_mse: 0.6852\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 2.7670 - mse: 2.5368 - val_loss: 0.9465 - val_mse: 0.7211\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 2.6833 - mse: 2.4445 - val_loss: 0.9020 - val_mse: 0.6680\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 2.7898 - mse: 2.5413 - val_loss: 0.9858 - val_mse: 0.7070\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 2.7487 - mse: 2.4709 - val_loss: 0.9251 - val_mse: 0.6581\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 2.6168 - mse: 2.3680 - val_loss: 0.8673 - val_mse: 0.6275\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 2.6697 - mse: 2.4315 - val_loss: 1.0501 - val_mse: 0.7815\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 2.8154 - mse: 2.5109 - val_loss: 0.9550 - val_mse: 0.6113\n",
      "Epoch 21/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 2.7018 - mse: 2.3576Restoring model weights from the end of the best epoch: 11.\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 2.7978 - mse: 2.4535 - val_loss: 0.9597 - val_mse: 0.6092\n",
      "Epoch 21: early stopping\n",
      "18/18 [==============================] - 1s 12ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 12s 79ms/step - loss: 7.9201 - mse: 4.0300 - val_loss: 2.0546 - val_mse: 0.9703\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 4.0047 - mse: 3.4041 - val_loss: 1.2829 - val_mse: 0.9147\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 3.3560 - mse: 3.0302 - val_loss: 1.0150 - val_mse: 0.7333\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 3.0938 - mse: 2.8470 - val_loss: 0.9268 - val_mse: 0.7068\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 2.9635 - mse: 2.7621 - val_loss: 0.9335 - val_mse: 0.7490\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 2.8921 - mse: 2.7173 - val_loss: 0.8647 - val_mse: 0.6976\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 2.9518 - mse: 2.7940 - val_loss: 0.8948 - val_mse: 0.7429\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.8605 - mse: 2.7136 - val_loss: 1.0091 - val_mse: 0.8626\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 2.8359 - mse: 2.6893 - val_loss: 0.9344 - val_mse: 0.7940\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 2.7310 - mse: 2.5942 - val_loss: 0.8839 - val_mse: 0.7552\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.8768 - mse: 2.7458 - val_loss: 0.9373 - val_mse: 0.7947\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.8863 - mse: 2.7300 - val_loss: 0.8317 - val_mse: 0.6775\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 2.9007 - mse: 2.7504 - val_loss: 0.9087 - val_mse: 0.7626\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 2.7980 - mse: 2.6535 - val_loss: 0.8253 - val_mse: 0.6827\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.7226 - mse: 2.5804 - val_loss: 0.8595 - val_mse: 0.7247\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.8929 - mse: 2.7470 - val_loss: 0.9534 - val_mse: 0.8044\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 2.7301 - mse: 2.5865 - val_loss: 0.9802 - val_mse: 0.8247\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.8825 - mse: 2.7168 - val_loss: 0.9793 - val_mse: 0.8238\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 2.7740 - mse: 2.6264 - val_loss: 1.0045 - val_mse: 0.8618\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 2.7527 - mse: 2.6070 - val_loss: 0.8057 - val_mse: 0.6652\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 2.5532 - mse: 2.4160 - val_loss: 0.8698 - val_mse: 0.7370\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 2.6464 - mse: 2.5124 - val_loss: 0.9472 - val_mse: 0.8066\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.6677 - mse: 2.5247 - val_loss: 0.8238 - val_mse: 0.6841\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 2.6553 - mse: 2.5195 - val_loss: 0.8598 - val_mse: 0.7231\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 2.8478 - mse: 2.7028 - val_loss: 1.0148 - val_mse: 0.8353\n",
      "Epoch 26/1000\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 2.8441 - mse: 2.6524 - val_loss: 0.9107 - val_mse: 0.7240\n",
      "Epoch 27/1000\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 2.6425 - mse: 2.4622 - val_loss: 0.8664 - val_mse: 0.6927\n",
      "Epoch 28/1000\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 2.6808 - mse: 2.5037 - val_loss: 0.9406 - val_mse: 0.7563\n",
      "Epoch 29/1000\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 2.6341 - mse: 2.4620 - val_loss: 0.8143 - val_mse: 0.6506\n",
      "Epoch 30/1000\n",
      "56/56 [==============================] - 3s 50ms/step - loss: 2.5382 - mse: 2.3791 - val_loss: 0.8050 - val_mse: 0.6490\n",
      "Epoch 31/1000\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 2.5008 - mse: 2.3436 - val_loss: 0.8809 - val_mse: 0.7310\n",
      "Epoch 32/1000\n",
      "56/56 [==============================] - 3s 50ms/step - loss: 2.5010 - mse: 2.3561 - val_loss: 0.8523 - val_mse: 0.7116\n",
      "Epoch 33/1000\n",
      "56/56 [==============================] - 3s 49ms/step - loss: 2.4452 - mse: 2.3082 - val_loss: 0.8363 - val_mse: 0.7009\n",
      "Epoch 34/1000\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 2.4065 - mse: 2.2747 - val_loss: 0.8051 - val_mse: 0.6759\n",
      "Epoch 35/1000\n",
      "56/56 [==============================] - 3s 50ms/step - loss: 2.3623 - mse: 2.2350 - val_loss: 0.7644 - val_mse: 0.6396\n",
      "Epoch 36/1000\n",
      "56/56 [==============================] - 3s 49ms/step - loss: 2.3249 - mse: 2.2030 - val_loss: 0.8970 - val_mse: 0.7790\n",
      "Epoch 37/1000\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 2.3117 - mse: 2.1952 - val_loss: 0.7628 - val_mse: 0.6459\n",
      "Epoch 38/1000\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 2.3506 - mse: 2.2356 - val_loss: 0.7917 - val_mse: 0.6762\n",
      "Epoch 39/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.4258 - mse: 2.3122 - val_loss: 0.7449 - val_mse: 0.6321\n",
      "Epoch 40/1000\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 2.3933 - mse: 2.2815 - val_loss: 0.7976 - val_mse: 0.6868\n",
      "Epoch 41/1000\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 2.4201 - mse: 2.3100 - val_loss: 0.7937 - val_mse: 0.6851\n",
      "Epoch 42/1000\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 2.3889 - mse: 2.2785 - val_loss: 0.8020 - val_mse: 0.6916\n",
      "Epoch 43/1000\n",
      "56/56 [==============================] - 3s 49ms/step - loss: 2.4532 - mse: 2.3384 - val_loss: 0.7961 - val_mse: 0.6777\n",
      "Epoch 44/1000\n",
      "56/56 [==============================] - 3s 50ms/step - loss: 2.3570 - mse: 2.2435 - val_loss: 0.8141 - val_mse: 0.7018\n",
      "Epoch 45/1000\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 2.3750 - mse: 2.2614 - val_loss: 0.7454 - val_mse: 0.6330\n",
      "Epoch 46/1000\n",
      "56/56 [==============================] - 3s 49ms/step - loss: 2.3531 - mse: 2.2444 - val_loss: 0.8593 - val_mse: 0.7540\n",
      "Epoch 47/1000\n",
      "56/56 [==============================] - 3s 49ms/step - loss: 2.3710 - mse: 2.2636 - val_loss: 0.7785 - val_mse: 0.6710\n",
      "Epoch 48/1000\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 2.3124 - mse: 2.2064 - val_loss: 0.7809 - val_mse: 0.6765\n",
      "Epoch 49/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 2.3216 - mse: 2.2190Restoring model weights from the end of the best epoch: 39.\n",
      "56/56 [==============================] - 3s 51ms/step - loss: 2.3042 - mse: 2.2016 - val_loss: 0.7723 - val_mse: 0.6705\n",
      "Epoch 49: early stopping\n",
      "18/18 [==============================] - 2s 25ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 7s 40ms/step - loss: 4.8913 - mse: 3.9211 - val_loss: 1.5569 - val_mse: 0.9159\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 3.6145 - mse: 3.0761 - val_loss: 1.1968 - val_mse: 0.7346\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 3.2497 - mse: 2.8243 - val_loss: 1.0875 - val_mse: 0.6988\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 3.1086 - mse: 2.7470 - val_loss: 1.0246 - val_mse: 0.6899\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 3.1095 - mse: 2.7901 - val_loss: 1.0135 - val_mse: 0.7075\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.9378 - mse: 2.6512 - val_loss: 0.9406 - val_mse: 0.6717\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.9026 - mse: 2.6424 - val_loss: 0.8674 - val_mse: 0.6242\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.8236 - mse: 2.5860 - val_loss: 0.8548 - val_mse: 0.6216\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.7906 - mse: 2.5639 - val_loss: 0.8942 - val_mse: 0.6751\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 2.7689 - mse: 2.5516 - val_loss: 0.8905 - val_mse: 0.6762\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 2.7219 - mse: 2.5111 - val_loss: 0.9641 - val_mse: 0.7605\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 2.7946 - mse: 2.5853 - val_loss: 0.8601 - val_mse: 0.6528\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 2.6763 - mse: 2.4739 - val_loss: 0.9745 - val_mse: 0.7762\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 2.6735 - mse: 2.4704 - val_loss: 1.0285 - val_mse: 0.8213\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 2.5744 - mse: 2.3710 - val_loss: 0.8809 - val_mse: 0.6789\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.5587 - mse: 2.3605 - val_loss: 0.9100 - val_mse: 0.7144\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.4266 - mse: 2.2334 - val_loss: 0.8607 - val_mse: 0.6721\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.4151 - mse: 2.2292 - val_loss: 0.8387 - val_mse: 0.6577\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 2.3942 - mse: 2.2154 - val_loss: 0.8410 - val_mse: 0.6593\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.3230 - mse: 2.1422 - val_loss: 0.8335 - val_mse: 0.6561\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 2.2274 - mse: 2.0519 - val_loss: 0.8436 - val_mse: 0.6725\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 2.1700 - mse: 1.9986 - val_loss: 0.8241 - val_mse: 0.6549\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 2.0872 - mse: 1.9212 - val_loss: 0.8688 - val_mse: 0.7076\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.1027 - mse: 1.9392 - val_loss: 0.8709 - val_mse: 0.7056\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.0337 - mse: 1.8686 - val_loss: 0.9226 - val_mse: 0.7548\n",
      "Epoch 26/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.0357 - mse: 1.8663 - val_loss: 0.8421 - val_mse: 0.6742\n",
      "Epoch 27/1000\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 1.9263 - mse: 1.7583 - val_loss: 0.8167 - val_mse: 0.6490\n",
      "Epoch 28/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.8653 - mse: 1.6982 - val_loss: 0.8577 - val_mse: 0.6915\n",
      "Epoch 29/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.7591 - mse: 1.5941 - val_loss: 0.8932 - val_mse: 0.7285\n",
      "Epoch 30/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.6986 - mse: 1.5350 - val_loss: 0.8751 - val_mse: 0.7133\n",
      "Epoch 31/1000\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 1.6243 - mse: 1.4627 - val_loss: 0.9041 - val_mse: 0.7439\n",
      "Epoch 32/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.5671 - mse: 1.4050 - val_loss: 0.8624 - val_mse: 0.7009\n",
      "Epoch 33/1000\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 1.5960 - mse: 1.4377 - val_loss: 0.8676 - val_mse: 0.7102\n",
      "Epoch 34/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.5489 - mse: 1.3913 - val_loss: 0.8673 - val_mse: 0.7096\n",
      "Epoch 35/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.5175 - mse: 1.3615 - val_loss: 0.8403 - val_mse: 0.6850\n",
      "Epoch 36/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.4734 - mse: 1.3196 - val_loss: 0.8412 - val_mse: 0.6870\n",
      "Epoch 37/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 1.4298 - mse: 1.2803Restoring model weights from the end of the best epoch: 27.\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.4504 - mse: 1.3009 - val_loss: 0.8630 - val_mse: 0.7156\n",
      "Epoch 37: early stopping\n",
      "18/18 [==============================] - 1s 10ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 15s 107ms/step - loss: 5.1325 - mse: 3.9950 - val_loss: 1.4400 - val_mse: 0.8953\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 4s 67ms/step - loss: 3.4411 - mse: 3.0185 - val_loss: 1.0793 - val_mse: 0.7394\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 4s 66ms/step - loss: 3.1651 - mse: 2.8700 - val_loss: 0.9759 - val_mse: 0.7198\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 4s 66ms/step - loss: 3.0339 - mse: 2.7990 - val_loss: 0.9188 - val_mse: 0.7017\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 4s 64ms/step - loss: 2.9788 - mse: 2.7781 - val_loss: 0.9519 - val_mse: 0.7672\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 4s 66ms/step - loss: 2.8582 - mse: 2.6829 - val_loss: 0.8076 - val_mse: 0.6426\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 4s 65ms/step - loss: 2.8430 - mse: 2.6848 - val_loss: 0.8419 - val_mse: 0.6876\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 4s 63ms/step - loss: 2.8099 - mse: 2.6616 - val_loss: 0.8321 - val_mse: 0.6880\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 4s 64ms/step - loss: 2.9325 - mse: 2.7654 - val_loss: 0.9006 - val_mse: 0.7126\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 4s 64ms/step - loss: 2.8894 - mse: 2.7086 - val_loss: 0.8285 - val_mse: 0.6566\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 4s 64ms/step - loss: 2.7179 - mse: 2.5542 - val_loss: 0.8873 - val_mse: 0.7309\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 4s 65ms/step - loss: 2.6722 - mse: 2.5207 - val_loss: 0.7918 - val_mse: 0.6455\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 4s 65ms/step - loss: 2.6868 - mse: 2.5434 - val_loss: 0.7830 - val_mse: 0.6412\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 4s 65ms/step - loss: 2.6695 - mse: 2.5285 - val_loss: 0.7936 - val_mse: 0.6518\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 4s 65ms/step - loss: 2.6843 - mse: 2.5423 - val_loss: 0.7889 - val_mse: 0.6472\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 4s 65ms/step - loss: 2.6867 - mse: 2.5485 - val_loss: 0.7687 - val_mse: 0.6332\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 4s 64ms/step - loss: 2.5312 - mse: 2.3977 - val_loss: 0.8738 - val_mse: 0.7395\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 4s 64ms/step - loss: 2.5221 - mse: 2.3924 - val_loss: 0.7747 - val_mse: 0.6467\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 4s 65ms/step - loss: 2.4605 - mse: 2.3353 - val_loss: 0.7848 - val_mse: 0.6622\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 4s 66ms/step - loss: 2.3494 - mse: 2.2287 - val_loss: 0.7131 - val_mse: 0.5959\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 4s 68ms/step - loss: 2.3357 - mse: 2.2210 - val_loss: 0.8150 - val_mse: 0.7007\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 4s 73ms/step - loss: 2.4173 - mse: 2.3022 - val_loss: 0.7554 - val_mse: 0.6386\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 4s 72ms/step - loss: 2.4252 - mse: 2.3064 - val_loss: 0.8855 - val_mse: 0.7707\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 4s 72ms/step - loss: 2.6811 - mse: 2.5629 - val_loss: 0.8495 - val_mse: 0.7274\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 3s 62ms/step - loss: 2.5788 - mse: 2.4505 - val_loss: 0.9071 - val_mse: 0.7781\n",
      "Epoch 26/1000\n",
      "56/56 [==============================] - 4s 71ms/step - loss: 2.3928 - mse: 2.2664 - val_loss: 0.9004 - val_mse: 0.7754\n",
      "Epoch 27/1000\n",
      "56/56 [==============================] - 4s 71ms/step - loss: 2.5193 - mse: 2.3919 - val_loss: 0.8376 - val_mse: 0.7102\n",
      "Epoch 28/1000\n",
      "56/56 [==============================] - 4s 71ms/step - loss: 2.2948 - mse: 2.1679 - val_loss: 0.7787 - val_mse: 0.6542\n",
      "Epoch 29/1000\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 2.4337 - mse: 2.3090 - val_loss: 0.9863 - val_mse: 0.8233\n",
      "Epoch 30/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 2.6264 - mse: 2.3962Restoring model weights from the end of the best epoch: 20.\n",
      "56/56 [==============================] - 4s 66ms/step - loss: 2.6264 - mse: 2.3962 - val_loss: 0.9599 - val_mse: 0.7326\n",
      "Epoch 30: early stopping\n",
      "18/18 [==============================] - 3s 34ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 14s 89ms/step - loss: 4.8180 - mse: 3.9511 - val_loss: 1.4278 - val_mse: 1.1113\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 3.3146 - mse: 3.1026 - val_loss: 0.8755 - val_mse: 0.7320\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 2.9204 - mse: 2.8065 - val_loss: 0.8137 - val_mse: 0.7242\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 3s 49ms/step - loss: 2.8464 - mse: 2.7707 - val_loss: 0.7082 - val_mse: 0.6449\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 2.7540 - mse: 2.6991 - val_loss: 0.7726 - val_mse: 0.7252\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 3s 51ms/step - loss: 2.7290 - mse: 2.6868 - val_loss: 0.6958 - val_mse: 0.6583\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 2.6728 - mse: 2.6390 - val_loss: 0.6810 - val_mse: 0.6504\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 2.7005 - mse: 2.6720 - val_loss: 0.7673 - val_mse: 0.7411\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 2.6480 - mse: 2.6232 - val_loss: 0.6408 - val_mse: 0.6174\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 2.5775 - mse: 2.5554 - val_loss: 0.6426 - val_mse: 0.6217\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 2.4775 - mse: 2.4575 - val_loss: 0.6672 - val_mse: 0.6480\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 2.5243 - mse: 2.5058 - val_loss: 0.6759 - val_mse: 0.6580\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 2.6518 - mse: 2.6343 - val_loss: 0.6969 - val_mse: 0.6796\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 2.4547 - mse: 2.4379 - val_loss: 0.6854 - val_mse: 0.6693\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 2.4793 - mse: 2.4633 - val_loss: 0.6313 - val_mse: 0.6154\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 2.6078 - mse: 2.5920 - val_loss: 0.6481 - val_mse: 0.6323\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 2.4973 - mse: 2.4818 - val_loss: 0.6562 - val_mse: 0.6409\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.3121 - mse: 2.2970 - val_loss: 0.6379 - val_mse: 0.6227\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 2.3519 - mse: 2.3371 - val_loss: 0.6263 - val_mse: 0.6118\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 2.2483 - mse: 2.2339 - val_loss: 0.6290 - val_mse: 0.6150\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 2.1994 - mse: 2.1853 - val_loss: 0.6789 - val_mse: 0.6648\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 2.1787 - mse: 2.1649 - val_loss: 0.6443 - val_mse: 0.6306\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 2.1729 - mse: 2.1595 - val_loss: 0.6416 - val_mse: 0.6281\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 2.0984 - mse: 2.0851 - val_loss: 0.6042 - val_mse: 0.5910\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 2.0550 - mse: 2.0420 - val_loss: 0.6274 - val_mse: 0.6145\n",
      "Epoch 26/1000\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 2.1477 - mse: 2.1346 - val_loss: 0.6794 - val_mse: 0.6662\n",
      "Epoch 27/1000\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 2.0877 - mse: 2.0745 - val_loss: 0.6358 - val_mse: 0.6227\n",
      "Epoch 28/1000\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 1.9772 - mse: 1.9641 - val_loss: 0.6298 - val_mse: 0.6167\n",
      "Epoch 29/1000\n",
      "56/56 [==============================] - 3s 49ms/step - loss: 2.0732 - mse: 2.0600 - val_loss: 0.6934 - val_mse: 0.6799\n",
      "Epoch 30/1000\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 2.2570 - mse: 2.2436 - val_loss: 0.6699 - val_mse: 0.6564\n",
      "Epoch 31/1000\n",
      "56/56 [==============================] - 3s 49ms/step - loss: 1.9282 - mse: 1.9147 - val_loss: 0.6624 - val_mse: 0.6487\n",
      "Epoch 32/1000\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 1.9388 - mse: 1.9249 - val_loss: 0.6490 - val_mse: 0.6344\n",
      "Epoch 33/1000\n",
      "56/56 [==============================] - 3s 49ms/step - loss: 2.0552 - mse: 2.0212 - val_loss: 0.7414 - val_mse: 0.6551\n",
      "Epoch 34/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 2.2208 - mse: 2.0354Restoring model weights from the end of the best epoch: 24.\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 2.2111 - mse: 2.0269 - val_loss: 0.7299 - val_mse: 0.6285\n",
      "Epoch 34: early stopping\n",
      "18/18 [==============================] - 3s 26ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 10s 79ms/step - loss: 7.8093 - mse: 3.9362 - val_loss: 1.7230 - val_mse: 0.9067\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 2s 35ms/step - loss: 3.7487 - mse: 3.1542 - val_loss: 1.3562 - val_mse: 0.8715\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 2s 36ms/step - loss: 3.3651 - mse: 2.9551 - val_loss: 1.0600 - val_mse: 0.7414\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 2s 35ms/step - loss: 3.1552 - mse: 2.8726 - val_loss: 0.9599 - val_mse: 0.6881\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 2s 35ms/step - loss: 3.0189 - mse: 2.7801 - val_loss: 0.9594 - val_mse: 0.7488\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 2s 36ms/step - loss: 3.0428 - mse: 2.8303 - val_loss: 0.8840 - val_mse: 0.6914\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 2s 37ms/step - loss: 2.9874 - mse: 2.7873 - val_loss: 0.8805 - val_mse: 0.6950\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 2.8778 - mse: 2.7033 - val_loss: 0.9278 - val_mse: 0.7605\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 2s 36ms/step - loss: 2.9213 - mse: 2.7551 - val_loss: 0.9823 - val_mse: 0.8265\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 2s 36ms/step - loss: 2.9329 - mse: 2.7373 - val_loss: 0.9401 - val_mse: 0.7567\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 2.9389 - mse: 2.7339 - val_loss: 1.2125 - val_mse: 1.0125\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 2s 35ms/step - loss: 2.8279 - mse: 2.6355 - val_loss: 0.9603 - val_mse: 0.7581\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 2s 35ms/step - loss: 2.9609 - mse: 2.7569 - val_loss: 1.0531 - val_mse: 0.8284\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 2s 37ms/step - loss: 2.9989 - mse: 2.7684 - val_loss: 0.9005 - val_mse: 0.7049\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 2s 38ms/step - loss: 3.0084 - mse: 2.7473 - val_loss: 1.0864 - val_mse: 0.7821\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 2s 36ms/step - loss: 2.9402 - mse: 2.6893 - val_loss: 1.2744 - val_mse: 1.0666\n",
      "Epoch 17/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 2.9145 - mse: 2.6765Restoring model weights from the end of the best epoch: 7.\n",
      "56/56 [==============================] - 2s 36ms/step - loss: 2.9312 - mse: 2.6934 - val_loss: 0.9886 - val_mse: 0.7631\n",
      "Epoch 17: early stopping\n",
      "18/18 [==============================] - 2s 15ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 13s 100ms/step - loss: 10.6177 - mse: 4.1608 - val_loss: 1.5073 - val_mse: 0.9193\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 4s 75ms/step - loss: 3.7422 - mse: 3.4602 - val_loss: 1.0083 - val_mse: 0.8418\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 3s 61ms/step - loss: 3.2144 - mse: 3.0651 - val_loss: 1.0982 - val_mse: 0.9581\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 4s 71ms/step - loss: 3.1451 - mse: 3.0066 - val_loss: 0.9245 - val_mse: 0.7900\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 3s 62ms/step - loss: 3.0076 - mse: 2.8765 - val_loss: 0.8787 - val_mse: 0.7512\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 3s 62ms/step - loss: 2.9060 - mse: 2.7842 - val_loss: 0.8749 - val_mse: 0.7580\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 3s 60ms/step - loss: 2.9776 - mse: 2.8618 - val_loss: 0.9753 - val_mse: 0.8596\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 3s 60ms/step - loss: 2.9252 - mse: 2.8117 - val_loss: 0.8260 - val_mse: 0.7157\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 3s 60ms/step - loss: 2.7668 - mse: 2.6597 - val_loss: 0.7848 - val_mse: 0.6807\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 3s 60ms/step - loss: 2.8238 - mse: 2.7210 - val_loss: 0.8777 - val_mse: 0.7732\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 3s 60ms/step - loss: 2.8589 - mse: 2.7524 - val_loss: 1.0254 - val_mse: 0.9098\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 3s 61ms/step - loss: 2.8578 - mse: 2.7376 - val_loss: 0.8083 - val_mse: 0.6899\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 3s 60ms/step - loss: 2.7246 - mse: 2.6106 - val_loss: 0.8403 - val_mse: 0.7303\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 3s 61ms/step - loss: 2.5949 - mse: 2.4887 - val_loss: 0.8058 - val_mse: 0.7024\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 3s 62ms/step - loss: 2.7886 - mse: 2.6818 - val_loss: 0.9651 - val_mse: 0.8517\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 3s 60ms/step - loss: 2.6449 - mse: 2.5288 - val_loss: 0.9598 - val_mse: 0.8465\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 3s 61ms/step - loss: 2.6547 - mse: 2.5519 - val_loss: 0.8628 - val_mse: 0.7645\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 3s 61ms/step - loss: 2.4755 - mse: 2.3792 - val_loss: 0.8533 - val_mse: 0.7574\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 2.7445 - mse: 2.6495Restoring model weights from the end of the best epoch: 9.\n",
      "56/56 [==============================] - 3s 62ms/step - loss: 2.7445 - mse: 2.6495 - val_loss: 0.8506 - val_mse: 0.7545\n",
      "Epoch 19: early stopping\n",
      "18/18 [==============================] - 2s 26ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 7s 42ms/step - loss: 5.3629 - mse: 3.4822 - val_loss: 1.7869 - val_mse: 0.7079\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 3.6475 - mse: 2.7991 - val_loss: 1.3350 - val_mse: 0.6497\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 3.3622 - mse: 2.7640 - val_loss: 1.1820 - val_mse: 0.6470\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 3.1614 - mse: 2.6772 - val_loss: 1.0697 - val_mse: 0.6314\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 3.0087 - mse: 2.6024 - val_loss: 0.9853 - val_mse: 0.6080\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.9530 - mse: 2.5981 - val_loss: 0.9242 - val_mse: 0.5904\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.8602 - mse: 2.5407 - val_loss: 0.9279 - val_mse: 0.6229\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.8292 - mse: 2.5371 - val_loss: 0.9248 - val_mse: 0.6408\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.7638 - mse: 2.4889 - val_loss: 0.9979 - val_mse: 0.7262\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.7291 - mse: 2.4569 - val_loss: 0.8631 - val_mse: 0.5967\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.5978 - mse: 2.3388 - val_loss: 0.8638 - val_mse: 0.6084\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.5985 - mse: 2.3456 - val_loss: 0.8633 - val_mse: 0.6124\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.6143 - mse: 2.3652 - val_loss: 0.9059 - val_mse: 0.6578\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.5080 - mse: 2.2673 - val_loss: 0.8614 - val_mse: 0.6296\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.6296 - mse: 2.3994 - val_loss: 0.8466 - val_mse: 0.6169\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.4231 - mse: 2.1913 - val_loss: 0.8761 - val_mse: 0.6484\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.3382 - mse: 2.1107 - val_loss: 0.8628 - val_mse: 0.6349\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.3763 - mse: 2.1474 - val_loss: 0.8965 - val_mse: 0.6638\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.4762 - mse: 2.2433 - val_loss: 0.8408 - val_mse: 0.6102\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.2220 - mse: 1.9914 - val_loss: 0.8589 - val_mse: 0.6306\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.2365 - mse: 2.0096 - val_loss: 0.8548 - val_mse: 0.6304\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.1000 - mse: 1.8781 - val_loss: 0.8320 - val_mse: 0.6112\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.0887 - mse: 1.8685 - val_loss: 0.8459 - val_mse: 0.6272\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.0952 - mse: 1.8791 - val_loss: 0.8596 - val_mse: 0.6461\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 2.0048 - mse: 1.7905 - val_loss: 0.8315 - val_mse: 0.6172\n",
      "Epoch 26/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.0274 - mse: 1.8162 - val_loss: 0.8896 - val_mse: 0.6808\n",
      "Epoch 27/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.9987 - mse: 1.7890 - val_loss: 0.8480 - val_mse: 0.6372\n",
      "Epoch 28/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 2.0781 - mse: 1.8656 - val_loss: 0.8845 - val_mse: 0.6677\n",
      "Epoch 29/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 2.0776 - mse: 1.8573 - val_loss: 0.8660 - val_mse: 0.6439\n",
      "Epoch 30/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.9996 - mse: 1.7792 - val_loss: 0.8421 - val_mse: 0.6201\n",
      "Epoch 31/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.9005 - mse: 1.6806 - val_loss: 0.8687 - val_mse: 0.6484\n",
      "Epoch 32/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.8924 - mse: 1.6740 - val_loss: 0.8363 - val_mse: 0.6196\n",
      "Epoch 33/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.8228 - mse: 1.6068 - val_loss: 0.8400 - val_mse: 0.6251\n",
      "Epoch 34/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.8020 - mse: 1.5886 - val_loss: 0.8461 - val_mse: 0.6349\n",
      "Epoch 35/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.7600 - mse: 1.5518 - val_loss: 0.8203 - val_mse: 0.6161\n",
      "Epoch 36/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.8837 - mse: 1.6782 - val_loss: 0.8332 - val_mse: 0.6254\n",
      "Epoch 37/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.7948 - mse: 1.5881 - val_loss: 0.8547 - val_mse: 0.6516\n",
      "Epoch 38/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.7537 - mse: 1.5497 - val_loss: 0.8142 - val_mse: 0.6122\n",
      "Epoch 39/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.7181 - mse: 1.5196 - val_loss: 0.7927 - val_mse: 0.5970\n",
      "Epoch 40/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.6674 - mse: 1.4741 - val_loss: 0.8411 - val_mse: 0.6485\n",
      "Epoch 41/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.6582 - mse: 1.4672 - val_loss: 0.8114 - val_mse: 0.6219\n",
      "Epoch 42/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.7103 - mse: 1.5225 - val_loss: 0.8247 - val_mse: 0.6370\n",
      "Epoch 43/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.7702 - mse: 1.5812 - val_loss: 0.8284 - val_mse: 0.6383\n",
      "Epoch 44/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.6837 - mse: 1.4944 - val_loss: 0.8182 - val_mse: 0.6296\n",
      "Epoch 45/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.6394 - mse: 1.4536 - val_loss: 0.7983 - val_mse: 0.6145\n",
      "Epoch 46/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.6951 - mse: 1.5118 - val_loss: 0.7941 - val_mse: 0.6107\n",
      "Epoch 47/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.7464 - mse: 1.5633 - val_loss: 0.8060 - val_mse: 0.6232\n",
      "Epoch 48/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.5725 - mse: 1.3910 - val_loss: 0.7821 - val_mse: 0.6013\n",
      "Epoch 49/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.5332 - mse: 1.3555 - val_loss: 0.7963 - val_mse: 0.6209\n",
      "Epoch 50/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.5461 - mse: 1.3708 - val_loss: 0.7773 - val_mse: 0.6012\n",
      "Epoch 51/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.6110 - mse: 1.4367 - val_loss: 0.8204 - val_mse: 0.6460\n",
      "Epoch 52/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.5479 - mse: 1.3727 - val_loss: 0.7788 - val_mse: 0.6042\n",
      "Epoch 53/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.5473 - mse: 1.3735 - val_loss: 0.8086 - val_mse: 0.6352\n",
      "Epoch 54/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.5449 - mse: 1.3709 - val_loss: 0.8100 - val_mse: 0.6358\n",
      "Epoch 55/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.5259 - mse: 1.3535 - val_loss: 0.7939 - val_mse: 0.6223\n",
      "Epoch 56/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.5241 - mse: 1.3520 - val_loss: 0.7860 - val_mse: 0.6143\n",
      "Epoch 57/1000\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 1.5645 - mse: 1.3925 - val_loss: 0.8145 - val_mse: 0.6428\n",
      "Epoch 58/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.5210 - mse: 1.3487 - val_loss: 0.7999 - val_mse: 0.6260\n",
      "Epoch 59/1000\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 1.5898 - mse: 1.4162 - val_loss: 0.8122 - val_mse: 0.6387\n",
      "Epoch 60/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 1.6381 - mse: 1.4644Restoring model weights from the end of the best epoch: 50.\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 1.6374 - mse: 1.4636 - val_loss: 0.8165 - val_mse: 0.6406\n",
      "Epoch 60: early stopping\n",
      "18/18 [==============================] - 1s 11ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 15s 84ms/step - loss: 4.1035 - mse: 3.9788 - val_loss: 1.2257 - val_mse: 1.1122\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 2s 39ms/step - loss: 3.6175 - mse: 3.5077 - val_loss: 1.0667 - val_mse: 0.9595\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 3.2670 - mse: 3.1597 - val_loss: 0.8843 - val_mse: 0.7768\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 3.1965 - mse: 3.0900 - val_loss: 0.8909 - val_mse: 0.7849\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 2s 39ms/step - loss: 2.9261 - mse: 2.8211 - val_loss: 0.7984 - val_mse: 0.6948\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.8291 - mse: 2.7265 - val_loss: 0.8082 - val_mse: 0.7073\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.8551 - mse: 2.7545 - val_loss: 0.8196 - val_mse: 0.7201\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.7780 - mse: 2.6792 - val_loss: 0.7744 - val_mse: 0.6767\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.7083 - mse: 2.6116 - val_loss: 0.8362 - val_mse: 0.7407\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.6509 - mse: 2.5566 - val_loss: 0.7683 - val_mse: 0.6748\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.6629 - mse: 2.5699 - val_loss: 0.7828 - val_mse: 0.6905\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 2s 39ms/step - loss: 2.6045 - mse: 2.5124 - val_loss: 0.9345 - val_mse: 0.8425\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.7478 - mse: 2.6559 - val_loss: 0.7114 - val_mse: 0.6199\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 2s 39ms/step - loss: 2.5743 - mse: 2.4832 - val_loss: 0.7350 - val_mse: 0.6441\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 2s 38ms/step - loss: 2.5433 - mse: 2.4529 - val_loss: 0.8763 - val_mse: 0.7856\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.5461 - mse: 2.4554 - val_loss: 0.7849 - val_mse: 0.6947\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 2s 39ms/step - loss: 2.4677 - mse: 2.3772 - val_loss: 0.7259 - val_mse: 0.6350\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 2s 38ms/step - loss: 2.4288 - mse: 2.3382 - val_loss: 0.7156 - val_mse: 0.6254\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 2s 39ms/step - loss: 2.4649 - mse: 2.3751 - val_loss: 0.7570 - val_mse: 0.6691\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 2s 39ms/step - loss: 2.6802 - mse: 2.5926 - val_loss: 0.7299 - val_mse: 0.6427\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 2s 38ms/step - loss: 2.5130 - mse: 2.4261 - val_loss: 0.7073 - val_mse: 0.6200\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 2s 39ms/step - loss: 2.3536 - mse: 2.2664 - val_loss: 0.7169 - val_mse: 0.6293\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 2s 39ms/step - loss: 2.3680 - mse: 2.2807 - val_loss: 0.7258 - val_mse: 0.6382\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 2s 39ms/step - loss: 2.3771 - mse: 2.2905 - val_loss: 0.6699 - val_mse: 0.5833\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 2s 38ms/step - loss: 2.3043 - mse: 2.2181 - val_loss: 0.7378 - val_mse: 0.6514\n",
      "Epoch 26/1000\n",
      "56/56 [==============================] - 2s 39ms/step - loss: 2.6020 - mse: 2.5157 - val_loss: 0.7467 - val_mse: 0.6600\n",
      "Epoch 27/1000\n",
      "56/56 [==============================] - 2s 39ms/step - loss: 2.3220 - mse: 2.2352 - val_loss: 0.8153 - val_mse: 0.7283\n",
      "Epoch 28/1000\n",
      "56/56 [==============================] - 2s 38ms/step - loss: 2.3409 - mse: 2.2537 - val_loss: 0.7318 - val_mse: 0.6445\n",
      "Epoch 29/1000\n",
      "56/56 [==============================] - 2s 39ms/step - loss: 2.1659 - mse: 2.0782 - val_loss: 0.7143 - val_mse: 0.6264\n",
      "Epoch 30/1000\n",
      "56/56 [==============================] - 2s 38ms/step - loss: 2.1894 - mse: 2.1024 - val_loss: 0.7276 - val_mse: 0.6410\n",
      "Epoch 31/1000\n",
      "56/56 [==============================] - 2s 38ms/step - loss: 2.1388 - mse: 2.0519 - val_loss: 0.8010 - val_mse: 0.7138\n",
      "Epoch 32/1000\n",
      "56/56 [==============================] - 2s 38ms/step - loss: 2.2086 - mse: 2.1208 - val_loss: 0.8000 - val_mse: 0.7123\n",
      "Epoch 33/1000\n",
      "56/56 [==============================] - 2s 39ms/step - loss: 2.2974 - mse: 2.2092 - val_loss: 0.7625 - val_mse: 0.6737\n",
      "Epoch 34/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 2.2441 - mse: 2.1547Restoring model weights from the end of the best epoch: 24.\n",
      "56/56 [==============================] - 2s 38ms/step - loss: 2.2245 - mse: 2.1352 - val_loss: 0.7290 - val_mse: 0.6394\n",
      "Epoch 34: early stopping\n",
      "18/18 [==============================] - 2s 23ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 13s 85ms/step - loss: 4.2210 - mse: 4.0725 - val_loss: 1.2506 - val_mse: 1.1264\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 2s 42ms/step - loss: 3.7397 - mse: 3.6268 - val_loss: 1.1617 - val_mse: 1.0571\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 3.3569 - mse: 3.2577 - val_loss: 0.8875 - val_mse: 0.7935\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 3.0037 - mse: 2.9139 - val_loss: 0.7313 - val_mse: 0.6457\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.8514 - mse: 2.7695 - val_loss: 0.7052 - val_mse: 0.6267\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.7948 - mse: 2.7192 - val_loss: 0.8222 - val_mse: 0.7495\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.7333 - mse: 2.6627 - val_loss: 0.7259 - val_mse: 0.6575\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.6938 - mse: 2.6273 - val_loss: 0.7772 - val_mse: 0.7126\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.6286 - mse: 2.5656 - val_loss: 0.7363 - val_mse: 0.6748\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 2s 42ms/step - loss: 2.6320 - mse: 2.5717 - val_loss: 0.7248 - val_mse: 0.6657\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.5262 - mse: 2.4683 - val_loss: 0.7261 - val_mse: 0.6693\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 2s 42ms/step - loss: 2.4222 - mse: 2.3663 - val_loss: 0.7001 - val_mse: 0.6450\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.6602 - mse: 2.6056 - val_loss: 0.7064 - val_mse: 0.6519\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 2.5127 - mse: 2.4590 - val_loss: 0.7367 - val_mse: 0.6839\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.5455 - mse: 2.4933 - val_loss: 0.7255 - val_mse: 0.6744\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.4964 - mse: 2.4460 - val_loss: 0.7611 - val_mse: 0.7111\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.5818 - mse: 2.5321 - val_loss: 0.7339 - val_mse: 0.6843\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.4249 - mse: 2.3758 - val_loss: 0.7166 - val_mse: 0.6686\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.6664 - mse: 2.6189 - val_loss: 0.6379 - val_mse: 0.5908\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.4785 - mse: 2.4317 - val_loss: 0.7428 - val_mse: 0.6964\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.4250 - mse: 2.3789 - val_loss: 0.7258 - val_mse: 0.6800\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.3131 - mse: 2.2675 - val_loss: 0.6876 - val_mse: 0.6422\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.2456 - mse: 2.2005 - val_loss: 0.6977 - val_mse: 0.6530\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.4519 - mse: 2.4072 - val_loss: 0.6827 - val_mse: 0.6382\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.2805 - mse: 2.2363 - val_loss: 0.6501 - val_mse: 0.6061\n",
      "Epoch 26/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.1916 - mse: 2.1473 - val_loss: 0.6449 - val_mse: 0.6000\n",
      "Epoch 27/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.1391 - mse: 2.0950 - val_loss: 0.6587 - val_mse: 0.6152\n",
      "Epoch 28/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.1173 - mse: 2.0742 - val_loss: 0.6403 - val_mse: 0.5976\n",
      "Epoch 29/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 2.0782 - mse: 2.0355Restoring model weights from the end of the best epoch: 19.\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.0807 - mse: 2.0381 - val_loss: 0.6702 - val_mse: 0.6277\n",
      "Epoch 29: early stopping\n",
      "18/18 [==============================] - 2s 24ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 9s 56ms/step - loss: 4.4362 - mse: 4.2110 - val_loss: 1.3031 - val_mse: 1.1531\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 4.0514 - mse: 3.9201 - val_loss: 1.1671 - val_mse: 1.0495\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 3.7747 - mse: 3.6640 - val_loss: 1.1028 - val_mse: 0.9970\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 3.4400 - mse: 3.3365 - val_loss: 1.0190 - val_mse: 0.9167\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 3.3903 - mse: 3.2863 - val_loss: 1.0254 - val_mse: 0.9185\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 3.0401 - mse: 2.9313 - val_loss: 0.9585 - val_mse: 0.8493\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 2.9063 - mse: 2.7996 - val_loss: 0.8447 - val_mse: 0.7401\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 2.8462 - mse: 2.7436 - val_loss: 0.8675 - val_mse: 0.7659\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 2.7729 - mse: 2.6727 - val_loss: 0.8197 - val_mse: 0.7199\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 2.6607 - mse: 2.5627 - val_loss: 0.8978 - val_mse: 0.8016\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 2.7176 - mse: 2.6192 - val_loss: 0.8059 - val_mse: 0.7073\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 2.5990 - mse: 2.5020 - val_loss: 0.8729 - val_mse: 0.7773\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 2.6517 - mse: 2.5536 - val_loss: 0.8516 - val_mse: 0.7521\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 2.5585 - mse: 2.4611 - val_loss: 0.9376 - val_mse: 0.8424\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 2.4181 - mse: 2.3231 - val_loss: 0.7695 - val_mse: 0.6706\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 2.4553 - mse: 2.3575 - val_loss: 0.7660 - val_mse: 0.6706\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 2.2761 - mse: 2.1822 - val_loss: 0.7857 - val_mse: 0.6937\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 2.2149 - mse: 2.1234 - val_loss: 0.8155 - val_mse: 0.7257\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 2.1635 - mse: 2.0731 - val_loss: 0.9213 - val_mse: 0.8308\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 2.0999 - mse: 2.0111 - val_loss: 0.7683 - val_mse: 0.6807\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 2.0007 - mse: 1.9140 - val_loss: 0.8443 - val_mse: 0.7580\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 2.1141 - mse: 2.0278 - val_loss: 0.8169 - val_mse: 0.7302\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 1.9248 - mse: 1.8389 - val_loss: 0.8099 - val_mse: 0.7247\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 1.8800 - mse: 1.7949 - val_loss: 0.7836 - val_mse: 0.6992\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 1.8301 - mse: 1.7462 - val_loss: 0.7784 - val_mse: 0.6949\n",
      "Epoch 26/1000\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 1.7665 - mse: 1.6837Restoring model weights from the end of the best epoch: 16.\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 1.7450 - mse: 1.6621 - val_loss: 0.7851 - val_mse: 0.7027\n",
      "Epoch 26: early stopping\n",
      "18/18 [==============================] - 2s 12ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 9s 61ms/step - loss: 3.5856 - mse: 3.3288 - val_loss: 0.9483 - val_mse: 0.7161\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 3.1143 - mse: 2.8957 - val_loss: 0.8801 - val_mse: 0.6727\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 2.9000 - mse: 2.7026 - val_loss: 0.8239 - val_mse: 0.6358\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 2.8448 - mse: 2.6637 - val_loss: 0.8044 - val_mse: 0.6293\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 2.7153 - mse: 2.5454 - val_loss: 0.7853 - val_mse: 0.6199\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 2.7528 - mse: 2.5866 - val_loss: 0.7958 - val_mse: 0.6304\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 2.6287 - mse: 2.4634 - val_loss: 0.8122 - val_mse: 0.6486\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 2.5793 - mse: 2.4165 - val_loss: 0.8994 - val_mse: 0.7374\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 2.5897 - mse: 2.4266 - val_loss: 0.7907 - val_mse: 0.6273\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 2.4318 - mse: 2.2718 - val_loss: 0.7855 - val_mse: 0.6279\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 2.4666 - mse: 2.3080 - val_loss: 0.7770 - val_mse: 0.6173\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 2.3836 - mse: 2.2273 - val_loss: 0.7730 - val_mse: 0.6177\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 2.2691 - mse: 2.1143 - val_loss: 0.7704 - val_mse: 0.6150\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 2.2407 - mse: 2.0841 - val_loss: 0.8238 - val_mse: 0.6669\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 2.2132 - mse: 2.0561 - val_loss: 0.7684 - val_mse: 0.6096\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 2.0719 - mse: 1.9134 - val_loss: 0.7652 - val_mse: 0.6065\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 2.0605 - mse: 1.9032 - val_loss: 0.7926 - val_mse: 0.6359\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.9857 - mse: 1.8276 - val_loss: 0.7842 - val_mse: 0.6263\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.8365 - mse: 1.6807 - val_loss: 0.8139 - val_mse: 0.6587\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 1.8282 - mse: 1.6725 - val_loss: 0.7746 - val_mse: 0.6182\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 1.7300 - mse: 1.5747 - val_loss: 0.7854 - val_mse: 0.6316\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 1.7101 - mse: 1.5567 - val_loss: 0.7959 - val_mse: 0.6420\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.7010 - mse: 1.5464 - val_loss: 0.7579 - val_mse: 0.6015\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.6359 - mse: 1.4801 - val_loss: 0.7400 - val_mse: 0.5851\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.6383 - mse: 1.4865 - val_loss: 0.7247 - val_mse: 0.5740\n",
      "Epoch 26/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.5724 - mse: 1.4211 - val_loss: 0.7646 - val_mse: 0.6137\n",
      "Epoch 27/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 1.5477 - mse: 1.3970 - val_loss: 0.7781 - val_mse: 0.6277\n",
      "Epoch 28/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 1.4435 - mse: 1.2939 - val_loss: 0.7359 - val_mse: 0.5870\n",
      "Epoch 29/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.3743 - mse: 1.2269 - val_loss: 0.7410 - val_mse: 0.5949\n",
      "Epoch 30/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.3517 - mse: 1.2066 - val_loss: 0.7249 - val_mse: 0.5803\n",
      "Epoch 31/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.2965 - mse: 1.1527 - val_loss: 0.7585 - val_mse: 0.6154\n",
      "Epoch 32/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 1.2613 - mse: 1.1189 - val_loss: 0.7327 - val_mse: 0.5913\n",
      "Epoch 33/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.2681 - mse: 1.1269 - val_loss: 0.7303 - val_mse: 0.5893\n",
      "Epoch 34/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.2576 - mse: 1.1162 - val_loss: 0.7082 - val_mse: 0.5657\n",
      "Epoch 35/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 1.2292 - mse: 1.0864 - val_loss: 0.7819 - val_mse: 0.6387\n",
      "Epoch 36/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 1.2575 - mse: 1.1138 - val_loss: 0.7598 - val_mse: 0.6149\n",
      "Epoch 37/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.1958 - mse: 1.0505 - val_loss: 0.7630 - val_mse: 0.6175\n",
      "Epoch 38/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 1.1296 - mse: 0.9843 - val_loss: 0.7692 - val_mse: 0.6242\n",
      "Epoch 39/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.0424 - mse: 0.8974 - val_loss: 0.7431 - val_mse: 0.5978\n",
      "Epoch 40/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.0559 - mse: 0.9098 - val_loss: 0.7732 - val_mse: 0.6255\n",
      "Epoch 41/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.9830 - mse: 0.8360 - val_loss: 0.7790 - val_mse: 0.6328\n",
      "Epoch 42/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.9506 - mse: 0.8051 - val_loss: 0.7450 - val_mse: 0.5993\n",
      "Epoch 43/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.9100 - mse: 0.7653 - val_loss: 0.7264 - val_mse: 0.5827\n",
      "Epoch 44/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.9553 - mse: 0.8093Restoring model weights from the end of the best epoch: 34.\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.9521 - mse: 0.8061 - val_loss: 0.7975 - val_mse: 0.6465\n",
      "Epoch 44: early stopping\n",
      "18/18 [==============================] - 2s 13ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 8s 51ms/step - loss: 4.0674 - mse: 3.9243 - val_loss: 1.0321 - val_mse: 0.9023\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 3.2989 - mse: 3.1720 - val_loss: 0.9709 - val_mse: 0.8453\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 2.9605 - mse: 2.8374 - val_loss: 0.8080 - val_mse: 0.6874\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 2.8721 - mse: 2.7535 - val_loss: 0.8022 - val_mse: 0.6859\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 2.8610 - mse: 2.7466 - val_loss: 0.7481 - val_mse: 0.6356\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 2.7582 - mse: 2.6472 - val_loss: 0.8262 - val_mse: 0.7170\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 2.6966 - mse: 2.5885 - val_loss: 0.8106 - val_mse: 0.7037\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 2.6259 - mse: 2.5206 - val_loss: 0.7841 - val_mse: 0.6797\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 2.6453 - mse: 2.5420 - val_loss: 0.8117 - val_mse: 0.7084\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 2.8792 - mse: 2.7746 - val_loss: 0.8315 - val_mse: 0.7254\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 2.6703 - mse: 2.5633 - val_loss: 0.7870 - val_mse: 0.6794\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 2.6031 - mse: 2.4969 - val_loss: 0.7694 - val_mse: 0.6640\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 3.0418 - mse: 2.9359 - val_loss: 0.9489 - val_mse: 0.8421\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 2.6858 - mse: 2.5787 - val_loss: 0.7742 - val_mse: 0.6680\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 2.5717 - mse: 2.4655Restoring model weights from the end of the best epoch: 5.\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 2.5717 - mse: 2.4655 - val_loss: 0.8143 - val_mse: 0.7076\n",
      "Epoch 15: early stopping\n",
      "18/18 [==============================] - 1s 11ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 8s 56ms/step - loss: 5.1958 - mse: 3.1889 - val_loss: 1.0122 - val_mse: 0.6388\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.9327 - mse: 2.7242 - val_loss: 0.7465 - val_mse: 0.6138\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.8324 - mse: 2.7193 - val_loss: 0.7713 - val_mse: 0.6704\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.8453 - mse: 2.7488 - val_loss: 0.7527 - val_mse: 0.6593\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.6481 - mse: 2.5556 - val_loss: 0.7058 - val_mse: 0.6144\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 2.5555 - mse: 2.4651 - val_loss: 0.7072 - val_mse: 0.6172\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.4860 - mse: 2.3948 - val_loss: 0.6947 - val_mse: 0.6031\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.4757 - mse: 2.3828 - val_loss: 0.6979 - val_mse: 0.6047\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.3991 - mse: 2.3051 - val_loss: 0.6884 - val_mse: 0.5933\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.2146 - mse: 2.1197 - val_loss: 0.6742 - val_mse: 0.5792\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.1798 - mse: 2.0839 - val_loss: 0.6925 - val_mse: 0.5954\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.1307 - mse: 2.0324 - val_loss: 0.7430 - val_mse: 0.6434\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.1390 - mse: 2.0387 - val_loss: 0.7363 - val_mse: 0.6355\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.0389 - mse: 1.9378 - val_loss: 0.7208 - val_mse: 0.6190\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.0606 - mse: 1.9591 - val_loss: 0.7236 - val_mse: 0.6221\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 1.7455 - mse: 1.6438 - val_loss: 0.6910 - val_mse: 0.5894\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 1.7209 - mse: 1.6194 - val_loss: 0.7177 - val_mse: 0.6161\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 1.6607 - mse: 1.5592 - val_loss: 0.7144 - val_mse: 0.6136\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 1.6935 - mse: 1.5924 - val_loss: 0.7310 - val_mse: 0.6296\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 1.5656 - mse: 1.4646Restoring model weights from the end of the best epoch: 10.\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 1.5656 - mse: 1.4646 - val_loss: 0.7565 - val_mse: 0.6557\n",
      "Epoch 20: early stopping\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 10s 67ms/step - loss: 5.2943 - mse: 3.5602 - val_loss: 1.9032 - val_mse: 0.8124\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 3.7089 - mse: 2.8370 - val_loss: 1.4186 - val_mse: 0.7225\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 3.3023 - mse: 2.7038 - val_loss: 1.1340 - val_mse: 0.6187\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 3.1562 - mse: 2.7029 - val_loss: 1.0742 - val_mse: 0.6728\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 3.0457 - mse: 2.6788 - val_loss: 1.0379 - val_mse: 0.6969\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 3.0346 - mse: 2.7120 - val_loss: 1.0199 - val_mse: 0.7080\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 3.0407 - mse: 2.7415 - val_loss: 0.9711 - val_mse: 0.6838\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.8622 - mse: 2.5946 - val_loss: 0.9324 - val_mse: 0.6802\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.8577 - mse: 2.6114 - val_loss: 0.9460 - val_mse: 0.7035\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.8232 - mse: 2.5810 - val_loss: 0.8679 - val_mse: 0.6317\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.5901 - mse: 2.3624 - val_loss: 0.9264 - val_mse: 0.6973\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 2.8646 - mse: 2.6236 - val_loss: 0.9036 - val_mse: 0.6463\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.9478 - mse: 2.6802 - val_loss: 0.9108 - val_mse: 0.6464\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.6578 - mse: 2.4084 - val_loss: 0.8569 - val_mse: 0.6183\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.7926 - mse: 2.5643 - val_loss: 0.8897 - val_mse: 0.6707\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.6108 - mse: 2.3874 - val_loss: 0.8935 - val_mse: 0.6649\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.8383 - mse: 2.6127 - val_loss: 0.8470 - val_mse: 0.6272\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.6364 - mse: 2.4223 - val_loss: 0.8153 - val_mse: 0.6038\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.6440 - mse: 2.4238 - val_loss: 1.0194 - val_mse: 0.7815\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.6818 - mse: 2.4309 - val_loss: 0.8684 - val_mse: 0.6301\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.7279 - mse: 2.5005 - val_loss: 0.8252 - val_mse: 0.6093\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.6580 - mse: 2.4336 - val_loss: 0.9404 - val_mse: 0.7109\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.6817 - mse: 2.4545 - val_loss: 0.9301 - val_mse: 0.7073\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.5838 - mse: 2.3703 - val_loss: 0.8125 - val_mse: 0.6059\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.7289 - mse: 2.5059 - val_loss: 0.9278 - val_mse: 0.6749\n",
      "Epoch 26/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.7910 - mse: 2.5565 - val_loss: 0.8550 - val_mse: 0.6397\n",
      "Epoch 27/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.6216 - mse: 2.4161 - val_loss: 0.8605 - val_mse: 0.6565\n",
      "Epoch 28/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.6677 - mse: 2.4575 - val_loss: 0.8663 - val_mse: 0.6602\n",
      "Epoch 29/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.4991 - mse: 2.2993 - val_loss: 0.8201 - val_mse: 0.6183\n",
      "Epoch 30/1000\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 2.6651 - mse: 2.4620 - val_loss: 0.8245 - val_mse: 0.6269\n",
      "Epoch 31/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.5428 - mse: 2.3522 - val_loss: 0.7928 - val_mse: 0.6059\n",
      "Epoch 32/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.5711 - mse: 2.3857 - val_loss: 0.9224 - val_mse: 0.7308\n",
      "Epoch 33/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.5513 - mse: 2.3470 - val_loss: 0.8378 - val_mse: 0.6338\n",
      "Epoch 34/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.4752 - mse: 2.2743 - val_loss: 0.8312 - val_mse: 0.6271\n",
      "Epoch 35/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.4269 - mse: 2.2201 - val_loss: 0.8622 - val_mse: 0.6566\n",
      "Epoch 36/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.3023 - mse: 2.1006 - val_loss: 0.8870 - val_mse: 0.6874\n",
      "Epoch 37/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.2593 - mse: 2.0590 - val_loss: 0.8576 - val_mse: 0.6578\n",
      "Epoch 38/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.2010 - mse: 2.0016 - val_loss: 0.8368 - val_mse: 0.6401\n",
      "Epoch 39/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.2800 - mse: 2.0756 - val_loss: 0.8776 - val_mse: 0.6640\n",
      "Epoch 40/1000\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 2.3746 - mse: 2.1501 - val_loss: 0.9319 - val_mse: 0.7002\n",
      "Epoch 41/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 2.3737 - mse: 2.1362Restoring model weights from the end of the best epoch: 31.\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.3737 - mse: 2.1362 - val_loss: 0.9521 - val_mse: 0.7098\n",
      "Epoch 41: early stopping\n",
      "18/18 [==============================] - 2s 14ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 11s 84ms/step - loss: 9.6716 - mse: 4.2479 - val_loss: 1.4851 - val_mse: 1.2546\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 3s 55ms/step - loss: 4.2538 - mse: 4.1818 - val_loss: 1.3214 - val_mse: 1.3053\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 3s 55ms/step - loss: 4.1789 - mse: 4.1677 - val_loss: 1.3199 - val_mse: 1.3105\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 3s 54ms/step - loss: 4.1593 - mse: 4.1502 - val_loss: 1.3782 - val_mse: 1.3692\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 3s 54ms/step - loss: 4.1193 - mse: 4.1104 - val_loss: 1.3534 - val_mse: 1.3447\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 3s 55ms/step - loss: 4.1526 - mse: 4.1442 - val_loss: 1.2797 - val_mse: 1.2714\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 3s 55ms/step - loss: 4.0356 - mse: 4.0273 - val_loss: 1.2994 - val_mse: 1.2911\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 3s 54ms/step - loss: 3.9973 - mse: 3.9891 - val_loss: 1.6083 - val_mse: 1.5999\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 3s 55ms/step - loss: 4.0398 - mse: 4.0313 - val_loss: 1.4028 - val_mse: 1.3944\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 3s 54ms/step - loss: 3.9045 - mse: 3.8960 - val_loss: 1.2943 - val_mse: 1.2858\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 3s 55ms/step - loss: 3.8927 - mse: 3.8841 - val_loss: 1.5777 - val_mse: 1.5689\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 3s 55ms/step - loss: 3.6903 - mse: 3.6814 - val_loss: 1.4518 - val_mse: 1.4426\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 3s 55ms/step - loss: 3.8109 - mse: 3.8015 - val_loss: 1.5003 - val_mse: 1.4896\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 3s 55ms/step - loss: 3.5515 - mse: 3.5410 - val_loss: 1.2166 - val_mse: 1.2066\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 3s 55ms/step - loss: 3.4185 - mse: 3.4082 - val_loss: 1.2886 - val_mse: 1.2781\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 3s 54ms/step - loss: 3.2230 - mse: 3.2125 - val_loss: 1.4244 - val_mse: 1.4137\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 3s 55ms/step - loss: 3.1733 - mse: 3.1624 - val_loss: 1.4017 - val_mse: 1.3904\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 3s 55ms/step - loss: 3.0904 - mse: 3.0787 - val_loss: 1.3619 - val_mse: 1.3480\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 3s 54ms/step - loss: 2.8047 - mse: 2.7910 - val_loss: 1.7067 - val_mse: 1.6943\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 3s 56ms/step - loss: 2.6927 - mse: 2.6802 - val_loss: 1.9631 - val_mse: 1.9505\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 3s 54ms/step - loss: 2.6236 - mse: 2.6106 - val_loss: 1.6606 - val_mse: 1.6473\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 3s 54ms/step - loss: 2.5609 - mse: 2.5472 - val_loss: 2.1395 - val_mse: 2.1255\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 3s 54ms/step - loss: 2.4352 - mse: 2.4205 - val_loss: 1.3746 - val_mse: 1.3598\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 2.2643 - mse: 2.2491Restoring model weights from the end of the best epoch: 14.\n",
      "56/56 [==============================] - 3s 55ms/step - loss: 2.2643 - mse: 2.2491 - val_loss: 1.6706 - val_mse: 1.6552\n",
      "Epoch 24: early stopping\n",
      "18/18 [==============================] - 2s 23ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 4s 26ms/step - loss: 4.4304 - mse: 3.4225 - val_loss: 1.0880 - val_mse: 0.6500\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 3.0206 - mse: 2.7320 - val_loss: 0.8051 - val_mse: 0.5997\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.9160 - mse: 2.7355 - val_loss: 0.7753 - val_mse: 0.6116\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.7546 - mse: 2.6017 - val_loss: 0.7963 - val_mse: 0.6526\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.7163 - mse: 2.5781 - val_loss: 0.7284 - val_mse: 0.5934\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.6029 - mse: 2.4709 - val_loss: 0.7389 - val_mse: 0.6094\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.5788 - mse: 2.4486 - val_loss: 0.7733 - val_mse: 0.6414\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.5340 - mse: 2.3985 - val_loss: 0.7539 - val_mse: 0.6167\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.4544 - mse: 2.3161 - val_loss: 0.7769 - val_mse: 0.6374\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.4039 - mse: 2.2632 - val_loss: 0.7610 - val_mse: 0.6178\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.3316 - mse: 2.1853 - val_loss: 0.7712 - val_mse: 0.6241\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.2691 - mse: 2.1191 - val_loss: 0.7388 - val_mse: 0.5865\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.2246 - mse: 2.0739 - val_loss: 0.7597 - val_mse: 0.6094\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.0839 - mse: 1.9319 - val_loss: 0.7706 - val_mse: 0.6190\n",
      "Epoch 15/1000\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 2.0328 - mse: 1.8818Restoring model weights from the end of the best epoch: 5.\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 2.0257 - mse: 1.8746 - val_loss: 0.7885 - val_mse: 0.6375\n",
      "Epoch 15: early stopping\n",
      "18/18 [==============================] - 1s 5ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 9s 66ms/step - loss: 3.2292 - mse: 3.2261 - val_loss: 0.6170 - val_mse: 0.6139\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 2.7282 - mse: 2.7252 - val_loss: 0.6003 - val_mse: 0.5974\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.5933 - mse: 2.5903 - val_loss: 0.6209 - val_mse: 0.6180\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 2.5228 - mse: 2.5199 - val_loss: 0.6484 - val_mse: 0.6455\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 2.4181 - mse: 2.4152 - val_loss: 0.5813 - val_mse: 0.5784\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 2.2085 - mse: 2.2056 - val_loss: 0.6404 - val_mse: 0.6376\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 2.0842 - mse: 2.0813 - val_loss: 0.6031 - val_mse: 0.6002\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 1.9127 - mse: 1.9099 - val_loss: 0.6238 - val_mse: 0.6210\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 2s 35ms/step - loss: 1.7789 - mse: 1.7761 - val_loss: 0.6184 - val_mse: 0.6156\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 2s 35ms/step - loss: 1.7381 - mse: 1.7354 - val_loss: 0.6142 - val_mse: 0.6115\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 1.6242 - mse: 1.6215 - val_loss: 0.6226 - val_mse: 0.6199\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 2s 35ms/step - loss: 1.5465 - mse: 1.5439 - val_loss: 0.5898 - val_mse: 0.5873\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 1.4807 - mse: 1.4781 - val_loss: 0.5912 - val_mse: 0.5887\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 1.3321 - mse: 1.3296 - val_loss: 0.6122 - val_mse: 0.6097\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 1.2752 - mse: 1.2728Restoring model weights from the end of the best epoch: 5.\n",
      "56/56 [==============================] - 2s 35ms/step - loss: 1.2752 - mse: 1.2728 - val_loss: 0.5980 - val_mse: 0.5956\n",
      "Epoch 15: early stopping\n",
      "18/18 [==============================] - 2s 15ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 14s 88ms/step - loss: 8.5392 - mse: 4.0661 - val_loss: 1.9657 - val_mse: 1.0872\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 4.0646 - mse: 3.6394 - val_loss: 1.1559 - val_mse: 0.9535\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 3.5275 - mse: 3.3953 - val_loss: 0.9938 - val_mse: 0.9100\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 3.2490 - mse: 3.1874 - val_loss: 0.8705 - val_mse: 0.8259\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.9157 - mse: 2.8805 - val_loss: 0.8164 - val_mse: 0.7894\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.8479 - mse: 2.8258 - val_loss: 0.6870 - val_mse: 0.6688\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.8019 - mse: 2.7863 - val_loss: 0.8189 - val_mse: 0.8056\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 2s 42ms/step - loss: 2.7675 - mse: 2.7555 - val_loss: 0.6668 - val_mse: 0.6558\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 2s 42ms/step - loss: 2.6150 - mse: 2.6050 - val_loss: 0.7188 - val_mse: 0.7094\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.6447 - mse: 2.6358 - val_loss: 0.7065 - val_mse: 0.6980\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.5527 - mse: 2.5445 - val_loss: 0.6924 - val_mse: 0.6844\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.5487 - mse: 2.5410 - val_loss: 0.6775 - val_mse: 0.6699\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.5288 - mse: 2.5213 - val_loss: 0.7011 - val_mse: 0.6936\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.4606 - mse: 2.4532 - val_loss: 0.6604 - val_mse: 0.6530\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.6702 - mse: 2.6629 - val_loss: 0.6668 - val_mse: 0.6595\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.4608 - mse: 2.4536 - val_loss: 0.6530 - val_mse: 0.6458\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.7388 - mse: 2.7316 - val_loss: 0.8488 - val_mse: 0.8414\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.6712 - mse: 2.6637 - val_loss: 0.6868 - val_mse: 0.6793\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.5678 - mse: 2.5602 - val_loss: 0.6285 - val_mse: 0.6206\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.6157 - mse: 2.5973 - val_loss: 0.7458 - val_mse: 0.7201\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.4775 - mse: 2.4658 - val_loss: 0.6483 - val_mse: 0.6402\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.2918 - mse: 2.2839 - val_loss: 0.6830 - val_mse: 0.6752\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.4304 - mse: 2.4226 - val_loss: 0.6453 - val_mse: 0.6376\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 2.2429 - mse: 2.2352 - val_loss: 0.6086 - val_mse: 0.6009\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 2.2485 - mse: 2.2408 - val_loss: 0.6245 - val_mse: 0.6168\n",
      "Epoch 26/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.2567 - mse: 2.2490 - val_loss: 0.6391 - val_mse: 0.6314\n",
      "Epoch 27/1000\n",
      "56/56 [==============================] - 2s 42ms/step - loss: 2.2551 - mse: 2.2473 - val_loss: 0.6028 - val_mse: 0.5951\n",
      "Epoch 28/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.2913 - mse: 2.2835 - val_loss: 0.6796 - val_mse: 0.6718\n",
      "Epoch 29/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.3379 - mse: 2.3300 - val_loss: 0.6689 - val_mse: 0.6609\n",
      "Epoch 30/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.8789 - mse: 2.8705 - val_loss: 0.7776 - val_mse: 0.7686\n",
      "Epoch 31/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.5513 - mse: 2.5422 - val_loss: 0.8528 - val_mse: 0.8436\n",
      "Epoch 32/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.4839 - mse: 2.4747 - val_loss: 0.7509 - val_mse: 0.7416\n",
      "Epoch 33/1000\n",
      "56/56 [==============================] - 2s 40ms/step - loss: 2.5964 - mse: 2.5869 - val_loss: 0.7603 - val_mse: 0.7500\n",
      "Epoch 34/1000\n",
      "56/56 [==============================] - 2s 42ms/step - loss: 2.4937 - mse: 2.4840 - val_loss: 0.6555 - val_mse: 0.6460\n",
      "Epoch 35/1000\n",
      "56/56 [==============================] - 2s 41ms/step - loss: 2.2239 - mse: 2.2144 - val_loss: 0.6382 - val_mse: 0.6289\n",
      "Epoch 36/1000\n",
      "56/56 [==============================] - 2s 42ms/step - loss: 2.1551 - mse: 2.1458 - val_loss: 0.6425 - val_mse: 0.6332\n",
      "Epoch 37/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 2.2728 - mse: 2.2635Restoring model weights from the end of the best epoch: 27.\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 2.2534 - mse: 2.2440 - val_loss: 0.6739 - val_mse: 0.6646\n",
      "Epoch 37: early stopping\n",
      "18/18 [==============================] - 3s 29ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 4s 28ms/step - loss: 3.7686 - mse: 3.4515 - val_loss: 0.9634 - val_mse: 0.6929\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 3.0237 - mse: 2.7712 - val_loss: 0.8666 - val_mse: 0.6304\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.8678 - mse: 2.6418 - val_loss: 0.7981 - val_mse: 0.5821\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.8367 - mse: 2.6272 - val_loss: 0.8261 - val_mse: 0.6233\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.7520 - mse: 2.5541 - val_loss: 0.7831 - val_mse: 0.5894\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.6679 - mse: 2.4781 - val_loss: 0.8291 - val_mse: 0.6425\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.6949 - mse: 2.5108 - val_loss: 0.7989 - val_mse: 0.6164\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.5055 - mse: 2.3236 - val_loss: 0.7793 - val_mse: 0.5990\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.3838 - mse: 2.2069 - val_loss: 0.7726 - val_mse: 0.5984\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.4548 - mse: 2.2810 - val_loss: 0.8175 - val_mse: 0.6439\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.3772 - mse: 2.2039 - val_loss: 0.7936 - val_mse: 0.6196\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 2.2483 - mse: 2.0756 - val_loss: 0.7854 - val_mse: 0.6138\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 2.1297 - mse: 1.9593 - val_loss: 0.7773 - val_mse: 0.6081\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 2.0695 - mse: 1.9007 - val_loss: 0.7900 - val_mse: 0.6218\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 1.9476 - mse: 1.7798 - val_loss: 0.8033 - val_mse: 0.6356\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.8919 - mse: 1.7248 - val_loss: 0.8046 - val_mse: 0.6387\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.8413 - mse: 1.6754 - val_loss: 0.8043 - val_mse: 0.6385\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.8132 - mse: 1.6474 - val_loss: 0.7798 - val_mse: 0.6147\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 1.7142 - mse: 1.5508 - val_loss: 0.7627 - val_mse: 0.6009\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.6732 - mse: 1.5120 - val_loss: 0.8039 - val_mse: 0.6425\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.6271 - mse: 1.4678 - val_loss: 0.7632 - val_mse: 0.6061\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 1.5007 - mse: 1.3450 - val_loss: 0.7596 - val_mse: 0.6043\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.3825 - mse: 1.2284 - val_loss: 0.7600 - val_mse: 0.6074\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 1.3065 - mse: 1.1556 - val_loss: 0.7829 - val_mse: 0.6343\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.2528 - mse: 1.1059 - val_loss: 0.7634 - val_mse: 0.6185\n",
      "Epoch 26/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.2065 - mse: 1.0629 - val_loss: 0.7704 - val_mse: 0.6280\n",
      "Epoch 27/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 1.1550 - mse: 1.0146 - val_loss: 0.7758 - val_mse: 0.6364\n",
      "Epoch 28/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.0864 - mse: 0.9489 - val_loss: 0.7692 - val_mse: 0.6333\n",
      "Epoch 29/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 1.0341 - mse: 0.8992 - val_loss: 0.7388 - val_mse: 0.6058\n",
      "Epoch 30/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 1.0049 - mse: 0.8726 - val_loss: 0.7398 - val_mse: 0.6084\n",
      "Epoch 31/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 0.9466 - mse: 0.8166 - val_loss: 0.7544 - val_mse: 0.6264\n",
      "Epoch 32/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 0.9039 - mse: 0.7772 - val_loss: 0.7657 - val_mse: 0.6402\n",
      "Epoch 33/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 0.8503 - mse: 0.7265 - val_loss: 0.7499 - val_mse: 0.6271\n",
      "Epoch 34/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 0.8346 - mse: 0.7128 - val_loss: 0.7383 - val_mse: 0.6178\n",
      "Epoch 35/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 0.7907 - mse: 0.6712 - val_loss: 0.7382 - val_mse: 0.6202\n",
      "Epoch 36/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 0.7186 - mse: 0.6021 - val_loss: 0.7286 - val_mse: 0.6135\n",
      "Epoch 37/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 0.6649 - mse: 0.5508 - val_loss: 0.7371 - val_mse: 0.6239\n",
      "Epoch 38/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 0.6126 - mse: 0.5008 - val_loss: 0.7241 - val_mse: 0.6137\n",
      "Epoch 39/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 0.5994 - mse: 0.4906 - val_loss: 0.7545 - val_mse: 0.6472\n",
      "Epoch 40/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 0.5907 - mse: 0.4842 - val_loss: 0.7442 - val_mse: 0.6380\n",
      "Epoch 41/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 0.5508 - mse: 0.4470 - val_loss: 0.7452 - val_mse: 0.6430\n",
      "Epoch 42/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 0.5344 - mse: 0.4330 - val_loss: 0.7527 - val_mse: 0.6514\n",
      "Epoch 43/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 0.5257 - mse: 0.4262 - val_loss: 0.7498 - val_mse: 0.6514\n",
      "Epoch 44/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 0.5003 - mse: 0.4027 - val_loss: 0.7393 - val_mse: 0.6433\n",
      "Epoch 45/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 0.5052 - mse: 0.4098 - val_loss: 0.7449 - val_mse: 0.6504\n",
      "Epoch 46/1000\n",
      "56/56 [==============================] - 1s 13ms/step - loss: 0.4972 - mse: 0.4035 - val_loss: 0.7472 - val_mse: 0.6550\n",
      "Epoch 47/1000\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 0.4510 - mse: 0.3601 - val_loss: 0.7361 - val_mse: 0.6460\n",
      "Epoch 48/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.4041 - mse: 0.3155Restoring model weights from the end of the best epoch: 38.\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 0.4041 - mse: 0.3155 - val_loss: 0.7358 - val_mse: 0.6488\n",
      "Epoch 48: early stopping\n",
      "18/18 [==============================] - 1s 6ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 4s 29ms/step - loss: 3.1859 - mse: 3.1710 - val_loss: 0.7303 - val_mse: 0.7154\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.8816 - mse: 2.8667 - val_loss: 0.6520 - val_mse: 0.6371\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.7346 - mse: 2.7196 - val_loss: 0.6345 - val_mse: 0.6195\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.6530 - mse: 2.6379 - val_loss: 0.6435 - val_mse: 0.6282\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.5090 - mse: 2.4936 - val_loss: 0.6335 - val_mse: 0.6179\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.4815 - mse: 2.4657 - val_loss: 0.6300 - val_mse: 0.6141\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.4876 - mse: 2.4715 - val_loss: 0.6248 - val_mse: 0.6084\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.3884 - mse: 2.3717 - val_loss: 0.6161 - val_mse: 0.5993\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.2238 - mse: 2.2067 - val_loss: 0.6306 - val_mse: 0.6132\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.2188 - mse: 2.2011 - val_loss: 0.6171 - val_mse: 0.5991\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 2.0870 - mse: 2.0689 - val_loss: 0.6702 - val_mse: 0.6519\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 2.0692 - mse: 2.0506 - val_loss: 0.6130 - val_mse: 0.5942\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.7799 - mse: 1.7610 - val_loss: 0.6075 - val_mse: 0.5885\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.7819 - mse: 1.7628 - val_loss: 0.6890 - val_mse: 0.6698\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 15ms/step - loss: 1.8474 - mse: 1.8282 - val_loss: 0.6352 - val_mse: 0.6158\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.6869 - mse: 1.6674 - val_loss: 0.6296 - val_mse: 0.6101\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.5294 - mse: 1.5098 - val_loss: 0.6338 - val_mse: 0.6142\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.5270 - mse: 1.5073 - val_loss: 0.6743 - val_mse: 0.6544\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.4712 - mse: 1.4512 - val_loss: 0.6090 - val_mse: 0.5889\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.3625 - mse: 1.3424 - val_loss: 0.6541 - val_mse: 0.6339\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.2703 - mse: 1.2501 - val_loss: 0.6589 - val_mse: 0.6385\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 1s 16ms/step - loss: 1.2695 - mse: 1.2490 - val_loss: 0.6315 - val_mse: 0.6109\n",
      "Epoch 23/1000\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 1.1752 - mse: 1.1546Restoring model weights from the end of the best epoch: 13.\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 1.1503 - mse: 1.1296 - val_loss: 0.6455 - val_mse: 0.6247\n",
      "Epoch 23: early stopping\n",
      "18/18 [==============================] - 1s 7ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 9s 63ms/step - loss: 3.5139 - mse: 3.1971 - val_loss: 0.7744 - val_mse: 0.6699\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 2.8196 - mse: 2.7677 - val_loss: 0.6709 - val_mse: 0.6468\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 2.6790 - mse: 2.6622 - val_loss: 0.6184 - val_mse: 0.6062\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 2.6104 - mse: 2.5998 - val_loss: 0.6379 - val_mse: 0.6284\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 2.6230 - mse: 2.6138 - val_loss: 0.5954 - val_mse: 0.5864\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 2.4628 - mse: 2.4539 - val_loss: 0.6120 - val_mse: 0.6031\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 2.3276 - mse: 2.3186 - val_loss: 0.6570 - val_mse: 0.6479\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 2.3428 - mse: 2.3336 - val_loss: 0.6490 - val_mse: 0.6398\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 2.2529 - mse: 2.2435 - val_loss: 0.6306 - val_mse: 0.6209\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 2.1599 - mse: 2.1501 - val_loss: 0.6273 - val_mse: 0.6174\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 1.9891 - mse: 1.9790 - val_loss: 0.5901 - val_mse: 0.5799\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 1.8864 - mse: 1.8760 - val_loss: 0.6687 - val_mse: 0.6582\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.7720 - mse: 1.7614 - val_loss: 0.6008 - val_mse: 0.5900\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.8159 - mse: 1.8050 - val_loss: 0.6450 - val_mse: 0.6339\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 1.6062 - mse: 1.5950 - val_loss: 0.6365 - val_mse: 0.6252\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.5461 - mse: 1.5347 - val_loss: 0.6628 - val_mse: 0.6513\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 1.5982 - mse: 1.5866 - val_loss: 0.6121 - val_mse: 0.6003\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.5001 - mse: 1.4883 - val_loss: 0.6198 - val_mse: 0.6079\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.3928 - mse: 1.3808 - val_loss: 0.6214 - val_mse: 0.6094\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.3451 - mse: 1.3330 - val_loss: 0.6113 - val_mse: 0.5991\n",
      "Epoch 21/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 1.3131 - mse: 1.3009Restoring model weights from the end of the best epoch: 11.\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 1.3290 - mse: 1.3167 - val_loss: 0.6067 - val_mse: 0.5944\n",
      "Epoch 21: early stopping\n",
      "18/18 [==============================] - 2s 13ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 9s 61ms/step - loss: 5.3303 - mse: 3.2320 - val_loss: 1.1034 - val_mse: 0.6518\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.9981 - mse: 2.7542 - val_loss: 0.8576 - val_mse: 0.6976\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.7914 - mse: 2.6462 - val_loss: 0.7467 - val_mse: 0.6106\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.6649 - mse: 2.5325 - val_loss: 0.7385 - val_mse: 0.6089\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.6418 - mse: 2.5137 - val_loss: 0.7471 - val_mse: 0.6204\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.6290 - mse: 2.5027 - val_loss: 0.7316 - val_mse: 0.6056\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 2.4171 - mse: 2.2916 - val_loss: 0.7918 - val_mse: 0.6662\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 2.3249 - mse: 2.2005 - val_loss: 0.7476 - val_mse: 0.6234\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 2.2346 - mse: 2.1100 - val_loss: 0.7367 - val_mse: 0.6115\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 2.0663 - mse: 1.9411 - val_loss: 0.7512 - val_mse: 0.6262\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.2038 - mse: 2.0785 - val_loss: 0.7826 - val_mse: 0.6568\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 2.2526 - mse: 2.1264 - val_loss: 0.7501 - val_mse: 0.6237\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 1.9857 - mse: 1.8584 - val_loss: 0.7196 - val_mse: 0.5923\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 1.9499 - mse: 1.8225 - val_loss: 0.7302 - val_mse: 0.6029\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 1.7857 - mse: 1.6583 - val_loss: 0.7618 - val_mse: 0.6345\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 1.6865 - mse: 1.5595 - val_loss: 0.7644 - val_mse: 0.6379\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 1.6248 - mse: 1.4987 - val_loss: 0.7735 - val_mse: 0.6475\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 1.5805 - mse: 1.4549 - val_loss: 0.7162 - val_mse: 0.5907\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 1.5474 - mse: 1.4222 - val_loss: 0.7506 - val_mse: 0.6260\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 1.5808 - mse: 1.4557 - val_loss: 0.7458 - val_mse: 0.6207\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 1.5587 - mse: 1.4335 - val_loss: 0.7272 - val_mse: 0.6019\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.4490 - mse: 1.3238 - val_loss: 0.7020 - val_mse: 0.5771\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.4831 - mse: 1.3580 - val_loss: 0.7500 - val_mse: 0.6248\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 1.3481 - mse: 1.2232 - val_loss: 0.7129 - val_mse: 0.5882\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 1.2909 - mse: 1.1661 - val_loss: 0.7447 - val_mse: 0.6200\n",
      "Epoch 26/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.2692 - mse: 1.1449 - val_loss: 0.7233 - val_mse: 0.5992\n",
      "Epoch 27/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.2115 - mse: 1.0874 - val_loss: 0.7155 - val_mse: 0.5914\n",
      "Epoch 28/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 1.1524 - mse: 1.0289 - val_loss: 0.7380 - val_mse: 0.6149\n",
      "Epoch 29/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.1316 - mse: 1.0086 - val_loss: 0.7222 - val_mse: 0.5993\n",
      "Epoch 30/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.0512 - mse: 0.9286 - val_loss: 0.7398 - val_mse: 0.6173\n",
      "Epoch 31/1000\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 1.0504 - mse: 0.9278 - val_loss: 0.7043 - val_mse: 0.5818\n",
      "Epoch 32/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 1.1262 - mse: 1.0035Restoring model weights from the end of the best epoch: 22.\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 1.1262 - mse: 1.0035 - val_loss: 0.7210 - val_mse: 0.5978\n",
      "Epoch 32: early stopping\n",
      "18/18 [==============================] - 2s 14ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 6s 37ms/step - loss: 3.1866 - mse: 3.1194 - val_loss: 0.7204 - val_mse: 0.6608\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.8532 - mse: 2.7972 - val_loss: 0.6530 - val_mse: 0.6003\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.7027 - mse: 2.6522 - val_loss: 0.6538 - val_mse: 0.6053\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.5263 - mse: 2.4792 - val_loss: 0.6725 - val_mse: 0.6266\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 2.4793 - mse: 2.4341 - val_loss: 0.6413 - val_mse: 0.5966\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.3476 - mse: 2.3033 - val_loss: 0.6796 - val_mse: 0.6356\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.3701 - mse: 2.3261 - val_loss: 0.6883 - val_mse: 0.6440\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.1460 - mse: 2.1017 - val_loss: 0.6659 - val_mse: 0.6219\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 2.1204 - mse: 2.0762 - val_loss: 0.7115 - val_mse: 0.6670\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.9407 - mse: 1.8964 - val_loss: 0.6594 - val_mse: 0.6153\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.7843 - mse: 1.7400 - val_loss: 0.6639 - val_mse: 0.6193\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.8227 - mse: 1.7782 - val_loss: 0.6430 - val_mse: 0.5985\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.6469 - mse: 1.6024 - val_loss: 0.6362 - val_mse: 0.5917\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.5425 - mse: 1.4981 - val_loss: 0.6717 - val_mse: 0.6275\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.3964 - mse: 1.3522 - val_loss: 0.6575 - val_mse: 0.6132\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.2889 - mse: 1.2444 - val_loss: 0.6520 - val_mse: 0.6074\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.2474 - mse: 1.2022 - val_loss: 0.6868 - val_mse: 0.6413\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.1505 - mse: 1.1048 - val_loss: 0.6639 - val_mse: 0.6179\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.1557 - mse: 1.1089 - val_loss: 0.6560 - val_mse: 0.6088\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 1.0450 - mse: 0.9975 - val_loss: 0.6389 - val_mse: 0.5909\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 0.9565 - mse: 0.9079 - val_loss: 0.6570 - val_mse: 0.6081\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 0.8451 - mse: 0.7962 - val_loss: 0.6891 - val_mse: 0.6399\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.7746 - mse: 0.7254Restoring model weights from the end of the best epoch: 13.\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 0.7746 - mse: 0.7254 - val_loss: 0.6746 - val_mse: 0.6252\n",
      "Epoch 23: early stopping\n",
      "18/18 [==============================] - 1s 7ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 15s 107ms/step - loss: 4.1089 - mse: 4.0993 - val_loss: 1.0055 - val_mse: 0.9959\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 3s 61ms/step - loss: 3.1843 - mse: 3.1745 - val_loss: 0.8079 - val_mse: 0.7979\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 3s 60ms/step - loss: 3.0630 - mse: 3.0530 - val_loss: 1.1057 - val_mse: 1.0957\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 3s 61ms/step - loss: 3.0397 - mse: 3.0294 - val_loss: 0.7596 - val_mse: 0.7490\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 3s 61ms/step - loss: 2.8832 - mse: 2.8725 - val_loss: 0.7604 - val_mse: 0.7497\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 3s 62ms/step - loss: 2.7894 - mse: 2.7787 - val_loss: 0.7083 - val_mse: 0.6975\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 3s 61ms/step - loss: 2.8586 - mse: 2.8475 - val_loss: 0.7588 - val_mse: 0.7477\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 3s 60ms/step - loss: 2.7149 - mse: 2.7038 - val_loss: 0.7157 - val_mse: 0.7046\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 3s 60ms/step - loss: 2.7622 - mse: 2.7511 - val_loss: 0.8641 - val_mse: 0.8531\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 3s 60ms/step - loss: 2.6795 - mse: 2.6685 - val_loss: 0.7251 - val_mse: 0.7141\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 3s 62ms/step - loss: 2.5785 - mse: 2.5675 - val_loss: 0.6987 - val_mse: 0.6878\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 3s 60ms/step - loss: 2.5862 - mse: 2.5752 - val_loss: 0.7025 - val_mse: 0.6915\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 3s 60ms/step - loss: 2.7267 - mse: 2.7156 - val_loss: 0.8191 - val_mse: 0.8077\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 3s 60ms/step - loss: 2.9122 - mse: 2.9006 - val_loss: 0.7304 - val_mse: 0.7188\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 3s 61ms/step - loss: 2.8406 - mse: 2.8289 - val_loss: 0.8057 - val_mse: 0.7940\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 3s 60ms/step - loss: 2.6420 - mse: 2.6302 - val_loss: 0.7472 - val_mse: 0.7354\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 3s 61ms/step - loss: 2.6382 - mse: 2.6264 - val_loss: 0.7081 - val_mse: 0.6963\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 3s 60ms/step - loss: 2.7111 - mse: 2.6974 - val_loss: 0.7810 - val_mse: 0.7661\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 3s 61ms/step - loss: 2.5849 - mse: 2.5699 - val_loss: 0.7981 - val_mse: 0.7831\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 3s 60ms/step - loss: 2.6438 - mse: 2.6287 - val_loss: 0.7152 - val_mse: 0.7001\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - ETA: 0s - loss: 3.0025 - mse: 2.9862Restoring model weights from the end of the best epoch: 11.\n",
      "56/56 [==============================] - 3s 61ms/step - loss: 3.0025 - mse: 2.9862 - val_loss: 1.1188 - val_mse: 1.1009\n",
      "Epoch 21: early stopping\n",
      "18/18 [==============================] - 3s 33ms/step\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 11s 70ms/step - loss: 9.8586 - mse: 3.5024 - val_loss: 1.7765 - val_mse: 0.7133\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 3.2971 - mse: 2.9850 - val_loss: 0.7633 - val_mse: 0.7313\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.7898 - mse: 2.7803 - val_loss: 0.6855 - val_mse: 0.6838\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.7117 - mse: 2.7106 - val_loss: 0.6539 - val_mse: 0.6529\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.6042 - mse: 2.6033 - val_loss: 0.6420 - val_mse: 0.6411\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.5208 - mse: 2.5199 - val_loss: 0.6274 - val_mse: 0.6265\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.4428 - mse: 2.4418 - val_loss: 0.7688 - val_mse: 0.7679\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 2.4949 - mse: 2.4940 - val_loss: 0.6402 - val_mse: 0.6392\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.5977 - mse: 2.5967 - val_loss: 0.7098 - val_mse: 0.7087\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.3757 - mse: 2.3747 - val_loss: 0.5904 - val_mse: 0.5894\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 2.4702 - mse: 2.4692 - val_loss: 0.6082 - val_mse: 0.6072\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.2791 - mse: 2.2781 - val_loss: 0.6588 - val_mse: 0.6577\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.2392 - mse: 2.2381 - val_loss: 0.6188 - val_mse: 0.6177\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 1.9904 - mse: 1.9893 - val_loss: 0.6186 - val_mse: 0.6175\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 1.9302 - mse: 1.9290 - val_loss: 0.5999 - val_mse: 0.5987\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 2.1341 - mse: 2.1330 - val_loss: 0.6183 - val_mse: 0.6171\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 1.8670 - mse: 1.8658 - val_loss: 0.5916 - val_mse: 0.5904\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 1.7544 - mse: 1.7532 - val_loss: 0.6240 - val_mse: 0.6228\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 1.8889 - mse: 1.8876 - val_loss: 0.6332 - val_mse: 0.6319\n",
      "Epoch 20/1000\n",
      "55/56 [============================>.] - ETA: 0s - loss: 1.7642 - mse: 1.7629Restoring model weights from the end of the best epoch: 10.\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 1.7741 - mse: 1.7728 - val_loss: 0.6264 - val_mse: 0.6252\n",
      "Epoch 20: early stopping\n",
      "18/18 [==============================] - 2s 13ms/step\n",
      "最佳參數: [182, 595, 5, 1, 279, 231, 255, 2, 0.0004815340293313356, 1.4556943974919337e-05, 2.5406206595049187e-05]\n",
      "最小損失: 0.0021168392781654916\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM, concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer, Real\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.acquisition import gaussian_ei\n",
    "\n",
    "#進行調參的次數\n",
    "n_calls = 30\n",
    "#此函式可以幫我們設定一個模型的結構\n",
    "def set_LSTM_LSTM(lstm1_structure, lstm2_structure, Megred_struture):\n",
    "    lstm1_neurons_num = lstm1_structure['lstm_neurons_num']\n",
    "    lstm1_activations = lstm1_structure['lstm_activations']\n",
    "    lstm1_recurrent_activations = lstm1_structure['lstm_recurrent_activations']\n",
    "    dense1_neurons_num = lstm1_structure['dense_neurons_num']\n",
    "    dense1_activations = lstm1_structure['dense_activations']\n",
    "    kernel_regularizer1= lstm1_structure['kernel_regularizer']\n",
    "\n",
    "    lstm2_neurons_num = lstm2_structure['lstm_neurons_num']\n",
    "    lstm2_activations = lstm2_structure['lstm_activations']\n",
    "    lstm2_recurrent_activations = lstm2_structure['lstm_recurrent_activations']\n",
    "    dense2_neurons_num = lstm2_structure['dense_neurons_num']\n",
    "    dense2_activations = lstm2_structure['dense_activations']\n",
    "    kernel_regularizer2= lstm2_structure['kernel_regularizer']\n",
    "    \n",
    "    Merged_neurons_num = Megred_struture['neurons_num']\n",
    "    Megred_activations = Megred_struture['activations']\n",
    "    Merged_kernel_regularizer = Megred_struture['kernel_regularizer']\n",
    "\n",
    "    input_lstm1 = Input(shape=lstm1_structure['input_shape'])\n",
    "    hidden_1 = input_lstm1\n",
    "\n",
    "    for i in range(0, len(lstm1_neurons_num), 1):\n",
    "        if i == len(lstm1_neurons_num) - 1:\n",
    "            return_sequences=False\n",
    "        else:\n",
    "            return_sequences=True \n",
    "        hidden_1 = LSTM(lstm1_neurons_num[i], return_sequences=return_sequences,\\\n",
    "        activation=lstm1_activations[i], kernel_regularizer=kernel_regularizer1[i],\n",
    "        recurrent_activation= lstm1_recurrent_activations[i])(hidden_1)\n",
    "    output_1 = hidden_1\n",
    "    for i in range(0, len(dense1_neurons_num), 1):\n",
    "        output_1 = Dense(dense1_neurons_num[i], \\\n",
    "            kernel_regularizer=kernel_regularizer1[len(lstm1_neurons_num)-1+i], \\\n",
    "            activation=dense1_activations[i])(output_1)\n",
    "        \n",
    "    input_lstm2 = Input(shape=lstm2_structure['input_shape'])\n",
    "    hidden_2 = input_lstm2\n",
    "\n",
    "    for i in range(0, len(lstm2_neurons_num), 1):\n",
    "        if i == len(lstm2_neurons_num) - 1:\n",
    "            return_sequences=False\n",
    "        else:\n",
    "            return_sequences=True \n",
    "        hidden_2 = LSTM(lstm2_neurons_num[i], return_sequences=return_sequences,\\\n",
    "        activation=lstm2_activations[i], kernel_regularizer=kernel_regularizer2[i],\n",
    "        recurrent_activation= lstm2_recurrent_activations[i])(hidden_2)\n",
    "    output_2 = hidden_2\n",
    "    for i in range(0, len(dense2_neurons_num), 2):\n",
    "        output_2 = Dense(dense2_neurons_num[i], \\\n",
    "            kernel_regularizer=kernel_regularizer2[len(lstm2_neurons_num)-1+i], \\\n",
    "            activation=dense2_activations[i])(output_2)\n",
    "        \n",
    "    merged = concatenate([output_1, output_2], axis=-1)\n",
    "    dense = merged\n",
    "    for i in range(len(Merged_neurons_num)):\n",
    "        dense = Dense(Merged_neurons_num[i], Megred_activations[i], Merged_kernel_regularizer[i])(dense)\n",
    "\n",
    "    output = Dense(y_train.shape[1])(dense)\n",
    "    model = Model(inputs=[input_lstm1, input_lstm2], outputs=output)\n",
    "    return model\n",
    "\n",
    "search_space = [\n",
    "    Integer(100, 600, name='lstm1_neurons_num'),\n",
    "    Integer(100, 600, name='lstm2_neurons_num'),\n",
    "    Integer(1, 5, name='lstm1_layers_num'),\n",
    "    Integer(1, 5, name='lstm2_layers_num'),\n",
    "    Integer(100, 600, name='dense1_neurons_num'),\n",
    "    Integer(100, 600, name='dense2_neurons_num'),\n",
    "    Integer(100, 600, name='merged_neurons_num'),\n",
    "    Integer(1, 3, name='merged_layers_num'),\n",
    "    Real(1e-6, 1e-2, prior='log-uniform', name='lambda1'),\n",
    "    Real(1e-6, 1e-2, prior='log-uniform', name='lambda2'),\n",
    "    Real(1e-6, 1e-2, prior='log-uniform', name='lambda3')\n",
    "]\n",
    "\n",
    "\n",
    "def train_and_evaluate_net(lstm1_neurons_num, lstm2_neurons_num, lstm1_layers_num,\\\n",
    "                           lstm2_layers_num, dense1_neurons_num, dense2_neurons_num,\n",
    "                           merged_neurons_num, merged_layers_num, lambda1, lambda2, lambda3):\n",
    "    batch_size = 32\n",
    "    epochs = 1000\n",
    "\n",
    "    OCHL_lstm_neurons_num = [lstm1_neurons_num]*lstm1_layers_num \n",
    "    OCHLE_lstm_activations = ['tanh']*len(OCHL_lstm_neurons_num)\n",
    "    OCHL_lstm_recurrent_activations = ['sigmoid']*len(OCHL_lstm_neurons_num)\n",
    "    OCHL_dense_neurons_num = [dense1_neurons_num]\n",
    "    OCHL_dense_activations = ['relu']\n",
    "    OCHL_kernel_regularizer=[l2(lambda1)]*(len(OCHL_lstm_neurons_num) + len(OCHL_dense_neurons_num))\n",
    "\n",
    "    Slope_lstm_neurons_num = [lstm2_neurons_num]*lstm2_layers_num\n",
    "    Slope_lstm_activations = ['tanh']*len(Slope_lstm_neurons_num)\n",
    "    Slope_lstm_recurrent_activations = ['sigmoid']*len(Slope_lstm_neurons_num)\n",
    "    Slope_dense_neurons_num = [dense2_neurons_num]\n",
    "    Slope_dense_activations = ['relu']\n",
    "    Slope_kernel_regularizer=[l2(lambda2)]*(len(Slope_lstm_neurons_num) + len(Slope_dense_neurons_num))\n",
    "\n",
    "    Merged_neurons_num = [merged_neurons_num] * merged_layers_num\n",
    "    Megred_activations = ['relu']*len(Merged_neurons_num)\n",
    "    Merged_kernel_regularizer=[l2(lambda3)]*(len(Merged_neurons_num))\n",
    "\n",
    "    lstm_OCHL_structure = {\n",
    "        'input_shape': OCHLE_train.shape[1:],\n",
    "        'lstm_neurons_num': OCHL_lstm_neurons_num,\n",
    "        'lstm_activations': OCHLE_lstm_activations,\n",
    "        'lstm_recurrent_activations':OCHL_lstm_recurrent_activations,\n",
    "        'dense_neurons_num':OCHL_dense_neurons_num,\n",
    "        'dense_activations':OCHL_dense_activations,\n",
    "        'kernel_regularizer':OCHL_kernel_regularizer\n",
    "        }\n",
    "\n",
    "    lstm_Slope_structure = {\n",
    "        'input_shape': X_train.shape[1:],\n",
    "        'lstm_neurons_num': Slope_lstm_neurons_num,\n",
    "        'lstm_activations': Slope_lstm_activations,\n",
    "        'lstm_recurrent_activations':Slope_lstm_recurrent_activations,\n",
    "        'dense_neurons_num':Slope_dense_neurons_num,\n",
    "        'dense_activations':Slope_dense_activations,\n",
    "        'kernel_regularizer':Slope_kernel_regularizer\n",
    "        }\n",
    "\n",
    "    Merged_structure = {\n",
    "        'neurons_num': Merged_neurons_num,\n",
    "        'activations': Megred_activations,\n",
    "        'kernel_regularizer': Merged_kernel_regularizer\n",
    "        }\n",
    "    alltrain = 1\n",
    "    allMSE = np.zeros(alltrain) \n",
    "    for j in range(alltrain):\n",
    "        #設定模型結構\n",
    "        model = set_LSTM_LSTM(lstm_OCHL_structure, lstm_Slope_structure, Merged_structure)\n",
    "        model.compile(loss='mse', optimizer = 'adam', metrics=['mse'])  \n",
    "\n",
    "        # 訓練模型\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=10, \\\n",
    "                                verbose=2, mode='min', restore_best_weights=True)\n",
    "        hist_model = model.fit(\n",
    "            [OCHLE_train, X_train], y_train, epochs=epochs, batch_size=batch_size, \\\n",
    "            validation_split=0.2, callbacks=[early_stopping]\n",
    "        )\n",
    "\n",
    "        #得到輸出\n",
    "        y_pred = model.predict([OCHLE_test, X_test])\n",
    "        y_pred = y_pred / magnification_slope\n",
    "        columns_names = ['履約價', '隱含波動率({})'.format(s_c)]\n",
    "        column_index = [IV_data.columns.get_loc(col) for col in columns_names]\n",
    "\n",
    "        SSE_everyday = np.zeros(((len(y_pred), K_num)))\n",
    "    \n",
    "        for i in range(len(y_pred)):\n",
    "            K_day = IV_matrix_test[i*K_num:(i+1)*K_num, column_index[0]]\n",
    "            iv_day = IV_matrix_test[i*K_num:(i+1)*K_num, column_index[1]]\n",
    "            y_pred_day = y_pred[i]\n",
    "\n",
    "            ForecastData, SSE_everyday[i] = minSSE_recovery(y=iv_day, x=K_day, slope_yhat=y_pred_day)\n",
    "        sse_everyday = SSE_everyday[:, 0]\n",
    "        allMSE[j] = np.mean(sse_everyday)\n",
    "\n",
    "    loss = np.min(allMSE)\n",
    "    return loss\n",
    "\n",
    "@use_named_args(search_space)\n",
    "def objective(**params):\n",
    "    lstm1_neurons_num = params['lstm1_neurons_num']\n",
    "    lstm2_neurons_num = params['lstm2_neurons_num']\n",
    "    lstm1_layers_num = params['lstm1_layers_num']\n",
    "    lstm2_layers_num = params['lstm2_layers_num']\n",
    "    dense1_neurons_num = params['dense1_neurons_num']\n",
    "    dense2_neurons_num = params['dense2_neurons_num']\n",
    "    merged_neurons_num = params['merged_neurons_num']\n",
    "    merged_layers_num = params['merged_layers_num']\n",
    "    lambda1 = params['lambda1']\n",
    "    lambda2 = params['lambda2']\n",
    "    lambda3 = params['lambda3']\n",
    "    \n",
    "    loss = train_and_evaluate_net(lstm1_neurons_num, lstm2_neurons_num, lstm1_layers_num,\n",
    "                                  lstm2_layers_num, dense1_neurons_num, dense2_neurons_num,\n",
    "                                  merged_neurons_num, merged_layers_num, lambda1, lambda2, lambda3)\n",
    "    return loss\n",
    "\n",
    "\n",
    "result = gp_minimize(objective, search_space, n_calls=n_calls, random_state=42, acq_func='EI')\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"最佳參數: {}\".format(result.x))\n",
    "print(\"最小損失: {}\".format(result.fun))\n",
    "\n",
    "\n",
    "best_params = result.x\n",
    "lstm1_neurons_num = best_params[0]\n",
    "lstm2_neurons_num = best_params[1]\n",
    "lstm1_layers_num = best_params[2]\n",
    "lstm2_layers_num = best_params[3]\n",
    "dense1_neurons_num = best_params[4]\n",
    "dense2_neurons_num = best_params[5]\n",
    "merged_neurons_num = best_params[6]\n",
    "merged_layers_num = best_params[7]\n",
    "lambda1 = best_params[8]\n",
    "lambda2 = best_params[9]\n",
    "lambda3 = best_params[10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4/4 [==============================] - 8s 544ms/step - loss: 5.4268 - mse: 4.7774 - val_loss: 1.8976 - val_mse: 1.3001\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.4263 - mse: 3.8525 - val_loss: 1.4466 - val_mse: 0.9194\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.6822 - mse: 3.1767 - val_loss: 1.2530 - val_mse: 0.7902\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 3.3015 - mse: 2.8585 - val_loss: 1.1375 - val_mse: 0.7332\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 3.1859 - mse: 2.7995 - val_loss: 1.0357 - val_mse: 0.6840\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 3.0455 - mse: 2.7096 - val_loss: 0.9574 - val_mse: 0.6524\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.9245 - mse: 2.6335 - val_loss: 0.8792 - val_mse: 0.6153\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 2.8364 - mse: 2.5849 - val_loss: 0.8187 - val_mse: 0.5910\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 2.7671 - mse: 2.5502 - val_loss: 0.7944 - val_mse: 0.5982\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 2.7024 - mse: 2.5155 - val_loss: 0.7909 - val_mse: 0.6220\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 2.6453 - mse: 2.4844 - val_loss: 0.7293 - val_mse: 0.5839\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.5726 - mse: 2.4342 - val_loss: 0.6959 - val_mse: 0.5708\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.5152 - mse: 2.3961 - val_loss: 0.7409 - val_mse: 0.6331\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.4597 - mse: 2.3570 - val_loss: 0.6748 - val_mse: 0.5818\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.3731 - mse: 2.2845 - val_loss: 0.7017 - val_mse: 0.6213\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.2764 - mse: 2.1997 - val_loss: 0.6614 - val_mse: 0.5918\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.1822 - mse: 2.1157 - val_loss: 0.6502 - val_mse: 0.5896\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.1081 - mse: 2.0502 - val_loss: 0.6556 - val_mse: 0.6027\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.0505 - mse: 1.9998 - val_loss: 0.6355 - val_mse: 0.5891\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.9735 - mse: 1.9290 - val_loss: 0.6811 - val_mse: 0.6401\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.8791 - mse: 1.8398 - val_loss: 0.6169 - val_mse: 0.5806\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.8581 - mse: 1.8232 - val_loss: 0.6495 - val_mse: 0.6171\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.7308 - mse: 1.6995 - val_loss: 0.6353 - val_mse: 0.6062\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 1.7224 - mse: 1.6943 - val_loss: 0.6313 - val_mse: 0.6051\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.6742 - mse: 1.6487 - val_loss: 0.6459 - val_mse: 0.6220\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.5520 - mse: 1.5288 - val_loss: 0.6189 - val_mse: 0.5970\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.4717 - mse: 1.4504 - val_loss: 0.6283 - val_mse: 0.6081\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 1.3972 - mse: 1.3775 - val_loss: 0.6100 - val_mse: 0.5912\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.3313 - mse: 1.3130 - val_loss: 0.6261 - val_mse: 0.6086\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.2844 - mse: 1.2672 - val_loss: 0.6324 - val_mse: 0.6159\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.2216 - mse: 1.2055 - val_loss: 0.6183 - val_mse: 0.6027\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.1898 - mse: 1.1745 - val_loss: 0.6308 - val_mse: 0.6161\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.1420 - mse: 1.1274 - val_loss: 0.6134 - val_mse: 0.5993\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.1080 - mse: 1.0941 - val_loss: 0.6135 - val_mse: 0.6000\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.0763 - mse: 1.0629 - val_loss: 0.6182 - val_mse: 0.6052\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 1.0495 - mse: 1.0366 - val_loss: 0.6166 - val_mse: 0.6040\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.0372 - mse: 1.0247 - val_loss: 0.6335 - val_mse: 0.6212\n",
      "Epoch 38/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0465 - mse: 1.0344Restoring model weights from the end of the best epoch: 28.\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.0120 - mse: 0.9999 - val_loss: 0.6305 - val_mse: 0.6186\n",
      "Epoch 38: early stopping\n",
      "18/18 [==============================] - 2s 13ms/step\n",
      "Epoch 1/1000\n",
      "4/4 [==============================] - 8s 635ms/step - loss: 5.4647 - mse: 4.8142 - val_loss: 1.9584 - val_mse: 1.3583\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.5385 - mse: 3.9614 - val_loss: 1.5179 - val_mse: 0.9861\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.7568 - mse: 3.2462 - val_loss: 1.2506 - val_mse: 0.7815\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.3009 - mse: 2.8510 - val_loss: 1.1446 - val_mse: 0.7327\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.1640 - mse: 2.7695 - val_loss: 1.0570 - val_mse: 0.6967\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.0537 - mse: 2.7090 - val_loss: 0.9602 - val_mse: 0.6459\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.9276 - mse: 2.6272 - val_loss: 0.8901 - val_mse: 0.6167\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.8330 - mse: 2.5718 - val_loss: 0.8548 - val_mse: 0.6172\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.7399 - mse: 2.5131 - val_loss: 0.7956 - val_mse: 0.5895\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.6680 - mse: 2.4714 - val_loss: 0.7646 - val_mse: 0.5860\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.5881 - mse: 2.4177 - val_loss: 0.7562 - val_mse: 0.6014\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.4995 - mse: 2.3517 - val_loss: 0.7172 - val_mse: 0.5830\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.4036 - mse: 2.2754 - val_loss: 0.7005 - val_mse: 0.5840\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.3409 - mse: 2.2296 - val_loss: 0.6795 - val_mse: 0.5782\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.2253 - mse: 2.1285 - val_loss: 0.6765 - val_mse: 0.5882\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.0823 - mse: 1.9979 - val_loss: 0.6973 - val_mse: 0.6203\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.9849 - mse: 1.9111 - val_loss: 0.6594 - val_mse: 0.5919\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.8641 - mse: 1.7993 - val_loss: 0.6681 - val_mse: 0.6087\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.7430 - mse: 1.6860 - val_loss: 0.6698 - val_mse: 0.6174\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.6635 - mse: 1.6131 - val_loss: 0.6598 - val_mse: 0.6133\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.6539 - mse: 1.6091 - val_loss: 0.6389 - val_mse: 0.5975\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.5261 - mse: 1.4861 - val_loss: 0.6921 - val_mse: 0.6550\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 1.4700 - mse: 1.4342 - val_loss: 0.6381 - val_mse: 0.6047\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.3922 - mse: 1.3599 - val_loss: 0.6394 - val_mse: 0.6092\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 1.3183 - mse: 1.2890 - val_loss: 0.6585 - val_mse: 0.6310\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.3175 - mse: 1.2908 - val_loss: 0.6582 - val_mse: 0.6330\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 1.3079 - mse: 1.2833 - val_loss: 0.6522 - val_mse: 0.6290\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.2415 - mse: 1.2189 - val_loss: 0.6309 - val_mse: 0.6094\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.1937 - mse: 1.1727 - val_loss: 0.6253 - val_mse: 0.6053\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.1501 - mse: 1.1306 - val_loss: 0.6191 - val_mse: 0.6004\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.1096 - mse: 1.0913 - val_loss: 0.6527 - val_mse: 0.6352\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.0806 - mse: 1.0634 - val_loss: 0.6255 - val_mse: 0.6089\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 1.0575 - mse: 1.0412 - val_loss: 0.6246 - val_mse: 0.6089\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.0386 - mse: 1.0231 - val_loss: 0.6282 - val_mse: 0.6132\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.0158 - mse: 1.0010 - val_loss: 0.6161 - val_mse: 0.6017\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.0038 - mse: 0.9897 - val_loss: 0.6161 - val_mse: 0.6023\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.9667 - mse: 0.9531 - val_loss: 0.6359 - val_mse: 0.6226\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.9483 - mse: 0.9351 - val_loss: 0.6256 - val_mse: 0.6128\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.9086 - mse: 0.8959 - val_loss: 0.6189 - val_mse: 0.6065\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.8786 - mse: 0.8662 - val_loss: 0.6210 - val_mse: 0.6089\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.8447 - mse: 0.8327 - val_loss: 0.6219 - val_mse: 0.6101\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.8155 - mse: 0.8038 - val_loss: 0.6236 - val_mse: 0.6120\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.7924 - mse: 0.7809 - val_loss: 0.6161 - val_mse: 0.6047\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.7622 - mse: 0.7509 - val_loss: 0.6300 - val_mse: 0.6189\n",
      "Epoch 45/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7024 - mse: 0.6912Restoring model weights from the end of the best epoch: 35.\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.7402 - mse: 0.7291 - val_loss: 0.6245 - val_mse: 0.6134\n",
      "Epoch 45: early stopping\n",
      "18/18 [==============================] - 2s 13ms/step\n",
      "Epoch 1/1000\n",
      "4/4 [==============================] - 8s 760ms/step - loss: 5.5455 - mse: 4.8956 - val_loss: 1.9353 - val_mse: 1.3367\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 4.6765 - mse: 4.1016 - val_loss: 1.5352 - val_mse: 1.0069\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.9106 - mse: 3.4041 - val_loss: 1.2812 - val_mse: 0.8172\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.3851 - mse: 2.9407 - val_loss: 1.1554 - val_mse: 0.7495\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.1846 - mse: 2.7964 - val_loss: 1.0502 - val_mse: 0.6966\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.0556 - mse: 2.7177 - val_loss: 0.9491 - val_mse: 0.6420\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.9297 - mse: 2.6366 - val_loss: 0.8784 - val_mse: 0.6124\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.8252 - mse: 2.5714 - val_loss: 0.8303 - val_mse: 0.6003\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.7548 - mse: 2.5356 - val_loss: 0.8135 - val_mse: 0.6150\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.6898 - mse: 2.5006 - val_loss: 0.7921 - val_mse: 0.6210\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.6375 - mse: 2.4744 - val_loss: 0.7295 - val_mse: 0.5820\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.5794 - mse: 2.4389 - val_loss: 0.7447 - val_mse: 0.6174\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.5535 - mse: 2.4323 - val_loss: 0.7269 - val_mse: 0.6171\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.5379 - mse: 2.4332 - val_loss: 0.6718 - val_mse: 0.5769\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.4305 - mse: 2.3400 - val_loss: 0.7067 - val_mse: 0.6246\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.3014 - mse: 2.2230 - val_loss: 0.6641 - val_mse: 0.5927\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.2171 - mse: 2.1489 - val_loss: 0.6613 - val_mse: 0.5991\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.1322 - mse: 2.0727 - val_loss: 0.6437 - val_mse: 0.5893\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 2.0343 - mse: 1.9821 - val_loss: 0.6331 - val_mse: 0.5853\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.9076 - mse: 1.8617 - val_loss: 0.6476 - val_mse: 0.6055\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.8512 - mse: 1.8106 - val_loss: 0.6349 - val_mse: 0.5975\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 1.7752 - mse: 1.7391 - val_loss: 0.6418 - val_mse: 0.6084\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.7373 - mse: 1.7050 - val_loss: 0.6279 - val_mse: 0.5979\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.6043 - mse: 1.5752 - val_loss: 0.6311 - val_mse: 0.6040\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 1.5179 - mse: 1.4916 - val_loss: 0.6420 - val_mse: 0.6174\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.4435 - mse: 1.4196 - val_loss: 0.6212 - val_mse: 0.5986\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.3777 - mse: 1.3557 - val_loss: 0.6637 - val_mse: 0.6429\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 1.3386 - mse: 1.3183 - val_loss: 0.6336 - val_mse: 0.6143\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.2928 - mse: 1.2740 - val_loss: 0.6154 - val_mse: 0.5974\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.2647 - mse: 1.2471 - val_loss: 0.6250 - val_mse: 0.6081\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 1.2388 - mse: 1.2222 - val_loss: 0.6630 - val_mse: 0.6471\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.1853 - mse: 1.1696 - val_loss: 0.6322 - val_mse: 0.6171\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.1478 - mse: 1.1329 - val_loss: 0.6325 - val_mse: 0.6181\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.1351 - mse: 1.1210 - val_loss: 0.6841 - val_mse: 0.6704\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.1402 - mse: 1.1266 - val_loss: 0.6244 - val_mse: 0.6112\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.1027 - mse: 1.0896 - val_loss: 0.6525 - val_mse: 0.6398\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.0716 - mse: 1.0590 - val_loss: 0.6252 - val_mse: 0.6129\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.0566 - mse: 1.0444 - val_loss: 0.6684 - val_mse: 0.6564\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0360 - mse: 1.0242Restoring model weights from the end of the best epoch: 29.\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 1.0360 - mse: 1.0242 - val_loss: 0.6352 - val_mse: 0.6235\n",
      "Epoch 39: early stopping\n",
      "18/18 [==============================] - 2s 14ms/step\n",
      "Epoch 1/1000\n",
      "4/4 [==============================] - 8s 778ms/step - loss: 5.4657 - mse: 4.8157 - val_loss: 1.9419 - val_mse: 1.3423\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 4.4050 - mse: 3.8289 - val_loss: 1.4497 - val_mse: 0.9201\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.6568 - mse: 3.1488 - val_loss: 1.2405 - val_mse: 0.7747\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.2851 - mse: 2.8389 - val_loss: 1.1212 - val_mse: 0.7133\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.1722 - mse: 2.7820 - val_loss: 1.0311 - val_mse: 0.6752\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.0818 - mse: 2.7417 - val_loss: 0.9507 - val_mse: 0.6411\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.9572 - mse: 2.6615 - val_loss: 0.9024 - val_mse: 0.6338\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.8478 - mse: 2.5915 - val_loss: 0.8402 - val_mse: 0.6076\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.7697 - mse: 2.5478 - val_loss: 0.8346 - val_mse: 0.6334\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.7077 - mse: 2.5158 - val_loss: 0.7673 - val_mse: 0.5934\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.6200 - mse: 2.4543 - val_loss: 0.7567 - val_mse: 0.6066\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.5388 - mse: 2.3956 - val_loss: 0.7207 - val_mse: 0.5909\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.4668 - mse: 2.3430 - val_loss: 0.7164 - val_mse: 0.6041\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.3948 - mse: 2.2877 - val_loss: 0.6796 - val_mse: 0.5823\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.3025 - mse: 2.2097 - val_loss: 0.6755 - val_mse: 0.5911\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.2132 - mse: 2.1326 - val_loss: 0.6461 - val_mse: 0.5727\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.1169 - mse: 2.0466 - val_loss: 0.6545 - val_mse: 0.5903\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.0428 - mse: 1.9814 - val_loss: 0.6539 - val_mse: 0.5977\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.9755 - mse: 1.9216 - val_loss: 0.6278 - val_mse: 0.5783\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.8881 - mse: 1.8407 - val_loss: 0.6502 - val_mse: 0.6065\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.8230 - mse: 1.7810 - val_loss: 0.6616 - val_mse: 0.6228\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.7213 - mse: 1.6839 - val_loss: 0.6239 - val_mse: 0.5893\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.6349 - mse: 1.6015 - val_loss: 0.6608 - val_mse: 0.6296\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.5169 - mse: 1.4867 - val_loss: 0.6290 - val_mse: 0.6008\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.4566 - mse: 1.4293 - val_loss: 0.6383 - val_mse: 0.6127\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.3856 - mse: 1.3607 - val_loss: 0.6208 - val_mse: 0.5973\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.3309 - mse: 1.3081 - val_loss: 0.6331 - val_mse: 0.6116\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 1.3584 - mse: 1.3373 - val_loss: 0.6390 - val_mse: 0.6190\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.4027 - mse: 1.3833 - val_loss: 0.6213 - val_mse: 0.6028\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.3458 - mse: 1.3276 - val_loss: 0.6898 - val_mse: 0.6724\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.2822 - mse: 1.2652 - val_loss: 0.6424 - val_mse: 0.6260\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.2241 - mse: 1.2080 - val_loss: 0.6095 - val_mse: 0.5940\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.1728 - mse: 1.1575 - val_loss: 0.6392 - val_mse: 0.6245\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.1244 - mse: 1.1099 - val_loss: 0.6464 - val_mse: 0.6323\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.0886 - mse: 1.0747 - val_loss: 0.6337 - val_mse: 0.6202\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.0576 - mse: 1.0443 - val_loss: 0.6400 - val_mse: 0.6270\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.0206 - mse: 1.0077 - val_loss: 0.6303 - val_mse: 0.6177\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.9763 - mse: 0.9639 - val_loss: 0.6208 - val_mse: 0.6085\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.9466 - mse: 0.9345 - val_loss: 0.6370 - val_mse: 0.6251\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.9090 - mse: 0.8972 - val_loss: 0.6260 - val_mse: 0.6144\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.8789 - mse: 0.8674 - val_loss: 0.6471 - val_mse: 0.6357\n",
      "Epoch 42/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8274 - mse: 0.8161Restoring model weights from the end of the best epoch: 32.\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.8507 - mse: 0.8394 - val_loss: 0.6286 - val_mse: 0.6174\n",
      "Epoch 42: early stopping\n",
      "18/18 [==============================] - 2s 14ms/step\n",
      "Epoch 1/1000\n",
      "4/4 [==============================] - 8s 757ms/step - loss: 5.5155 - mse: 4.8655 - val_loss: 1.9212 - val_mse: 1.3228\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 4.5661 - mse: 3.9915 - val_loss: 1.4685 - val_mse: 0.9404\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.7480 - mse: 3.2418 - val_loss: 1.2409 - val_mse: 0.7773\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.2954 - mse: 2.8515 - val_loss: 1.1244 - val_mse: 0.7192\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.1573 - mse: 2.7699 - val_loss: 1.0319 - val_mse: 0.6791\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.0453 - mse: 2.7083 - val_loss: 0.9562 - val_mse: 0.6500\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.9246 - mse: 2.6324 - val_loss: 0.9037 - val_mse: 0.6387\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.8200 - mse: 2.5673 - val_loss: 0.8243 - val_mse: 0.5954\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.7430 - mse: 2.5248 - val_loss: 0.7999 - val_mse: 0.6025\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.6546 - mse: 2.4666 - val_loss: 0.7648 - val_mse: 0.5948\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.5721 - mse: 2.4101 - val_loss: 0.7398 - val_mse: 0.5934\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.5190 - mse: 2.3796 - val_loss: 0.7185 - val_mse: 0.5925\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.4359 - mse: 2.3158 - val_loss: 0.6915 - val_mse: 0.5829\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.3380 - mse: 2.2345 - val_loss: 0.6921 - val_mse: 0.5984\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.2462 - mse: 2.1568 - val_loss: 0.6600 - val_mse: 0.5790\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 2.1785 - mse: 2.1012 - val_loss: 0.6563 - val_mse: 0.5861\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.0235 - mse: 1.9564 - val_loss: 0.6850 - val_mse: 0.6240\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.9669 - mse: 1.9085 - val_loss: 0.6624 - val_mse: 0.6091\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.8832 - mse: 1.8322 - val_loss: 0.6308 - val_mse: 0.5841\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.7656 - mse: 1.7208 - val_loss: 0.6404 - val_mse: 0.5993\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.6985 - mse: 1.6590 - val_loss: 0.6739 - val_mse: 0.6375\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.6599 - mse: 1.6248 - val_loss: 0.6598 - val_mse: 0.6273\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.5328 - mse: 1.5015 - val_loss: 0.6591 - val_mse: 0.6300\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.4847 - mse: 1.4566 - val_loss: 0.6859 - val_mse: 0.6597\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.4907 - mse: 1.4653 - val_loss: 0.6489 - val_mse: 0.6251\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.4314 - mse: 1.4082 - val_loss: 0.6527 - val_mse: 0.6310\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.3766 - mse: 1.3554 - val_loss: 0.6442 - val_mse: 0.6242\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.3200 - mse: 1.3004 - val_loss: 0.6472 - val_mse: 0.6286\n",
      "Epoch 29/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1464 - mse: 1.1281Restoring model weights from the end of the best epoch: 19.\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 1.2647 - mse: 1.2466 - val_loss: 0.6597 - val_mse: 0.6424\n",
      "Epoch 29: early stopping\n",
      "18/18 [==============================] - 2s 16ms/step\n",
      "0.0019197045185739949\n",
      "原本的model1已經被替換\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, np.int64):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, l2):\n",
    "        return {\"type\": \"L2\", \"l2\": obj.l2}\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\n",
    "    \n",
    "\n",
    "\n",
    "#決定這次的模型編號\n",
    "model_idx = 1\n",
    "#本次預測的變數為：slope(隱波與履約價之間的斜率)或iv(隱波的數值)\n",
    "forecast_variable = 'slope'\n",
    "#資料設定都相同的情況下，最多儲存多少種模型結果\n",
    "max_model = 20\n",
    "\n",
    "#設定參數\n",
    "batch_size = 500\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "OCHL_lstm_neurons_num = [lstm1_neurons_num]*lstm1_layers_num \n",
    "OCHLE_lstm_activations = ['tanh']*len(OCHL_lstm_neurons_num)\n",
    "OCHL_lstm_recurrent_activations = ['sigmoid']*len(OCHL_lstm_neurons_num)\n",
    "OCHL_dense_neurons_num = [dense1_neurons_num]\n",
    "OCHL_dense_activations = ['relu']\n",
    "OCHL_kernel_regularizer=[l2(lambda1)]*(len(OCHL_lstm_neurons_num) + len(OCHL_dense_neurons_num))\n",
    "\n",
    "Slope_lstm_neurons_num = [lstm2_neurons_num]*lstm2_layers_num\n",
    "Slope_lstm_activations = ['tanh']*len(Slope_lstm_neurons_num)\n",
    "Slope_lstm_recurrent_activations = ['sigmoid']*len(Slope_lstm_neurons_num)\n",
    "Slope_dense_neurons_num = [dense2_neurons_num]\n",
    "Slope_dense_activations = ['relu']\n",
    "Slope_kernel_regularizer=[l2(lambda2)]*(len(Slope_lstm_neurons_num) + len(Slope_dense_neurons_num))\n",
    "\n",
    "Merged_neurons_num = [merged_neurons_num] * merged_layers_num\n",
    "Megred_activations = ['relu']*len(Merged_neurons_num)\n",
    "Merged_kernel_regularizer=[l2(lambda3)]*(len(Merged_neurons_num))\n",
    "\n",
    "lstm_OCHL_structure = {\n",
    "    'input_shape': OCHLE_train.shape[1:],\n",
    "    'lstm_neurons_num': OCHL_lstm_neurons_num,\n",
    "    'lstm_activations': OCHLE_lstm_activations,\n",
    "    'lstm_recurrent_activations':OCHL_lstm_recurrent_activations,\n",
    "    'dense_neurons_num':OCHL_dense_neurons_num,\n",
    "    'dense_activations':OCHL_dense_activations,\n",
    "    'kernel_regularizer':OCHL_kernel_regularizer\n",
    "}\n",
    "\n",
    "lstm_Slope_structure = {\n",
    "    'input_shape': X_train.shape[1:],\n",
    "    'lstm_neurons_num': Slope_lstm_neurons_num,\n",
    "    'lstm_activations': Slope_lstm_activations,\n",
    "    'lstm_recurrent_activations':Slope_lstm_recurrent_activations,\n",
    "    'dense_neurons_num':Slope_dense_neurons_num,\n",
    "    'dense_activations':Slope_dense_activations,\n",
    "    'kernel_regularizer':Slope_kernel_regularizer\n",
    "}\n",
    "\n",
    "Merged_structure = {\n",
    "    'neurons_num': Merged_neurons_num,\n",
    "    'activations': Megred_activations,\n",
    "    'kernel_regularizer': Merged_kernel_regularizer\n",
    "}\n",
    "\n",
    "structure_list = [lstm_OCHL_structure, lstm_Slope_structure, Merged_structure]\n",
    "structure_name_list = ['lstm_OCHL_structure', 'lstm_Slope_structure', 'Merged_structure']\n",
    "General_structure = {\n",
    "    structure_name_list[0] : structure_list[0],\n",
    "    structure_name_list[1]: structure_list[1],\n",
    "    structure_name_list[2] : structure_list[2]\n",
    "}\n",
    "\n",
    "\n",
    "def save_model_txt(file_path, structure_list, structure_name_list, mse, mse_adj):\n",
    "    with open('{}'.format(file_path), 'w', encoding='utf-8') as txt_file:\n",
    "        for i in range(len(structure_list)):\n",
    "            txt_file.write(structure_name_list[i] + ':\\n')\n",
    "            for key, value in structure_list[i].items():\n",
    "                txt_file.write(f\"{key}: {value}\\n\")\n",
    "            txt_file.write('-----------------\\n')\n",
    "        txt_file.write('MSE:{}'.format(mse))\n",
    "        txt_file.write('MSE_adj:{}'.format(mse_adj))\n",
    "\n",
    "\n",
    "alltrain = 5\n",
    "allMSE = np.zeros(alltrain)\n",
    "allMSE_adj = np.zeros(alltrain)  \n",
    "allForecastIV = np.zeros((K_num*len(OCHLE_test), alltrain))\n",
    "allSSE_everyday = np.zeros((K_num*len(OCHLE_test), alltrain))\n",
    "allSSE_everyday_adj = np.zeros((K_num*len(OCHLE_test), alltrain))\n",
    "for j in range(alltrain):\n",
    "    #設定模型結構\n",
    "    model = set_LSTM_LSTM(lstm_OCHL_structure, lstm_Slope_structure, Merged_structure)\n",
    "    model.compile(loss='mse', optimizer = 'adam', metrics=['mse'])  \n",
    "\n",
    "    # 訓練模型\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=10, \\\n",
    "                               verbose=2, mode='min', restore_best_weights=True)\n",
    "    hist_model = model.fit(\n",
    "        [OCHLE_train, X_train], y_train, epochs=epochs, batch_size=batch_size, \\\n",
    "        validation_split=0.2, callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #得到輸出\n",
    "    y_pred = model.predict([OCHLE_test, X_test])\n",
    "    y_pred = y_pred / magnification_slope\n",
    "    columns_names = ['履約價', '隱含波動率({})'.format(s_c)]\n",
    "    column_index = [IV_data.columns.get_loc(col) for col in columns_names]\n",
    "    ForecastIV = np.zeros(((len(y_pred), K_num)))\n",
    "    SSE_everyday = np.zeros(((len(y_pred), K_num)))\n",
    "    SSE_everyday_adj = np.zeros(((len(y_pred), K_num)))\n",
    "\n",
    "    model_name = 'model{}'.format(model_idx)\n",
    "    #model_file = 'model{}.h5'.format(model_idx)\n",
    "    model_png = 'model{}.png'.format(model_idx)\n",
    "    Forecast_name = 'model{}.csv'.format(model_idx)\n",
    "    model_txt = 'model{}.txt'.format(model_idx)\n",
    "    model_json = 'model{}.json'.format(model_idx)\n",
    "    for i in range(len(y_pred)):\n",
    "        K_day = IV_matrix_test[i*K_num:(i+1)*K_num, column_index[0]]\n",
    "        iv_day = IV_matrix_test[i*K_num:(i+1)*K_num, column_index[1]]\n",
    "        y_pred_day = y_pred[i]\n",
    "        iv_mean = iv_day / np.mean(iv_day)\n",
    "        ForecastIV[i], sse_day = minSSE_recovery(y=iv_day, x=K_day, slope_yhat=y_pred_day)\n",
    "        SSE_everyday[i] = sse_day\n",
    "        SSE_everyday_adj[i] = sse_day / iv_mean\n",
    "\n",
    "    ForecastIV = np.reshape(ForecastIV,(-1,1))\n",
    "    sse_everyday = SSE_everyday[:, 0]\n",
    "    sse_everyday_adj = SSE_everyday_adj[:, 0]\n",
    "    SSE_everyday = np.reshape(SSE_everyday ,(-1,1))\n",
    "    SSE_everyday_adj = np.reshape(SSE_everyday_adj ,(-1,1))\n",
    "    allMSE[j] = np.mean(sse_everyday)\n",
    "    allMSE_adj[j] = np.mean(sse_everyday_adj)\n",
    "    allForecastIV[:,j:j+1] = ForecastIV\n",
    "    allSSE_everyday[:, j:j+1] = SSE_everyday\n",
    "    allSSE_everyday_adj[:, j:j+1] = SSE_everyday_adj\n",
    "\n",
    "min_MSE_idx = np.argsort(allMSE)[0]\n",
    "ForecastIV = allForecastIV[:, min_MSE_idx:min_MSE_idx+1]\n",
    "SSE_everyday = allSSE_everyday[:, min_MSE_idx:min_MSE_idx+1]\n",
    "SSE_everyday_adj = allSSE_everyday_adj[:, min_MSE_idx:min_MSE_idx+1]\n",
    "min_MSE = allMSE[min_MSE_idx]\n",
    "min_MSE_adj = allMSE_adj[min_MSE_idx]\n",
    "\n",
    "Forecast_matrix  = np.hstack((IV_matrix_test, ForecastIV, SSE_everyday, SSE_everyday_adj))\n",
    "column = np.hstack((IV_data.columns.to_numpy(), \\\n",
    "                        np.array(['上市天數(交易日)','預測隱含波動率({})'.format(s_c), 'loss', '調整後loss'])))\n",
    "    \n",
    "   \n",
    "Forecast_Data = pd.DataFrame(data=Forecast_matrix, columns=column)\n",
    "\n",
    "\n",
    "loss_columns_names = ['交易日期', '到期天數', '上市天數(交易日)', 'loss']\n",
    "loss_columns_index = [Forecast_Data.columns.get_loc(col) for col in loss_columns_names]\n",
    "loss_Data = Forecast_Data.iloc[range(0, len(Forecast_Data), K_num), loss_columns_index]\n",
    "loss_Data = loss_Data.reset_index().iloc[:,1:]\n",
    "loss_Data = loss_Data.rename(columns={'loss': model_name})\n",
    "MSE_data = pd.DataFrame(columns=loss_Data.columns, data=[['MSE', 'MSE', 'MSE', min_MSE]])\n",
    "loss_Data = pd.concat([loss_Data, MSE_data], axis=0)\n",
    "loss_Data = loss_Data.reset_index().iloc[:,1:]\n",
    "print(min_MSE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_path = top_path\n",
    "model_type = 'LSTM-LSTM'\n",
    "\n",
    "model_Dir_tree = ['Forecast&model', expiry, IV_type, 'K_{}'.format(K_Range_dir), model_type,\\\n",
    "                  'seq{}_seq{}_min{}'.format(seq_length1, seq_length2, min_contract_day), forecast_variable]\n",
    "for model_dir in model_Dir_tree:\n",
    "    if model_dir not in os.listdir(model_path):\n",
    "        os.mkdir(model_path + model_dir)\n",
    "    model_path = model_path + model_dir + '/'\n",
    "\n",
    "loss_adj_columns_names = ['交易日期', '到期天數', '調整後loss']\n",
    "loss_adj_columns_index = [Forecast_Data.columns.get_loc(col) for col in loss_adj_columns_names]\n",
    "loss_adj_Data = Forecast_Data.iloc[range(0, len(Forecast_Data), K_num), loss_adj_columns_index]\n",
    "loss_adj_Data = loss_adj_Data.reset_index().iloc[:,1:]\n",
    "loss_adj_Data = loss_adj_Data.rename(columns={'調整後loss': model_name})\n",
    "MSE_adj_data = pd.DataFrame(columns=loss_adj_Data.columns, data=[['MSE', 'MSE', min_MSE_adj]])\n",
    "loss_adj_Data = pd.concat([loss_adj_Data, MSE_adj_data], axis=0)\n",
    "loss_adj_Data = loss_adj_Data.reset_index().iloc[:,1:]\n",
    "\n",
    "\n",
    "\n",
    "if 'Modelloss.csv' in os.listdir(model_path):\n",
    "    Modelloss = pd.read_csv(model_path + 'Modelloss.csv', index_col=False, encoding='Big5')\n",
    "    Modelloss_adj = pd.read_csv(model_path + 'Modelloss_adj.csv', index_col=False, encoding='Big5')\n",
    "    if model_name in Modelloss.columns:\n",
    "        if Modelloss[model_name][len(Modelloss)-1] > min_MSE:\n",
    "            Modelloss[model_name] = loss_Data[model_name]\n",
    "            Modelloss_adj[model_name] = loss_adj_Data[model_name]\n",
    "            Forecast_Data.to_csv(model_path + Forecast_name, index=False, encoding='Big5')\n",
    "            #model.save(model_path + model_file)\n",
    "            with open(model_path+model_json, 'w', encoding='utf-8') as json_file:\n",
    "                    json.dump(General_structure, json_file, ensure_ascii=False, indent=4, \\\n",
    "                              default=convert_to_serializable)\n",
    "            save_model_txt(model_path+model_txt, structure_list, structure_name_list, min_MSE, min_MSE_adj)\n",
    "            plot_model(model, to_file=model_path + model_png, show_shapes=True, show_layer_names=False)\n",
    "            print('原本的{}已經被替換'.format(model_name))\n",
    "        else:\n",
    "            print('此模型未被儲存')\n",
    "    elif len(Modelloss.columns) >= max_model+2 :\n",
    "        all_MSE = np.array(Modelloss.iloc[-1, 2:])\n",
    "        max_MSE = np.max(all_MSE)\n",
    "        if max_MSE > min_MSE:\n",
    "            max_MSE_idx = (np.arange(len(all_MSE))[np.equal(all_MSE, max_MSE)])[0] +2\n",
    "            Modelloss.iloc[:,max_MSE_idx] = loss_Data[model_name]\n",
    "            Modelloss_adj.iloc[:,max_MSE_idx] = loss_adj_Data[model_name]\n",
    "            model_name = Modelloss.columns[max_MSE_idx]\n",
    "            Forecast_name = model_name + '.csv'\n",
    "            #model_file = model_name + '.h5'\n",
    "            model_png = model_name + '.png'\n",
    "            Forecast_Data.to_csv(model_path + Forecast_name, index=False, encoding='Big5')\n",
    "            #model.save(model_path + model_file)\n",
    "            with open(model_path+model_json, 'w', encoding='utf-8') as json_file:\n",
    "                    json.dump(General_structure, json_file, ensure_ascii=False, indent=4, \\\n",
    "                              default=convert_to_serializable)\n",
    "            save_model_txt(model_path+model_txt, structure_list, structure_name_list, min_MSE, min_MSE_adj)\n",
    "            plot_model(model, to_file=model_path + model_png, show_shapes=True, show_layer_names=False)\n",
    "            print('原本的{}已經被替換'.format(model_name))\n",
    "        else:\n",
    "            print('此模型未被儲存')\n",
    "    else:\n",
    "        Modelloss = pd.concat([Modelloss, loss_Data[model_name]], axis=1)\n",
    "        Modelloss = Modelloss.reset_index().iloc[:,1:] \n",
    "        Modelloss_adj = pd.concat([Modelloss_adj, loss_Data[model_name]], axis=1)\n",
    "        Modelloss_adj = Modelloss_adj.reset_index().iloc[:,1:] \n",
    "        Forecast_Data.to_csv(model_path + Forecast_name, index=False, encoding='Big5')\n",
    "        #model.save(model_path + model_file)\n",
    "        with open(model_path+model_json, 'w', encoding='utf-8') as json_file:\n",
    "                    json.dump(General_structure, json_file, ensure_ascii=False, indent=4, \\\n",
    "                              default=convert_to_serializable)\n",
    "        save_model_txt(model_path+model_txt, structure_list, structure_name_list, min_MSE, min_MSE_adj)\n",
    "        plot_model(model, to_file=model_path + model_png, show_shapes=True, show_layer_names=False)\n",
    "        print('此模型已經被儲存為{}'.format(model_name))\n",
    "else:\n",
    "    Modelloss = loss_Data\n",
    "    Modelloss_adj = loss_adj_Data\n",
    "    Forecast_Data.to_csv(model_path + Forecast_name, index=False, encoding='Big5')\n",
    "    #model.save(model_path + model_file)\n",
    "    with open(model_path+model_json, 'w', encoding='utf-8') as json_file:\n",
    "                    json.dump(General_structure, json_file, ensure_ascii=False, indent=4, \\\n",
    "                              default=convert_to_serializable)\n",
    "    save_model_txt(model_path+model_txt, structure_list, structure_name_list, min_MSE, min_MSE_adj)\n",
    "    plot_model(model, to_file=model_path + model_png, show_shapes=True, show_layer_names=False)\n",
    "\n",
    "    \n",
    "Modelloss.to_csv(model_path + 'Modelloss.csv', index=False, encoding='Big5')\n",
    "Modelloss_adj.to_csv(model_path + 'Modelloss_adj.csv', index=False, encoding='Big5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
