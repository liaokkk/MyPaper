{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from function import Slope, minSSE_recovery\n",
    "\n",
    "s_c = '結算價'\n",
    "top_path = './../../../'\n",
    "Data_path = top_path + 'InterpData/'\n",
    "expiry = 'NearbyMonth'\n",
    "\n",
    "IV_type = 'callIV'\n",
    "K_Range = [300, 500]\n",
    "K_Range_file = '{}_{}.csv'.format(K_Range[0], K_Range[1])\n",
    "K_Range_dir = '{}_{}'.format(K_Range[0], K_Range[1])\n",
    "IV_path = '{}/{}/{}/{}'.format(Data_path, expiry, IV_type, K_Range_file)\n",
    "\n",
    "Dir_tree = [top_path, 'ForecastData', expiry, IV_type, K_Range_dir]\n",
    "current_path = Dir_tree[0]\n",
    "for i in range(1, len(Dir_tree), 1):\n",
    "    if Dir_tree[i] not in os.listdir(current_path):\n",
    "        os.mkdir(current_path + Dir_tree[i])\n",
    "    current_path = current_path + Dir_tree[i] + '/'\n",
    "\n",
    "IV_data = pd.read_csv(IV_path, encoding='Big5', index_col=False)\n",
    "IV_matrix = np.array(IV_data)\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "OC = np.array(IV_data['期貨開盤價'] - IV_data['期貨收盤價'])\n",
    "HL = np.array(IV_data['期貨最高價'] - IV_data['期貨最低價'])\n",
    "expirty_days = np.array(IV_data['到期天數'])\n",
    "#OC_HL_K_E = np.vstack((OC, HL, Kmin_reduce_F, Kmax_reduce_F, expirty_days)).T\n",
    "OCHL = np.vstack((OC, HL)).T\n",
    "\n",
    "\n",
    "IV_matrix = np.array(IV_data)\n",
    "K_num = len(np.where(IV_matrix[0, 0] == IV_matrix)[0])\n",
    "K = np.array(IV_data['履約價'])\n",
    "K = np.reshape(K, (-1, K_num))\n",
    "IV= np.array(IV_data['隱含波動率({})'.format(s_c)])\n",
    "IV = np.reshape(IV, (-1, K_num))\n",
    "K_IVslope = Slope(X=K, Y=IV, axis=1)\n",
    "E = IV_matrix[range(0, len(IV_matrix), K_num), IV_data.columns.get_loc('到期天數')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day_expiry_idx = np.arange(len(E))[np.equal(E, 1)]\n",
    "if one_day_expiry_idx[-1] == len(E)-1:\n",
    "    one_day_expiry_idx = one_day_expiry_idx[:-1]\n",
    "most_days_expiry_idx = one_day_expiry_idx + 1\n",
    "most_days_expiry_idx = np.hstack((0, most_days_expiry_idx))\n",
    "\n",
    "most_days_expiry_idx0 = most_days_expiry_idx[:-1]\n",
    "most_days_expiry_idx1 = most_days_expiry_idx[1:]\n",
    "trade_days_in_month = most_days_expiry_idx1 - most_days_expiry_idx0  \n",
    "most_days_expiry = E[most_days_expiry_idx]\n",
    "\n",
    "contract_appear_days1 = [list(range(1, trade_day_in_month+1, 1)) \\\n",
    "                for trade_day_in_month in trade_days_in_month]\n",
    "contract_appear_days1 = [contract_appear_day1 for subcontract_appear_day1 in contract_appear_days1\\\n",
    "                         for contract_appear_day1 in subcontract_appear_day1]\n",
    "contract_appear_days1 = np.array(contract_appear_days1)\n",
    "contract_appear_days2 = np.arange(1, len(E) - most_days_expiry_idx[-1] +1, 1)\n",
    "contract_appear_days = np.hstack((contract_appear_days1, contract_appear_days2))\n",
    "#contract_appear_days 為該契約(特定交易日期、到期日期，履約價不限)上市的交易日數，例如第一天上市到期天數35天，\n",
    "#則值為1，第二天則到期日為34天值為2，一直到k(因為是交易日數，所以數字不一定)。然後又到下個月的契約，值又從1開\n",
    "#始\n",
    "\n",
    "\n",
    "from function import TimeSeriesData\n",
    "seq_length1 = 7\n",
    "seq_length2 = seq_length1 + 1\n",
    "min_contract_day = 2\n",
    "magnification_slope = 10000\n",
    "\n",
    "\n",
    "\n",
    "K_IVslope_E = np.hstack((IV*magnification_slope, np.reshape(E, (-1, 1))))\n",
    "#K_IVslope_E = K_IVslope * magnification_slope\n",
    "Inputs_slope, Ouputs = TimeSeriesData(K_IVslope_E, seq_length=seq_length1, \\\n",
    "                                      drop_out_columns=[len(K_IVslope_E[0])-1])\n",
    "\n",
    "#K_IVslope_E = IV*magnification_slope\n",
    "#Inputs_slope, Ouputs = TimeSeriesData(K_IVslope_E, seq_length=seq_length1, drop_out_columns=[])\n",
    "\n",
    "\n",
    "Inputs_OCHLE  = OCHL[range(0, len(IV_matrix), K_num)]\n",
    "Inputs_OCHLE  = np.array([Inputs_OCHLE[i:i+seq_length2] \\\n",
    "                              for i in range(len(Inputs_OCHLE)-seq_length2+1)])\n",
    "Inputs_OCHLE  = Inputs_OCHLE.astype(float)\n",
    "if seq_length1  > seq_length2-1:\n",
    "    Inputs_OCHLE = Inputs_OCHLE[seq_length1-seq_length2+1:]\n",
    "    contract_appear_days = contract_appear_days[seq_length1-seq_length2+1:]\n",
    "    IV_matrix_forecast = IV_matrix[seq_length1*K_num:]\n",
    "if seq_length1 <= seq_length2-1:\n",
    "    Inputs_slope = Inputs_slope[seq_length2-1-seq_length1:]\n",
    "    Ouputs = Ouputs[seq_length2-1-seq_length1:]\n",
    "    contract_appear_days = contract_appear_days[seq_length2-1:]\n",
    "    IV_matrix_forecast = IV_matrix[(seq_length2-1)*K_num:]\n",
    "\n",
    "\n",
    "match_cond = np.greater_equal(contract_appear_days, min_contract_day)\n",
    "Inputs_OCHLE = Inputs_OCHLE[match_cond]\n",
    "Inputs_slope = Inputs_slope[match_cond]\n",
    "contract_appear_days_filter = contract_appear_days[match_cond]\n",
    "contract_appear_days_filter_Knum = contract_appear_days_filter.repeat(K_num)\n",
    "match_cond_Knum = match_cond.repeat(K_num)\n",
    "IV_matrix_forecast = IV_matrix_forecast[match_cond_Knum]\n",
    "IV_matrix_forecast= np.hstack((IV_matrix_forecast, np.reshape(contract_appear_days_filter_Knum, (-1, 1))))\n",
    "Ouputs = Ouputs[match_cond]\n",
    "\n",
    "\n",
    "\n",
    "train_size = int(len(Inputs_slope)*0.8)\n",
    "#val_size = int(train_size*0.2)\n",
    "X_train = Inputs_slope[:train_size]\n",
    "#X_train = Inputs_slope[:train_size-val_size]\n",
    "#X_val = Inputs_slope[train_size - val_size:train_size]\n",
    "OCHLE_train = Inputs_OCHLE[:train_size ]\n",
    "#OCHLE_train = Inputs_OCHLE[:train_size - val_size]\n",
    "#OCHLE_val = Inputs_OCHLE[train_size - val_size:train_size]\n",
    "y_train = Ouputs[:train_size]\n",
    "#y_train = Ouputs[:train_size-val_size]\n",
    "#y_val = Ouputs[train_size - val_size:train_size]\n",
    "\n",
    "\n",
    "X_test = Inputs_slope[train_size:]\n",
    "y_test = Ouputs[train_size:]\n",
    "IV_matrix_test = IV_matrix_forecast[K_num*train_size:]\n",
    "OCHLE_test = Inputs_OCHLE[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 7s 512ms/step - loss: 2281645.0000 - mse: 2281644.5000 - val_loss: 4082807.7500 - val_mse: 4082807.2500\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2265783.0000 - mse: 2265782.7500 - val_loss: 4031322.7500 - val_mse: 4031322.5000\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2205923.7500 - mse: 2205923.5000 - val_loss: 3876586.7500 - val_mse: 3876586.7500\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2042715.0000 - mse: 2042714.7500 - val_loss: 3499522.0000 - val_mse: 3499521.7500\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1681692.7500 - mse: 1681692.5000 - val_loss: 2742740.2500 - val_mse: 2742740.0000\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1057124.1250 - mse: 1057123.7500 - val_loss: 1575475.6250 - val_mse: 1575475.2500\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 425175.9062 - mse: 425175.5625 - val_loss: 711488.6875 - val_mse: 711488.4375\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 502833.9375 - mse: 502833.6562 - val_loss: 628890.3125 - val_mse: 628889.9375\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 374242.3125 - mse: 374242.0000 - val_loss: 766618.4375 - val_mse: 766618.1250\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 252881.5156 - mse: 252881.2188 - val_loss: 1053602.5000 - val_mse: 1053602.2500\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 307824.2500 - mse: 307823.9688 - val_loss: 1068730.2500 - val_mse: 1068730.0000\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 285540.2188 - mse: 285539.8750 - val_loss: 869049.9375 - val_mse: 869049.6250\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 249747.7969 - mse: 249747.5156 - val_loss: 716830.0000 - val_mse: 716829.6875\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 263227.5000 - mse: 263227.2188 - val_loss: 705072.1875 - val_mse: 705071.8750\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 251015.7031 - mse: 251015.4219 - val_loss: 791451.8125 - val_mse: 791451.5000\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 240659.6094 - mse: 240659.3281 - val_loss: 854067.5000 - val_mse: 854067.1875\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 243869.0625 - mse: 243868.7656 - val_loss: 832489.3125 - val_mse: 832489.0000\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 239909.8750 - mse: 239909.5781Restoring model weights from the end of the best epoch: 8.\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 239909.8750 - mse: 239909.5781 - val_loss: 771670.3750 - val_mse: 771670.0625\n",
      "Epoch 18: early stopping\n",
      "18/18 [==============================] - 1s 13ms/step\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 6s 456ms/step - loss: 2281910.0000 - mse: 2281910.0000 - val_loss: 4085603.5000 - val_mse: 4085603.2500\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2271819.2500 - mse: 2271819.0000 - val_loss: 4060881.7500 - val_mse: 4060881.5000\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 2243925.2500 - mse: 2243925.0000 - val_loss: 4003488.0000 - val_mse: 4003487.7500\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2180660.0000 - mse: 2180659.7500 - val_loss: 3883961.5000 - val_mse: 3883961.2500\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2061891.8750 - mse: 2061891.3750 - val_loss: 3668561.7500 - val_mse: 3668561.5000\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 1866721.6250 - mse: 1866721.6250 - val_loss: 3327588.0000 - val_mse: 3327587.7500\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 1583580.6250 - mse: 1583580.6250 - val_loss: 2843232.2500 - val_mse: 2843232.0000\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 1213436.1250 - mse: 1213436.0000 - val_loss: 2230851.7500 - val_mse: 2230851.5000\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 806930.5000 - mse: 806930.3125 - val_loss: 1570797.8750 - val_mse: 1570797.6250\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 477514.2812 - mse: 477514.0938 - val_loss: 1029437.3125 - val_mse: 1029437.1250\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 347196.0312 - mse: 347195.7812 - val_loss: 759599.6250 - val_mse: 759599.4375\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 376121.5312 - mse: 376121.3125 - val_loss: 677724.3125 - val_mse: 677724.1250\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 348749.2500 - mse: 348749.0312 - val_loss: 681126.5000 - val_mse: 681126.3125\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 271437.0938 - mse: 271436.8750 - val_loss: 767838.3125 - val_mse: 767838.1250\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 241203.6875 - mse: 241203.4688 - val_loss: 871346.3125 - val_mse: 871346.0625\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 250090.2656 - mse: 250090.0781 - val_loss: 918688.8750 - val_mse: 918688.6875\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 255362.7812 - mse: 255362.5781 - val_loss: 892700.0625 - val_mse: 892699.8750\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 247928.4844 - mse: 247928.2969 - val_loss: 831681.8125 - val_mse: 831681.6250\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 242316.9531 - mse: 242316.7500 - val_loss: 771594.6875 - val_mse: 771594.5000\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 241947.5469 - mse: 241947.3438 - val_loss: 744791.6875 - val_mse: 744791.5000\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 441801.5938 - mse: 441801.4375 - val_loss: 1749512.8750 - val_mse: 1749512.6250\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 581252.5000 - mse: 581252.3125Restoring model weights from the end of the best epoch: 12.\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 581252.5000 - mse: 581252.3125 - val_loss: 1398326.6250 - val_mse: 1398326.3750\n",
      "Epoch 22: early stopping\n",
      "18/18 [==============================] - 2s 11ms/step\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 5s 336ms/step - loss: 2282197.2500 - mse: 2282197.0000 - val_loss: 4086674.5000 - val_mse: 4086674.2500\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2266936.2500 - mse: 2266936.2500 - val_loss: 4020570.7500 - val_mse: 4020570.5000\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2152339.5000 - mse: 2152339.2500 - val_loss: 3655109.7500 - val_mse: 3655109.5000\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1665659.1250 - mse: 1665658.8750 - val_loss: 2384709.5000 - val_mse: 2384709.2500\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 641140.8750 - mse: 641140.6250 - val_loss: 833970.1250 - val_mse: 833969.8750\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 608262.1875 - mse: 608261.8750 - val_loss: 777345.5625 - val_mse: 777345.3125\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 284019.5938 - mse: 284019.2812 - val_loss: 1250679.3750 - val_mse: 1250679.2500\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 365218.4375 - mse: 365218.1250 - val_loss: 1132362.0000 - val_mse: 1132361.7500\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 283444.2812 - mse: 283444.0000 - val_loss: 765184.6250 - val_mse: 765184.3750\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 303006.5625 - mse: 303006.2812 - val_loss: 730180.0625 - val_mse: 730179.8125\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 263096.1875 - mse: 263095.9375 - val_loss: 926412.6875 - val_mse: 926412.4375\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 262164.9062 - mse: 262164.6562 - val_loss: 927235.0625 - val_mse: 927234.8125\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 247210.7969 - mse: 247210.5312 - val_loss: 754685.6875 - val_mse: 754685.4375\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 248471.2969 - mse: 248471.0312 - val_loss: 745810.6250 - val_mse: 745810.3750\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 243331.0469 - mse: 243330.7969 - val_loss: 839233.6250 - val_mse: 839233.3750\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 242896.7031 - mse: 242896.4531 - val_loss: 829611.5625 - val_mse: 829611.3125\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 239795.8281 - mse: 239795.5938 - val_loss: 755196.6875 - val_mse: 755196.5000\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 240166.3281 - mse: 240166.0781 - val_loss: 783015.3125 - val_mse: 783015.0000\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 238310.9844 - mse: 238310.7344 - val_loss: 814251.6250 - val_mse: 814251.3750\n",
      "Epoch 20/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 245449.9219 - mse: 245449.6875Restoring model weights from the end of the best epoch: 10.\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 238470.5938 - mse: 238470.3281 - val_loss: 792638.6875 - val_mse: 792638.5000\n",
      "Epoch 20: early stopping\n",
      "18/18 [==============================] - 1s 8ms/step\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 5s 289ms/step - loss: 2280695.0000 - mse: 2280692.2500 - val_loss: 4077718.0000 - val_mse: 4077715.2500\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 2257010.0000 - mse: 2257007.0000 - val_loss: 3997650.7500 - val_mse: 3997648.2500\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 2160736.5000 - mse: 2160734.0000 - val_loss: 3744343.5000 - val_mse: 3744340.7500\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1893936.3750 - mse: 1893933.5000 - val_loss: 3128754.7500 - val_mse: 3128752.2500\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 1327878.5000 - mse: 1327875.6250 - val_loss: 1970558.0000 - val_mse: 1970555.1250\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 531004.9375 - mse: 531002.0000 - val_loss: 735106.3125 - val_mse: 735103.3750\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 447153.3750 - mse: 447150.4688 - val_loss: 615255.5000 - val_mse: 615252.5625\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 427955.2500 - mse: 427952.2812 - val_loss: 730892.5000 - val_mse: 730889.5625\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 256080.4531 - mse: 256077.4688 - val_loss: 1095830.2500 - val_mse: 1095827.2500\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 325257.9062 - mse: 325254.9375 - val_loss: 1118396.0000 - val_mse: 1118393.0000\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 295704.9062 - mse: 295701.9375 - val_loss: 879359.5625 - val_mse: 879356.6250\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 249093.4062 - mse: 249090.4531 - val_loss: 696897.5625 - val_mse: 696894.5625\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 268415.3125 - mse: 268412.3438 - val_loss: 692492.3125 - val_mse: 692489.3750\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 249292.7656 - mse: 249289.7656 - val_loss: 810959.4375 - val_mse: 810956.5000\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 242202.1719 - mse: 242199.1875 - val_loss: 878912.6250 - val_mse: 878909.6875\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 247034.0469 - mse: 247031.0938 - val_loss: 831254.5000 - val_mse: 831251.5625\n",
      "Epoch 17/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 244604.3750 - mse: 244601.4062Restoring model weights from the end of the best epoch: 7.\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 239725.2812 - mse: 239722.3125 - val_loss: 751769.9375 - val_mse: 751767.0000\n",
      "Epoch 17: early stopping\n",
      "18/18 [==============================] - 1s 7ms/step\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 5s 473ms/step - loss: 2281530.7500 - mse: 2281525.2500 - val_loss: 4081964.0000 - val_mse: 4081958.7500\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2262475.0000 - mse: 2262470.0000 - val_loss: 4010328.0000 - val_mse: 4010323.5000\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 2170204.7500 - mse: 2170200.2500 - val_loss: 3752126.7500 - val_mse: 3752122.5000\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1886490.3750 - mse: 1886486.2500 - val_loss: 3080110.2500 - val_mse: 3080106.5000\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1268604.6250 - mse: 1268600.8750 - val_loss: 1809860.6250 - val_mse: 1809857.0000\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 459330.1250 - mse: 459326.5938 - val_loss: 672241.6875 - val_mse: 672238.3750\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 517833.2500 - mse: 517829.9375 - val_loss: 609701.8750 - val_mse: 609698.6250\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 361512.2188 - mse: 361509.0938 - val_loss: 834224.6250 - val_mse: 834221.5000\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 274427.7188 - mse: 274424.5938 - val_loss: 1156787.1250 - val_mse: 1156784.1250\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 337893.7500 - mse: 337890.7500 - val_loss: 1076443.2500 - val_mse: 1076440.2500\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 278223.3438 - mse: 278220.4375 - val_loss: 798575.6875 - val_mse: 798572.8125\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 256384.2500 - mse: 256381.3438 - val_loss: 668869.5625 - val_mse: 668866.6875\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 270501.5938 - mse: 270498.7188 - val_loss: 722598.0000 - val_mse: 722595.1875\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 241564.5156 - mse: 241561.6719 - val_loss: 853633.1250 - val_mse: 853630.3125\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 247974.0469 - mse: 247971.2344 - val_loss: 885256.4375 - val_mse: 885253.6250\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 245455.7188 - mse: 245452.9219 - val_loss: 795220.6875 - val_mse: 795217.9375\n",
      "Epoch 17/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 235877.2500 - mse: 235874.4375Restoring model weights from the end of the best epoch: 7.\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 239803.4531 - mse: 239800.6406 - val_loss: 734459.6875 - val_mse: 734456.8750\n",
      "Epoch 17: early stopping\n",
      "18/18 [==============================] - 1s 7ms/step\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 8s 592ms/step - loss: 2282391.7500 - mse: 2282382.0000 - val_loss: 4086066.7500 - val_mse: 4086058.0000\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2267978.0000 - mse: 2267968.7500 - val_loss: 4027128.7500 - val_mse: 4027119.5000\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2192004.7500 - mse: 2191995.5000 - val_loss: 3808456.5000 - val_mse: 3808447.2500\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1953255.2500 - mse: 1953245.8750 - val_loss: 3233028.0000 - val_mse: 3233018.5000\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1405870.5000 - mse: 1405861.1250 - val_loss: 2084035.2500 - val_mse: 2084025.7500\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 586162.0625 - mse: 586152.4375 - val_loss: 773436.6875 - val_mse: 773427.0625\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 438834.0625 - mse: 438824.3750 - val_loss: 624250.8125 - val_mse: 624241.0000\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 431282.0625 - mse: 431272.2812 - val_loss: 736259.1250 - val_mse: 736249.4375\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 256136.2656 - mse: 256126.5625 - val_loss: 1116866.0000 - val_mse: 1116856.2500\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 334819.7812 - mse: 334810.0938 - val_loss: 1128514.6250 - val_mse: 1128505.0000\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 295992.4375 - mse: 295982.7188 - val_loss: 857968.8125 - val_mse: 857959.1250\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 254123.0625 - mse: 254113.3750 - val_loss: 680352.3125 - val_mse: 680342.6250\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 274656.7812 - mse: 274647.1250 - val_loss: 699222.6250 - val_mse: 699212.9375\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 245122.0781 - mse: 245112.4688 - val_loss: 830214.4375 - val_mse: 830204.8750\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 245599.5156 - mse: 245589.9531 - val_loss: 893343.1250 - val_mse: 893333.5625\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 247841.8281 - mse: 247832.2969 - val_loss: 817351.3125 - val_mse: 817341.6875\n",
      "Epoch 17/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 235492.2656 - mse: 235482.7656Restoring model weights from the end of the best epoch: 7.\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 239037.6719 - mse: 239028.1719 - val_loss: 739214.6250 - val_mse: 739205.1250\n",
      "Epoch 17: early stopping\n",
      "18/18 [==============================] - 2s 13ms/step\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 4s 525ms/step - loss: 2282536.0000 - mse: 2282534.5000 - val_loss: 4091124.5000 - val_mse: 4091123.5000\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2280314.2500 - mse: 2280313.2500 - val_loss: 4085930.7500 - val_mse: 4085930.0000\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2274494.2500 - mse: 2274493.0000 - val_loss: 4073630.5000 - val_mse: 4073629.5000\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2260970.0000 - mse: 2260969.0000 - val_loss: 4047649.7500 - val_mse: 4047648.7500\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2233645.7500 - mse: 2233644.7500 - val_loss: 3998690.5000 - val_mse: 3998689.5000\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2183756.5000 - mse: 2183755.5000 - val_loss: 3914595.7500 - val_mse: 3914594.7500\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2102028.5000 - mse: 2102027.5000 - val_loss: 3779918.7500 - val_mse: 3779918.0000\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1978629.6250 - mse: 1978628.7500 - val_loss: 3579319.2500 - val_mse: 3579318.2500\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1806187.3750 - mse: 1806186.5000 - val_loss: 3298897.5000 - val_mse: 3298896.5000\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1578620.0000 - mse: 1578619.1250 - val_loss: 2934278.7500 - val_mse: 2934277.7500\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1302600.6250 - mse: 1302599.7500 - val_loss: 2493601.2500 - val_mse: 2493600.2500\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 994635.1875 - mse: 994634.3125 - val_loss: 2001190.2500 - val_mse: 2001189.3750\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 686558.5625 - mse: 686557.6250 - val_loss: 1506190.6250 - val_mse: 1506189.6250\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 439564.8750 - mse: 439563.9062 - val_loss: 1086494.1250 - val_mse: 1086493.1250\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 311086.5938 - mse: 311085.5938 - val_loss: 815301.3125 - val_mse: 815300.3125\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 298182.0000 - mse: 298181.0000 - val_loss: 695886.5000 - val_mse: 695885.4375\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 320203.3125 - mse: 320202.2812 - val_loss: 663809.4375 - val_mse: 663808.4375\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 301283.7188 - mse: 301282.7188 - val_loss: 684308.0000 - val_mse: 684307.0000\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 262955.3750 - mse: 262954.3750 - val_loss: 745436.0625 - val_mse: 745435.0625\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 243153.5469 - mse: 243152.5312 - val_loss: 818235.0000 - val_mse: 818234.0000\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 241134.3906 - mse: 241133.4062 - val_loss: 864005.9375 - val_mse: 864004.9375\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 245181.5469 - mse: 245180.5781 - val_loss: 873340.6250 - val_mse: 873339.6875\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 245127.4219 - mse: 245126.4531 - val_loss: 852122.5625 - val_mse: 852121.6250\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 241942.0156 - mse: 241941.0625 - val_loss: 818349.0000 - val_mse: 818348.0000\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 239658.0938 - mse: 239657.1094 - val_loss: 787771.4375 - val_mse: 787770.4375\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 239172.5156 - mse: 239171.5312 - val_loss: 770679.0000 - val_mse: 770678.0000\n",
      "Epoch 27/200\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 225801.4844 - mse: 225800.5156Restoring model weights from the end of the best epoch: 17.\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 239257.1250 - mse: 239256.1406 - val_loss: 768153.5625 - val_mse: 768152.5625\n",
      "Epoch 27: early stopping\n",
      "18/18 [==============================] - 1s 5ms/step\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 9s 677ms/step - loss: 2282090.7500 - mse: 2282088.7500 - val_loss: 4084663.2500 - val_mse: 4084661.2500\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 2268592.2500 - mse: 2268590.5000 - val_loss: 4042473.5000 - val_mse: 4042471.5000\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 2220001.7500 - mse: 2219999.5000 - val_loss: 3921140.0000 - val_mse: 3921138.0000\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 2091741.1250 - mse: 2091739.0000 - val_loss: 3626518.5000 - val_mse: 3626516.5000\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 1803540.6250 - mse: 1803538.5000 - val_loss: 3023342.5000 - val_mse: 3023340.5000\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 1281511.5000 - mse: 1281509.3750 - val_loss: 2017855.7500 - val_mse: 2017853.6250\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 602171.2500 - mse: 602169.1875 - val_loss: 921013.6250 - val_mse: 921011.5625\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 377176.8438 - mse: 377174.7500 - val_loss: 652625.3125 - val_mse: 652623.1875\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 481576.6562 - mse: 481574.5938 - val_loss: 643370.0625 - val_mse: 643368.0000\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 271548.4062 - mse: 271546.3438 - val_loss: 922982.6875 - val_mse: 922980.6250\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 279102.0000 - mse: 279099.9062 - val_loss: 1086295.8750 - val_mse: 1086293.7500\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 302215.4375 - mse: 302213.3750 - val_loss: 979327.6250 - val_mse: 979325.5625\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 260453.4375 - mse: 260451.3750 - val_loss: 783458.0625 - val_mse: 783456.0000\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 254544.8125 - mse: 254542.7188 - val_loss: 692076.4375 - val_mse: 692074.3750\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 260660.6562 - mse: 260658.5938 - val_loss: 729515.5625 - val_mse: 729513.5000\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 242015.5156 - mse: 242013.4531 - val_loss: 817047.5000 - val_mse: 817045.4375\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 241959.1562 - mse: 241957.1250 - val_loss: 857377.0625 - val_mse: 857375.0000\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 243098.4531 - mse: 243096.3750 - val_loss: 814001.4375 - val_mse: 813999.3750\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 238781.9219 - mse: 238779.8438Restoring model weights from the end of the best epoch: 9.\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 238781.9219 - mse: 238779.8438 - val_loss: 762137.6875 - val_mse: 762135.6250\n",
      "Epoch 19: early stopping\n",
      "18/18 [==============================] - 2s 18ms/step\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 10s 693ms/step - loss: 2282110.7500 - mse: 2282109.2500 - val_loss: 4085680.2500 - val_mse: 4085678.7500\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 2271364.0000 - mse: 2271362.5000 - val_loss: 4055553.5000 - val_mse: 4055552.0000\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2239994.7500 - mse: 2239993.2500 - val_loss: 3987711.5000 - val_mse: 3987710.0000\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2175177.0000 - mse: 2175175.7500 - val_loss: 3859731.2500 - val_mse: 3859729.7500\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2058214.6250 - mse: 2058213.0000 - val_loss: 3640990.5000 - val_mse: 3640988.7500\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 1866151.2500 - mse: 1866149.5000 - val_loss: 3299884.0000 - val_mse: 3299882.2500\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1584392.6250 - mse: 1584390.8750 - val_loss: 2815769.7500 - val_mse: 2815768.0000\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 1209552.1250 - mse: 1209550.5000 - val_loss: 2198393.5000 - val_mse: 2198391.7500\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 787375.6875 - mse: 787374.0625 - val_loss: 1519871.3750 - val_mse: 1519869.6250\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 423844.5000 - mse: 423842.7812 - val_loss: 945709.8125 - val_mse: 945708.0000\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 278374.8750 - mse: 278373.1250 - val_loss: 663935.3125 - val_mse: 663933.4375\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 344864.0625 - mse: 344862.2500 - val_loss: 608935.0000 - val_mse: 608933.1875\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 350772.2812 - mse: 350770.5000 - val_loss: 633437.1875 - val_mse: 633435.3750\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 272539.8438 - mse: 272538.0312 - val_loss: 744338.8750 - val_mse: 744337.0625\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 240675.6562 - mse: 240673.8594 - val_loss: 875511.6875 - val_mse: 875509.8750\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 252886.3750 - mse: 252884.5781 - val_loss: 934696.1875 - val_mse: 934694.3750\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 259215.7344 - mse: 259213.9375 - val_loss: 906387.0000 - val_mse: 906385.1875\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 250386.3281 - mse: 250384.5312 - val_loss: 833625.4375 - val_mse: 833623.6250\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 241034.0938 - mse: 241032.2969 - val_loss: 771744.6875 - val_mse: 771742.9375\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 240864.6094 - mse: 240862.8125 - val_loss: 741543.6250 - val_mse: 741541.8125\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 241647.9844 - mse: 241646.2031 - val_loss: 745221.1250 - val_mse: 745219.3125\n",
      "Epoch 22/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 244393.2344 - mse: 244391.4688Restoring model weights from the end of the best epoch: 12.\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 239688.2656 - mse: 239686.5000 - val_loss: 769791.3125 - val_mse: 769789.5000\n",
      "Epoch 22: early stopping\n",
      "18/18 [==============================] - 2s 11ms/step\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 6s 444ms/step - loss: 2281865.2500 - mse: 2281852.5000 - val_loss: 4083788.5000 - val_mse: 4083776.5000\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 2266293.0000 - mse: 2266281.2500 - val_loss: 4028971.2500 - val_mse: 4028960.0000\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 2198376.7500 - mse: 2198365.7500 - val_loss: 3843865.2500 - val_mse: 3843854.2500\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 1997588.8750 - mse: 1997578.2500 - val_loss: 3362760.2500 - val_mse: 3362749.7500\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 1535982.8750 - mse: 1535972.3750 - val_loss: 2400488.2500 - val_mse: 2400478.0000\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 793843.3125 - mse: 793833.0625 - val_loss: 1089853.3750 - val_mse: 1089843.2500\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 365236.5312 - mse: 365226.5312 - val_loss: 648599.8750 - val_mse: 648589.9375\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 522880.6875 - mse: 522870.7500 - val_loss: 633015.3125 - val_mse: 633005.5000\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 272507.7188 - mse: 272497.9375 - val_loss: 966044.3750 - val_mse: 966034.6875\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 298455.0938 - mse: 298445.4688 - val_loss: 1144117.1250 - val_mse: 1144107.5000\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 316735.7188 - mse: 316726.1250 - val_loss: 983349.3750 - val_mse: 983339.8125\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 258671.5312 - mse: 258662.0000 - val_loss: 751821.4375 - val_mse: 751811.9375\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 260808.0469 - mse: 260798.5469 - val_loss: 679414.0000 - val_mse: 679404.5625\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 262273.6250 - mse: 262264.1562 - val_loss: 747532.0625 - val_mse: 747522.6250\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 530856.5000 - mse: 530847.1250 - val_loss: 1632749.0000 - val_mse: 1632739.6250\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 472470.3438 - mse: 472460.9062 - val_loss: 960615.8750 - val_mse: 960606.3750\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 455535.7812 - mse: 455526.3125 - val_loss: 744342.5625 - val_mse: 744332.9375\n",
      "Epoch 18/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 242457.7969 - mse: 242448.1250Restoring model weights from the end of the best epoch: 8.\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 239083.0625 - mse: 239073.3750 - val_loss: 801228.3125 - val_mse: 801218.5000\n",
      "Epoch 18: early stopping\n",
      "18/18 [==============================] - 1s 7ms/step\n",
      "最佳参数: [201, 548, 2, 3, 448, 170, 402, 2, 6.490003020716535e-06, 0.005907643534563971, 0.00024857752864592076]\n",
      "最小损失: 98.01519303328816\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM, concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer, Real\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.acquisition import gaussian_ei\n",
    "\n",
    "#進行調參的次數\n",
    "n_calls=10\n",
    "\n",
    "#此函式可以幫我們設定一個模型的結構\n",
    "def set_LSTM_LSTM(lstm1_structure, lstm2_structure, Megred_struture):\n",
    "    lstm1_neurons_num = lstm1_structure['lstm_neurons_num']\n",
    "    lstm1_activations = lstm1_structure['lstm_activations']\n",
    "    lstm1_recurrent_activations = lstm1_structure['lstm_recurrent_activations']\n",
    "    dense1_neurons_num = lstm1_structure['dense_neurons_num']\n",
    "    dense1_activations = lstm1_structure['dense_activations']\n",
    "    kernel_regularizer1= lstm1_structure['kernel_regularizer']\n",
    "\n",
    "    lstm2_neurons_num = lstm2_structure['lstm_neurons_num']\n",
    "    lstm2_activations = lstm2_structure['lstm_activations']\n",
    "    lstm2_recurrent_activations = lstm2_structure['lstm_recurrent_activations']\n",
    "    dense2_neurons_num = lstm2_structure['dense_neurons_num']\n",
    "    dense2_activations = lstm2_structure['dense_activations']\n",
    "    kernel_regularizer2= lstm2_structure['kernel_regularizer']\n",
    "    \n",
    "    Merged_neurons_num = Megred_struture['neurons_num']\n",
    "    Megred_activations = Megred_struture['activations']\n",
    "    Merged_kernel_regularizer = Megred_struture['kernel_regularizer']\n",
    "\n",
    "    input_lstm1 = Input(shape=lstm1_structure['input_shape'])\n",
    "    hidden_1 = input_lstm1\n",
    "\n",
    "    for i in range(0, len(lstm1_neurons_num), 1):\n",
    "        if i == len(lstm1_neurons_num) - 1:\n",
    "            return_sequences=False\n",
    "        else:\n",
    "            return_sequences=True \n",
    "        hidden_1 = LSTM(lstm1_neurons_num[i], return_sequences=return_sequences,\\\n",
    "        activation=lstm1_activations[i], kernel_regularizer=kernel_regularizer1[i],\n",
    "        recurrent_activation= lstm1_recurrent_activations[i])(hidden_1)\n",
    "    output_1 = hidden_1\n",
    "    for i in range(0, len(dense1_neurons_num), 1):\n",
    "        output_1 = Dense(dense1_neurons_num[i], \\\n",
    "            kernel_regularizer=kernel_regularizer1[len(lstm1_neurons_num)-1+i], \\\n",
    "            activation=dense1_activations[i])(output_1)\n",
    "        \n",
    "    input_lstm2 = Input(shape=lstm2_structure['input_shape'])\n",
    "    hidden_2 = input_lstm2\n",
    "\n",
    "    for i in range(0, len(lstm2_neurons_num), 1):\n",
    "        if i == len(lstm2_neurons_num) - 1:\n",
    "            return_sequences=False\n",
    "        else:\n",
    "            return_sequences=True \n",
    "        hidden_2 = LSTM(lstm2_neurons_num[i], return_sequences=return_sequences,\\\n",
    "        activation=lstm2_activations[i], kernel_regularizer=kernel_regularizer2[i],\n",
    "        recurrent_activation= lstm2_recurrent_activations[i])(hidden_2)\n",
    "    output_2 = hidden_2\n",
    "    for i in range(0, len(dense2_neurons_num), 2):\n",
    "        output_2 = Dense(dense2_neurons_num[i], \\\n",
    "            kernel_regularizer=kernel_regularizer2[len(lstm2_neurons_num)-1+i], \\\n",
    "            activation=dense2_activations[i])(output_2)\n",
    "        \n",
    "    merged = concatenate([output_1, output_2], axis=-1)\n",
    "    dense = merged\n",
    "    for i in range(len(Merged_neurons_num)):\n",
    "        dense = Dense(Merged_neurons_num[i], Megred_activations[i], Merged_kernel_regularizer[i])(dense)\n",
    "\n",
    "    output = Dense(y_train.shape[1])(dense)\n",
    "    model = Model(inputs=[input_lstm1, input_lstm2], outputs=output)\n",
    "    return model\n",
    "\n",
    "search_space = [\n",
    "    Integer(100, 600, name='lstm1_neurons_num'),\n",
    "    Integer(100, 600, name='lstm2_neurons_num'),\n",
    "    Integer(1, 4, name='lstm1_layers_num'),\n",
    "    Integer(1, 4, name='lstm2_layers_num'),\n",
    "    Integer(100, 600, name='dense1_neurons_num'),\n",
    "    Integer(100, 600, name='dense2_neurons_num'),\n",
    "    Integer(100, 600, name='merged_neurons_num'),\n",
    "    Integer(1, 3, name='merged_layers_num'),\n",
    "    Real(1e-6, 1e-2, prior='log-uniform', name='lambda1'),\n",
    "    Real(1e-6, 1e-2, prior='log-uniform', name='lambda2'),\n",
    "    Real(1e-6, 1e-2, prior='log-uniform', name='lambda3')\n",
    "]\n",
    "\n",
    "\n",
    "def train_and_evaluate_net(lstm1_neurons_num, lstm2_neurons_num, lstm1_layers_num,\\\n",
    "                           lstm2_layers_num, dense1_neurons_num, dense2_neurons_num,\n",
    "                           merged_neurons_num, merged_layers_num, lambda1, lambda2, lambda3):\n",
    "    batch_size = 500\n",
    "    epochs = 200\n",
    "\n",
    "    OCHL_lstm_neurons_num = [lstm1_neurons_num]*lstm1_layers_num \n",
    "    OCHLE_lstm_activations = ['tanh']*len(OCHL_lstm_neurons_num)\n",
    "    OCHL_lstm_recurrent_activations = ['sigmoid']*len(OCHL_lstm_neurons_num)\n",
    "    OCHL_dense_neurons_num = [dense1_neurons_num]\n",
    "    OCHL_dense_activations = ['relu']\n",
    "    OCHL_kernel_regularizer=[l2(lambda1)]*(len(OCHL_lstm_neurons_num) + len(OCHL_dense_neurons_num))\n",
    "\n",
    "    Slope_lstm_neurons_num = [lstm2_neurons_num]*lstm2_layers_num\n",
    "    Slope_lstm_activations = ['tanh']*len(Slope_lstm_neurons_num)\n",
    "    Slope_lstm_recurrent_activations = ['sigmoid']*len(Slope_lstm_neurons_num)\n",
    "    Slope_dense_neurons_num = [dense2_neurons_num]\n",
    "    Slope_dense_activations = ['relu']\n",
    "    Slope_kernel_regularizer=[l2(lambda2)]*(len(Slope_lstm_neurons_num) + len(Slope_dense_neurons_num))\n",
    "\n",
    "    Merged_neurons_num = [merged_neurons_num] * merged_layers_num\n",
    "    Megred_activations = ['relu']*len(Merged_neurons_num)\n",
    "    Merged_kernel_regularizer=[l2(lambda3)]*(len(Merged_neurons_num))\n",
    "\n",
    "    lstm_OCHL_structure = {\n",
    "        'input_shape': OCHLE_train.shape[1:],\n",
    "        'lstm_neurons_num': OCHL_lstm_neurons_num,\n",
    "        'lstm_activations': OCHLE_lstm_activations,\n",
    "        'lstm_recurrent_activations':OCHL_lstm_recurrent_activations,\n",
    "        'dense_neurons_num':OCHL_dense_neurons_num,\n",
    "        'dense_activations':OCHL_dense_activations,\n",
    "        'kernel_regularizer':OCHL_kernel_regularizer\n",
    "        }\n",
    "\n",
    "    lstm_Slope_structure = {\n",
    "        'input_shape': X_train.shape[1:],\n",
    "        'lstm_neurons_num': Slope_lstm_neurons_num,\n",
    "        'lstm_activations': Slope_lstm_activations,\n",
    "        'lstm_recurrent_activations':Slope_lstm_recurrent_activations,\n",
    "        'dense_neurons_num':Slope_dense_neurons_num,\n",
    "        'dense_activations':Slope_dense_activations,\n",
    "        'kernel_regularizer':Slope_kernel_regularizer\n",
    "        }\n",
    "\n",
    "    Merged_structure = {\n",
    "        'neurons_num': Merged_neurons_num,\n",
    "        'activations': Megred_activations,\n",
    "        'kernel_regularizer': Merged_kernel_regularizer\n",
    "        }\n",
    "    alltrain = 1\n",
    "    allMSE = np.zeros(alltrain) \n",
    "    for j in range(alltrain):\n",
    "        #設定模型結構\n",
    "        model = set_LSTM_LSTM(lstm_OCHL_structure, lstm_Slope_structure, Merged_structure)\n",
    "        model.compile(loss='mse', optimizer = 'adam', metrics=['mse'])  \n",
    "\n",
    "        # 訓練模型\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10, \\\n",
    "                                verbose=2, mode='min', restore_best_weights=True)\n",
    "        hist_model = model.fit(\n",
    "            [OCHLE_train, X_train], y_train, epochs=epochs, batch_size=batch_size, \\\n",
    "            validation_split=0.2, callbacks=[early_stopping]\n",
    "        )\n",
    "\n",
    "        #得到輸出\n",
    "        y_pred = model.predict([OCHLE_test, X_test])\n",
    "        y_pred = y_pred / magnification_slope\n",
    "        columns_names = ['履約價', '隱含波動率({})'.format(s_c)]\n",
    "        column_index = [IV_data.columns.get_loc(col) for col in columns_names]\n",
    "\n",
    "        sse_allday = np.zeros(len(y_pred))\n",
    "    \n",
    "        for i in range(len(y_pred)):\n",
    "            iv_day = IV_matrix_test[i*K_num:(i+1)*K_num, column_index[1]]\n",
    "            y_pred_day = y_pred[i]\n",
    "\n",
    "            #c = (iv_day - y_pred_day).mean()\n",
    "            #y_pred_day = y_pred_day + c\n",
    "            sse_allday[i] = np.sum((iv_day-y_pred) * (iv_day-y_pred))\n",
    "        allMSE[j] = np.mean(sse_allday)\n",
    "\n",
    "    loss = np.min(allMSE)\n",
    "    return loss\n",
    "\n",
    "@use_named_args(search_space)\n",
    "def objective(**params):\n",
    "    lstm1_neurons_num = params['lstm1_neurons_num']\n",
    "    lstm2_neurons_num = params['lstm2_neurons_num']\n",
    "    lstm1_layers_num = params['lstm1_layers_num']\n",
    "    lstm2_layers_num = params['lstm2_layers_num']\n",
    "    dense1_neurons_num = params['dense1_neurons_num']\n",
    "    dense2_neurons_num = params['dense2_neurons_num']\n",
    "    merged_neurons_num = params['merged_neurons_num']\n",
    "    merged_layers_num = params['merged_layers_num']\n",
    "    lambda1 = params['lambda1']\n",
    "    lambda2 = params['lambda2']\n",
    "    lambda3 = params['lambda3']\n",
    "    \n",
    "    loss = train_and_evaluate_net(lstm1_neurons_num, lstm2_neurons_num, lstm1_layers_num,\n",
    "                                  lstm2_layers_num, dense1_neurons_num, dense2_neurons_num,\n",
    "                                  merged_neurons_num, merged_layers_num, lambda1, lambda2, lambda3)\n",
    "    return loss\n",
    "\n",
    "\n",
    "result = gp_minimize(objective, search_space, n_calls=n_calls, random_state=42, acq_func='EI')\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"最佳参数: {}\".format(result.x))\n",
    "print(\"最小损失: {}\".format(result.fun))\n",
    "\n",
    "\n",
    "best_params = result.x\n",
    "lstm1_neurons_num = best_params[0]\n",
    "lstm2_neurons_num = best_params[1]\n",
    "lstm1_layers_num = best_params[2]\n",
    "lstm2_layers_num = best_params[3]\n",
    "dense1_neurons_num = best_params[4]\n",
    "dense2_neurons_num = best_params[5]\n",
    "merged_neurons_num = best_params[6]\n",
    "merged_layers_num = best_params[7]\n",
    "lambda1 = best_params[8]\n",
    "lambda2 = best_params[9]\n",
    "lambda3 = best_params[10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4/4 [==============================] - 9s 642ms/step - loss: 2281971.5000 - mse: 2281958.7500 - val_loss: 4084324.0000 - val_mse: 4084312.0000\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2266723.7500 - mse: 2266712.0000 - val_loss: 4029146.2500 - val_mse: 4029134.7500\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2197286.0000 - mse: 2197275.0000 - val_loss: 3831749.5000 - val_mse: 3831738.5000\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1977907.1250 - mse: 1977896.1250 - val_loss: 3303014.7500 - val_mse: 3303004.2500\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1475330.6250 - mse: 1475319.8750 - val_loss: 2238585.0000 - val_mse: 2238574.5000\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 689525.0000 - mse: 689514.5000 - val_loss: 912358.3750 - val_mse: 912347.9375\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 406200.5938 - mse: 406190.1875 - val_loss: 646341.1250 - val_mse: 646330.8125\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 482353.6250 - mse: 482343.3438 - val_loss: 683570.0625 - val_mse: 683559.8750\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 257963.5156 - mse: 257953.3438 - val_loss: 1047841.0000 - val_mse: 1047830.9375\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 316535.4688 - mse: 316525.4688 - val_loss: 1126362.3750 - val_mse: 1126352.3750\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 302285.1875 - mse: 302275.1875 - val_loss: 903301.3125 - val_mse: 903291.3750\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 255524.1094 - mse: 255514.1875 - val_loss: 712946.6875 - val_mse: 712936.8750\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 269544.3125 - mse: 269534.4062 - val_loss: 701436.5000 - val_mse: 701426.6250\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 250611.4688 - mse: 250601.6406 - val_loss: 804776.3125 - val_mse: 804766.5000\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 242802.1406 - mse: 242792.3750 - val_loss: 879367.8125 - val_mse: 879358.0625\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 246559.2500 - mse: 246549.5156 - val_loss: 831439.6250 - val_mse: 831429.8750\n",
      "Epoch 17/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 247394.2188 - mse: 247384.4844Restoring model weights from the end of the best epoch: 7.\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 239906.1406 - mse: 239896.4219 - val_loss: 754155.0625 - val_mse: 754145.3125\n",
      "Epoch 17: early stopping\n",
      "18/18 [==============================] - 2s 7ms/step\n",
      "Epoch 1/1000\n",
      "4/4 [==============================] - 8s 742ms/step - loss: 2281634.0000 - mse: 2281621.2500 - val_loss: 4081972.7500 - val_mse: 4081960.7500\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 2263104.7500 - mse: 2263093.0000 - val_loss: 4018006.7500 - val_mse: 4017995.2500\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 2184848.0000 - mse: 2184836.7500 - val_loss: 3802878.2500 - val_mse: 3802867.2500\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 1950956.2500 - mse: 1950945.3750 - val_loss: 3248343.2500 - val_mse: 3248332.7500\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 1429289.1250 - mse: 1429278.6250 - val_loss: 2164327.7500 - val_mse: 2164317.2500\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 644682.3750 - mse: 644672.0625 - val_loss: 862497.1875 - val_mse: 862486.9375\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 404651.2500 - mse: 404641.0000 - val_loss: 633496.4375 - val_mse: 633486.3125\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 466221.9688 - mse: 466211.8750 - val_loss: 687194.8750 - val_mse: 687184.8750\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 251030.4375 - mse: 251020.4688 - val_loss: 1049628.2500 - val_mse: 1049618.3750\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 315867.4688 - mse: 315857.6250 - val_loss: 1128157.3750 - val_mse: 1128147.6250\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 304308.5938 - mse: 304298.7812 - val_loss: 909580.8125 - val_mse: 909571.0625\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 254162.9375 - mse: 254153.2031 - val_loss: 711548.6875 - val_mse: 711539.0000\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 266476.0625 - mse: 266466.3125 - val_loss: 691945.5000 - val_mse: 691935.8125\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 252145.8594 - mse: 252136.1719 - val_loss: 792381.3125 - val_mse: 792371.6875\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 382548.4062 - mse: 382538.7812 - val_loss: 802652.9375 - val_mse: 802643.3125\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 238767.7500 - mse: 238758.1250 - val_loss: 764999.0000 - val_mse: 764989.3750\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 239736.1562 - mse: 239726.5000Restoring model weights from the end of the best epoch: 7.\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 239736.1562 - mse: 239726.5000 - val_loss: 764898.6875 - val_mse: 764889.0000\n",
      "Epoch 17: early stopping\n",
      "18/18 [==============================] - 2s 7ms/step\n",
      "Epoch 1/1000\n",
      "4/4 [==============================] - 8s 777ms/step - loss: 2281792.7500 - mse: 2281780.0000 - val_loss: 4083110.5000 - val_mse: 4083098.5000\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 2264958.0000 - mse: 2264946.0000 - val_loss: 4024183.7500 - val_mse: 4024172.5000\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2191697.2500 - mse: 2191686.2500 - val_loss: 3823511.2500 - val_mse: 3823500.2500\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 1972612.8750 - mse: 1972602.1250 - val_loss: 3297954.5000 - val_mse: 3297944.0000\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1469711.7500 - mse: 1469701.2500 - val_loss: 2250164.0000 - val_mse: 2250153.7500\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 694741.5625 - mse: 694731.3125 - val_loss: 927362.8125 - val_mse: 927352.6250\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 374021.1250 - mse: 374011.0000 - val_loss: 636022.3125 - val_mse: 636012.1875\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 488812.6562 - mse: 488802.6562 - val_loss: 663118.0000 - val_mse: 663108.0625\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 258566.1875 - mse: 258556.3125 - val_loss: 1024780.3125 - val_mse: 1024770.4375\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 309640.0312 - mse: 309630.2188 - val_loss: 1126363.8750 - val_mse: 1126354.1250\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 304428.0312 - mse: 304418.3125 - val_loss: 920793.3750 - val_mse: 920783.6875\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 253990.2812 - mse: 253980.5938 - val_loss: 716759.3125 - val_mse: 716749.5625\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 267288.1875 - mse: 267278.5312 - val_loss: 688354.8125 - val_mse: 688345.1875\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 254092.3594 - mse: 254082.7812 - val_loss: 1901021.7500 - val_mse: 1901012.1250\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 569072.0625 - mse: 569062.5000 - val_loss: 1648997.3750 - val_mse: 1648987.7500\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 473130.5938 - mse: 473121.0312 - val_loss: 592068.9375 - val_mse: 592059.2500\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 307749.3750 - mse: 307739.6562 - val_loss: 672797.1875 - val_mse: 672787.3750\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 269476.3438 - mse: 269466.5000 - val_loss: 679593.6250 - val_mse: 679583.6875\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 246999.4844 - mse: 246989.4531 - val_loss: 814404.9375 - val_mse: 814394.8125\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 242355.9375 - mse: 242345.7656 - val_loss: 878134.4375 - val_mse: 878124.1875\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 245699.8125 - mse: 245689.5156 - val_loss: 824428.8125 - val_mse: 824418.4375\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 238462.0000 - mse: 238451.5938 - val_loss: 750883.8750 - val_mse: 750873.4375\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 240636.0938 - mse: 240625.6250 - val_loss: 739474.8125 - val_mse: 739464.3125\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 239798.0312 - mse: 239787.5156 - val_loss: 781658.8750 - val_mse: 781648.3125\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 238837.9062 - mse: 238827.3125 - val_loss: 816238.5625 - val_mse: 816227.9375\n",
      "Epoch 26/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 244502.0625 - mse: 244491.3906Restoring model weights from the end of the best epoch: 16.\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 239237.2812 - mse: 239226.6094 - val_loss: 795151.5000 - val_mse: 795140.8125\n",
      "Epoch 26: early stopping\n",
      "18/18 [==============================] - 2s 7ms/step\n",
      "136.1052513425306\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, np.int64):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, l2):\n",
    "        return {\"type\": \"L2\", \"l2\": obj.l2}\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\n",
    "\n",
    "\n",
    "#決定這次的模型編號\n",
    "model_idx = 1\n",
    "#本次預測的變數為：slope(隱波與履約價之間的斜率)或iv(隱波的數值)\n",
    "forecast_variable = 'iv'\n",
    "#資料設定都相同的情況下，最多儲存多少種模型結果\n",
    "max_model = 20\n",
    "\n",
    "#設定參數\n",
    "batch_size = 500\n",
    "epochs = 1000\n",
    "\n",
    "OCHL_lstm_neurons_num = [lstm1_neurons_num]*lstm1_layers_num \n",
    "OCHLE_lstm_activations = ['tanh']*len(OCHL_lstm_neurons_num)\n",
    "OCHL_lstm_recurrent_activations = ['sigmoid']*len(OCHL_lstm_neurons_num)\n",
    "OCHL_dense_neurons_num = [dense1_neurons_num]\n",
    "OCHL_dense_activations = ['relu']\n",
    "OCHL_kernel_regularizer=[l2(lambda1)]*(len(OCHL_lstm_neurons_num) + len(OCHL_dense_neurons_num))\n",
    "\n",
    "Slope_lstm_neurons_num = [lstm2_neurons_num]*lstm2_layers_num\n",
    "Slope_lstm_activations = ['tanh']*len(Slope_lstm_neurons_num)\n",
    "Slope_lstm_recurrent_activations = ['sigmoid']*len(Slope_lstm_neurons_num)\n",
    "Slope_dense_neurons_num = [dense2_neurons_num]\n",
    "Slope_dense_activations = ['relu']\n",
    "Slope_kernel_regularizer=[l2(lambda2)]*(len(Slope_lstm_neurons_num) + len(Slope_dense_neurons_num))\n",
    "\n",
    "Merged_neurons_num = [merged_neurons_num] * merged_layers_num\n",
    "Megred_activations = ['relu']*len(Merged_neurons_num)\n",
    "Merged_kernel_regularizer=[l2(lambda3)]*(len(Merged_neurons_num))\n",
    "\n",
    "lstm_OCHL_structure = {\n",
    "    'input_shape': OCHLE_train.shape[1:],\n",
    "    'lstm_neurons_num': OCHL_lstm_neurons_num,\n",
    "    'lstm_activations': OCHLE_lstm_activations,\n",
    "    'lstm_recurrent_activations':OCHL_lstm_recurrent_activations,\n",
    "    'dense_neurons_num':OCHL_dense_neurons_num,\n",
    "    'dense_activations':OCHL_dense_activations,\n",
    "    'kernel_regularizer':OCHL_kernel_regularizer\n",
    "}\n",
    "\n",
    "lstm_Slope_structure = {\n",
    "    'input_shape': X_train.shape[1:],\n",
    "    'lstm_neurons_num': Slope_lstm_neurons_num,\n",
    "    'lstm_activations': Slope_lstm_activations,\n",
    "    'lstm_recurrent_activations':Slope_lstm_recurrent_activations,\n",
    "    'dense_neurons_num':Slope_dense_neurons_num,\n",
    "    'dense_activations':Slope_dense_activations,\n",
    "    'kernel_regularizer':Slope_kernel_regularizer\n",
    "}\n",
    "\n",
    "Merged_structure = {\n",
    "    'neurons_num': Merged_neurons_num,\n",
    "    'activations': Megred_activations,\n",
    "    'kernel_regularizer': Merged_kernel_regularizer\n",
    "}\n",
    "\n",
    "\n",
    "structure_list = [lstm_OCHL_structure, lstm_Slope_structure, Merged_structure]\n",
    "structure_name_list = ['lstm_OCHL_structure', 'lstm_Slope_structure', 'Merged_structure']\n",
    "\n",
    "General_structure = {\n",
    "    structure_name_list[0] : structure_list[0],\n",
    "    structure_name_list[1]: structure_list[1],\n",
    "    structure_name_list[2] : structure_list[2]\n",
    "}\n",
    "\n",
    "\n",
    "def save_model_txt(file_path, structure_list, structure_name_list, mse, mse_adj):\n",
    "    with open('{}'.format(file_path), 'w', encoding='utf-8') as txt_file:\n",
    "        for i in range(len(structure_list)):\n",
    "            txt_file.write(structure_name_list[i] + ':\\n')\n",
    "            for key, value in structure_list[i].items():\n",
    "                txt_file.write(f\"{key}: {value}\\n\")\n",
    "            txt_file.write('-----------------\\n')\n",
    "        txt_file.write('MSE:{}'.format(mse))\n",
    "        txt_file.write('MSE_adj:{}'.format(mse_adj))\n",
    "\n",
    "alltrain = 3\n",
    "allMSE = np.zeros(alltrain)\n",
    "allMSE_adj = np.zeros(alltrain)   \n",
    "allForecastIV = np.zeros((K_num*len(OCHLE_test), 3))\n",
    "allSSE_everyday = np.zeros((K_num*len(OCHLE_test), 3))\n",
    "allSSE_everyday_adj = np.zeros((K_num*len(OCHLE_test), 3))\n",
    "for j in range(alltrain):\n",
    "    #設定模型結構\n",
    "    model = set_LSTM_LSTM(lstm_OCHL_structure, lstm_Slope_structure, Merged_structure)\n",
    "    model.compile(loss='mse', optimizer = 'adam', metrics=['mse'])  \n",
    "\n",
    "    # 訓練模型\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10, \\\n",
    "                               verbose=2, mode='min', restore_best_weights=True)\n",
    "    hist_model = model.fit(\n",
    "        [OCHLE_train, X_train], y_train, epochs=epochs, batch_size=batch_size, \\\n",
    "        validation_split=0.2, callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #得到輸出\n",
    "    y_pred = model.predict([OCHLE_test, X_test])\n",
    "    y_pred = y_pred / magnification_slope\n",
    "    columns_names = ['履約價', '隱含波動率({})'.format(s_c)]\n",
    "    column_index = [IV_data.columns.get_loc(col) for col in columns_names]\n",
    "    ForecastIV = np.zeros(((len(y_pred), K_num)))\n",
    "    SSE_everyday = np.zeros(((len(y_pred), K_num)))\n",
    "    SSE_everyday_adj = np.zeros(((len(y_pred), K_num)))\n",
    "\n",
    "    model_name = 'model{}'.format(model_idx)\n",
    "    #model_file = 'model{}.h5'.format(model_idx)\n",
    "    model_png = 'model{}.png'.format(model_idx)\n",
    "    model_txt = 'model{}.txt'.format(model_idx)\n",
    "    Forecast_name = 'model{}.csv'.format(model_idx)\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        iv_day = IV_matrix_test[i*K_num:(i+1)*K_num, column_index[1]]\n",
    "        y_pred_day = y_pred[i] / magnification_slope\n",
    "        #c = (iv_day - y_pred_day).mean()\n",
    "        #y_pred_day = y_pred_day + c\n",
    "        iv_mean = np.mean(iv_day)\n",
    "        y_pred_day_adj  =y_pred_day / np.std(iv_day, ddof=1)\n",
    "    \n",
    "        ForecastIV[i] = y_pred_day\n",
    "        sse_day = np.sum((iv_day-y_pred) * (iv_day-y_pred))\n",
    "        SSE_everyday[i] = sse_day\n",
    "        SSE_everyday_adj[i] = sse_day / iv_mean\n",
    "\n",
    "    ForecastIV = np.reshape(ForecastIV,(-1,1))\n",
    "    sse_everyday = SSE_everyday[:, 0]\n",
    "    sse_everyday_adj = SSE_everyday_adj[:, 0]\n",
    "    SSE_everyday = np.reshape(SSE_everyday ,(-1,1))\n",
    "    SSE_everyday_adj = np.reshape(SSE_everyday_adj ,(-1,1))\n",
    "    allMSE[j] = np.mean(sse_everyday)\n",
    "    allMSE_adj[j] = np.mean(sse_everyday_adj)\n",
    "    allForecastIV[:,j:j+1] = ForecastIV\n",
    "    allSSE_everyday[:, j:j+1] = SSE_everyday\n",
    "    allSSE_everyday_adj[:, j:j+1] = SSE_everyday_adj\n",
    "\n",
    "min_MSE_idx = np.argsort(allMSE)[0]\n",
    "ForecastIV = allForecastIV[:, min_MSE_idx:min_MSE_idx+1]\n",
    "SSE_everyday = allSSE_everyday[:, min_MSE_idx:min_MSE_idx+1]\n",
    "SSE_everyday_adj = allSSE_everyday_adj[:, min_MSE_idx:min_MSE_idx+1]\n",
    "min_MSE = allMSE[min_MSE_idx]\n",
    "min_MSE_adj = allMSE_adj[min_MSE_idx]\n",
    "\n",
    "Forecast_matrix  = np.hstack((IV_matrix_test, ForecastIV, SSE_everyday, SSE_everyday_adj))\n",
    "column = np.hstack((IV_data.columns.to_numpy(), \\\n",
    "                        np.array(['上市天數(交易日)','預測隱含波動率({})'.format(s_c), 'loss', '調整後loss'])))\n",
    "    \n",
    "   \n",
    "Forecast_Data = pd.DataFrame(data=Forecast_matrix, columns=column)\n",
    "\n",
    "\n",
    "loss_columns_names = ['交易日期', '到期天數', '上市天數(交易日)', 'loss']\n",
    "loss_columns_index = [Forecast_Data.columns.get_loc(col) for col in loss_columns_names]\n",
    "loss_Data = Forecast_Data.iloc[range(0, len(Forecast_Data), K_num), loss_columns_index]\n",
    "loss_Data = loss_Data.reset_index().iloc[:,1:]\n",
    "loss_Data = loss_Data.rename(columns={'loss': model_name})\n",
    "MSE_data = pd.DataFrame(columns=loss_Data.columns, data=[['MSE', 'MSE', 'MSE', min_MSE]])\n",
    "loss_Data = pd.concat([loss_Data, MSE_data], axis=0)\n",
    "loss_Data = loss_Data.reset_index().iloc[:,1:]\n",
    "print(min_MSE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_path = top_path\n",
    "model_type = 'LSTM-LSTM'\n",
    "\n",
    "model_Dir_tree = ['Forecast&model', expiry, IV_type, 'K_{}'.format(K_Range_dir), \\\n",
    "                  'seq{}_seq{}_min{}'.format(seq_length1, seq_length2, min_contract_day), model_type, forecast_variable]\n",
    "for model_dir in model_Dir_tree:\n",
    "    if model_dir not in os.listdir(model_path):\n",
    "        os.mkdir(model_path + model_dir)\n",
    "    model_path = model_path + model_dir + '/'\n",
    "\n",
    "loss_adj_columns_names = ['交易日期', '到期天數', '調整後loss']\n",
    "loss_adj_columns_index = [Forecast_Data.columns.get_loc(col) for col in loss_adj_columns_names]\n",
    "loss_adj_Data = Forecast_Data.iloc[range(0, len(Forecast_Data), K_num), loss_adj_columns_index]\n",
    "loss_adj_Data = loss_adj_Data.reset_index().iloc[:,1:]\n",
    "loss_adj_Data = loss_adj_Data.rename(columns={'調整後loss': model_name})\n",
    "MSE_adj_data = pd.DataFrame(columns=loss_adj_Data.columns, data=[['MSE', 'MSE', np.mean(sse_everyday_adj)]])\n",
    "loss_adj_Data = pd.concat([loss_adj_Data, MSE_adj_data], axis=0)\n",
    "loss_adj_Data = loss_adj_Data.reset_index().iloc[:,1:]\n",
    "\n",
    "\n",
    "\n",
    "if 'Modelloss.csv' in os.listdir(model_path):\n",
    "    Modelloss = pd.read_csv(model_path + 'Modelloss.csv', index_col=False, encoding='Big5')\n",
    "    Modelloss_adj = pd.read_csv(model_path + 'Modelloss_adj.csv', index_col=False, encoding='Big5')\n",
    "    if model_name in Modelloss.columns:\n",
    "        if Modelloss[model_name][len(Modelloss)-1] > np.mean(sse_everyday):\n",
    "            Modelloss[model_name] = loss_Data[model_name]\n",
    "            Modelloss_adj[model_name] = loss_adj_Data[model_name]\n",
    "            Forecast_Data.to_csv(model_path + Forecast_name, index=False, encoding='Big5')\n",
    "            #model.save(model_path + model_file)\n",
    "            save_model_txt(model_path+model_txt, structure_list, structure_name_list, min_MSE, min_MSE_adj)\n",
    "            plot_model(model, to_file=model_path + model_png, show_shapes=True, show_layer_names=True)\n",
    "            print('原本的{}已經被替換'.format(model_name))\n",
    "        else:\n",
    "            print('此模型未被儲存')\n",
    "    elif len(Modelloss.columns) >= max_model+2 :\n",
    "        all_MSE = np.array(Modelloss.iloc[-1, 2:])\n",
    "        max_MSE = np.max(all_MSE)\n",
    "        if max_MSE > np.mean(sse_everyday):\n",
    "            max_MSE_idx = (np.arange(len(all_MSE))[np.equal(all_MSE, max_MSE)])[0] +2\n",
    "            Modelloss.iloc[:,max_MSE_idx] = loss_Data[model_name]\n",
    "            Modelloss_adj.iloc[:,max_MSE_idx] = loss_adj_Data[model_name]\n",
    "            model_name = Modelloss.columns[max_MSE_idx]\n",
    "            Forecast_name = model_name + '.csv'\n",
    "            model_file = model_name + '.h5'\n",
    "            model_png = model_name + '.png'\n",
    "            Forecast_Data.to_csv(model_path + Forecast_name, index=False, encoding='Big5')\n",
    "            #model.save(model_path + model_file)\n",
    "            save_model_txt(model_path+model_txt, structure_list, structure_name_list, min_MSE, min_MSE_adj)\n",
    "            plot_model(model, to_file=model_path + model_png, show_shapes=True, show_layer_names=True)\n",
    "            print('原本的{}已經被替換'.format(model_name))\n",
    "        else:\n",
    "            print('此模型未被儲存')\n",
    "    else:\n",
    "        Modelloss = pd.concat([Modelloss, loss_Data[model_name]], axis=1)\n",
    "        Modelloss = Modelloss.reset_index().iloc[:,1:] \n",
    "        Modelloss_adj = pd.concat([Modelloss_adj, loss_Data[model_name]], axis=1)\n",
    "        Modelloss_adj = Modelloss_adj.reset_index().iloc[:,1:] \n",
    "        Forecast_Data.to_csv(model_path + Forecast_name, index=False, encoding='Big5')\n",
    "        #model.save(model_path + model_file)\n",
    "        save_model_txt(model_path+model_txt, structure_list, structure_name_list, min_MSE, min_MSE_adj)\n",
    "        plot_model(model, to_file=model_path + model_png, show_shapes=True, show_layer_names=True)\n",
    "        print('此模型已經被儲存為{}'.format(model_name))\n",
    "else:\n",
    "    Modelloss = loss_Data\n",
    "    Modelloss_adj = loss_adj_Data\n",
    "    Forecast_Data.to_csv(model_path + Forecast_name, index=False, encoding='Big5')\n",
    "    #model.save(model_path + model_file)\n",
    "    save_model_txt(model_path+model_txt, structure_list, structure_name_list, min_MSE, min_MSE_adj)\n",
    "    plot_model(model, to_file=model_path + model_png, show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    \n",
    "Modelloss.to_csv(model_path + 'Modelloss.csv', index=False, encoding='Big5')\n",
    "Modelloss_adj.to_csv(model_path + 'Modelloss_adj.csv', index=False, encoding='Big5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
